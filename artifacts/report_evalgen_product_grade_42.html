
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Grade AutoMetric Report Card</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
  <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['\(','\)']],
        displayMath: [['\[','\]']]
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
  <style>
    body.dark-mode { background-color: #121212; color: #e0e0e0; }
    body.dark-mode .card { background-color: #1e1e1e; border-color: #333; color: #e0e0e0; }
    body.dark-mode .table, body-dark-mode .table td { background-color: #1e1e1e; color: #e0e0e0; border-color: #333; }
  </style>
  <script>const RC_CORR = {}; const RC_RUNTIME = {}; const RC_ROB = {"available": false};</script>
</head>
<body>
  <div class="container my-5">
    <div class="d-flex justify-content-between align-items-center mb-4">
      <h1>Grade AutoMetric Report Card</h1>
      <div class="d-flex align-items-center">
        <div class="form-check form-switch me-3">
          <input class="form-check-input" type="checkbox" id="darkModeToggle">
          <label class="form-check-label" for="darkModeToggle">Dark Mode</label>
        </div>
        <button class="btn btn-primary" onclick="window.print()">Export to PDF</button>
      </div>
    </div>

    <div class="row g-4">
      <div class="col-md-6">
        <div class="card p-3 h-100">
          <h2>Regression Coefficients</h2>
          <table class="table table-striped"><thead><tr><th>Metric</th><th>Coeff.</th></tr></thead>
            <tbody><tr><td>grade_Qwen3-32B_examples</td><td>0.0939</td></tr><tr><td>evalgen_product_grade_Qwen3-32B_optimized_seed42</td><td>0.0933</td></tr><tr><td>GRMRewardModel</td><td>0.0656</td></tr><tr><td>Feature-Benefit_Separation_Qwen3-32B</td><td>0.0091</td></tr><tr><td>FKGL</td><td>-0.0345</td></tr></tbody>
          </table>
        </div>
      </div>

      <div class="col-md-6">
        <div class="card p-3 h-100">
          <h2>Correlation</h2>
          <div id="correlation-chart" style="height:420px;"></div>
          <div id="correlation-stats" class="mt-2" style="text-align:center; font-size: 1rem; font-weight: 600;"></div>
        </div>
      </div>

      <div class="col-md-6">
        <div class="card p-3 h-100">
          <h2>Robustness <span class="robust-tip text-primary" data-tip-id="robustness-tip-template" style="cursor:pointer; text-decoration: underline; font-size: 0.9rem;">?</span></h2>
          <div id="robustness-sens" style="height:240px;"></div>
          <div id="robustness-stab" style="height:240px;"></div>
        </div>
      </div>

      <div class="col-md-6">
        <div class="card p-3 h-100">
          <h2>Run Time Distribution</h2>
          <div id="runtime-chart" style="height:300px;"></div>
          <p id="runtime-info" class="mt-2"></p>
        </div>
      </div>

      <div class="col-md-6">
        <div class="card p-3 h-100">
          <h2>Metric Details</h2>
          <div class="accordion" id="metricDetails">
            <div class="accordion-item">
              <h2 class="accordion-header" id="descHeader"><button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#descPanel">Descriptions</button></h2>
              <div id="descPanel" class="accordion-collapse collapse"><div class="accordion-body"><ul><li><strong>grade_Qwen3-32B_examples:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">Example-based llm as a judge metric for 'grade'.  The original task description for the task we are evaluating is: You are an expert copywriter. You need to write an e-commerce product description based on the product details and customer reviews. Your description should be SEO-optimized. It should use an active voice and include the product's features, benefits, unique selling points without overpromising, and a call to action for the buyer. Benefits describe how product features will work for the buyer, addressing exactly how the product will improve their lives. Clearly distinguish between features (e.g., lightweight, USB-chargeable) and benefits (e.g., convenience, nutritious drinks on-the-go). Don't mention weaknesses of the product or use generic or repetitive language. Don't make up review text or quotes. Don't include any links. Don't cite the reviews too heavily. Divide your description into readable chunks divided by relevant subheadings. Keep your description around 200 words, no more than 300, in Markdown format.</pre></div></li>
<li><strong>evalgen_product_grade_Qwen3-32B_optimized_seed42:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">MIPROv2-optimized LLM judge for grade on evalgen_product</pre></div></li>
<li><strong>GRMRewardModel:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">The GRMRewardModel is a transformer-based reward model that assigns scalar scores to LLM responses based on their alignment with human preferences. Its main innovation lies in *Hidden State Regularization (HSR)*, a method that regularizes the representation space of hidden states across different examples to improve generalization. Unlike most reward models that rely solely on output logits or fine-tune only the final layer, GRM constrains intermediate hidden states using contrastive learning objectives, enabling more robust preference modeling.

This particular instantiation, `Ray2333/GRM-Llama3.2-3B-rewardmodel-ft`, is based on the Llama-3.2-3B-Instruct model and fine-tuned on the Skywork preference dataset using pairwise comparisons of completions. Given a message (prompt + response), the model outputs a scalar reward score indicating the desirability of the response.

- **Metric Type:** Reference-Free  
- **Range:** Unbounded (typically scaled to [−5, 5] depending on implementation)  
- **Higher is Better?:** Yes  
- **Reference-Based?:** No  
- **Input-Required?:** Yes</pre></div></li>
<li><strong>FKGL:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">The FKGL metric calculates readability using the average sentence length (words per sentence) and the average syllables per word. It is widely used to assess the difficulty of documents in fields such as education, technical communication, and public policy. Lower FKGL scores indicate easier-to-read material, while higher scores signify increased complexity.

- **Metric Type:** Fluency
- **Range:** No theoretical upper bound; typical range is approximately -3.4 to above 20.
- **Higher is Better?:** No
- **Reference-Based?:** No
- **Input-Required?:** Yes</pre></div></li>
<li><strong>Feature-Benefit_Separation_Qwen3-32B:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">**Feature-Benefit Separation** Clear distinction between product features (e.g., ingredients, design) and their corresponding benefits (e.g., improved hair health, convenience).</pre></div></li></ul></div></div>
            </div>
            <div class="accordion-item">
              <h2 class="accordion-header" id="usageHeader"><button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#usagePanel">Usage</button></h2>
              <div id="usagePanel" class="accordion-collapse collapse"><div class="accordion-body"><ul><li><strong>grade_Qwen3-32B_examples:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">- **Domain:** Text Generation
- **Tasks:** 
  - Generate SEO-optimized e-commerce product descriptions
  - Differentiate between product features and benefits in writing
  - Structure content with subheadings and readable chunks
  - Incorporate customer review insights without direct citations
  - Adhere to strict formatting and voice requirements (e.g., active voice, no markdown links)
- **Best Suited For:** 
  - When clear examples of compliant product descriptions exist for the model to learn from
  - For tasks requiring strict adherence to formatting rules (e.g., word limits, subheadings)
  - When SEO optimization and keyword integration are critical success factors
  - In scenarios where distinguishing between features and benefits is a core requirement
  - For tasks with explicit constraints (e.g., no mentions of weaknesses, no generic language)
- **Not Recommended For:** 
  - When product details are ambiguous or lack sufficient examples for the model to learn from
  - For highly creative or subjective writing tasks requiring originality beyond example patterns
  - In cases where the optimization examples are insufficiently diverse (e.g., only 2 examples per range)
  - When the task requires dynamic adaptation to rapidly changing SEO guidelines
  - For products with complex, technical specifications that demand specialized domain knowledge</pre></div></li>
<li><strong>evalgen_product_grade_Qwen3-32B_optimized_seed42:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">- **Domain:** Text Generation (E-commerce Content)
- **Tasks:** 
  - E-commerce Product Description Writing
  - SEO Content Optimization
  - Content Structuring with Subheadings
  - Feature-Benefit Differentiation in Marketing Copy
  - Call-to-Action Generation
- **Best Suited For:** 
  - When evaluating structured, SEO-focused content with clear formatting requirements (e.g., Markdown, subheadings)
  - When assessing adherence to specific feature/benefit distinction guidelines
  - When measuring effectiveness of active voice and persuasive language in marketing copy
  - When evaluating compliance with word count and structural constraints (200-300 words)
  - When judging the quality of call-to-action implementation in e-commerce contexts
- **Not Recommended For:** 
  - When evaluating highly creative or unconventional content that breaks standard e-commerce formatting rules
  - When assessing tasks requiring subjective creativity beyond structured guidelines
  - When the evaluation requires deep domain expertise in niche product categories
  - When the task involves multilingual SEO optimization with language-specific requirements
  - When evaluating content for emotional resonance rather than structural/SEO effectiveness</pre></div></li>
<li><strong>GRMRewardModel:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">### Domains and Tasks

- **Domain:** Text Generation  
- **Tasks:** Dialogue Generation, Response Generation, Safety Evaluation

### Applicability and Limitations

- **Best Suited For:**  
  Evaluating response quality and safety in conversational agents, especially in RLHF or reranking pipelines where pairwise preferences are available.

- **Not Recommended For:**  
  Evaluating creative generation (e.g., poetry or storytelling) or tasks that require ground-truth references (e.g., translation, summarization).</pre></div></li>
<li><strong>FKGL:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">### Domains and Tasks

- **Domain:** Text Generation, Education, Technical Communication  
- **Tasks:** Readability assessment, document simplification, educational content evaluation  

### Applicability and Limitations

- **Best Suited For:**  
- Analyzing educational materials, technical manuals, and legal documents to ensure they meet readability standards.  
- Simplifying public-facing content such as insurance policies or government forms.  

- **Not Recommended For:**  
- Tasks involving creative or highly contextual text, where readability depends on subjective factors.</pre></div></li>
<li><strong>Feature-Benefit_Separation_Qwen3-32B:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">- **Domain:** Text Generation (E-commerce Content Creation)
- **Tasks:** 
  - Product Description Writing
  - SEO-Optimized Copy Generation
  - Marketing Copy Review
  - Feature-Benefit Alignment Evaluation
  - E-commerce Content Optimization
- **Best Suited For:** 
  - When product details include explicit technical specifications and measurable attributes
  - For structured content requiring clear section separation (e.g., subheadings for features vs benefits)
  - When the task requires adherence to specific formatting rules (Markdown, word limits)
  - In scenarios where active voice and benefit-oriented language are critical
  - When evaluating consistency in feature-benefit mapping across multiple product descriptions
- **Not Recommended For:** 
  - For abstract or subjective product descriptions requiring creative storytelling
  - When input lacks specific product details or relies on vague customer reviews
  - In tasks requiring real-time integration of user reviews or dynamic data
  - For content requiring deep cultural or regional nuance beyond the model's training data
  - When the evaluation requires comparing physical product samples with descriptions</pre></div></li></ul></div></div>
            </div>
            <div class="accordion-item">
              <h2 class="accordion-header" id="limitsHeader"><button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#limitsPanel">Limitations</button></h2>
              <div id="limitsPanel" class="accordion-collapse collapse"><div class="accordion-body"><ul><li><strong>grade_Qwen3-32B_examples:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">- **Biases:** 
  - Overemphasis on SEO keywords at the expense of natural language flow
  - Bias toward example-based structures, limiting creative adaptation
  - Prioritization of feature enumeration over benefit articulation
  - Assumption that all products require the same subheading hierarchy
  - Tendency to favor active voice even when passive voice is contextually appropriate
- **Task Misalignment Risks:** 
  - Failure to distinguish between product features and benefits as required
  - Ignoring the 200-300 word constraint due to example-based length normalization
  - Over-reliance on customer reviews without proper contextual integration
  - Misapplication of markdown formatting rules (e.g., improper heading levels)
  - Inadequate call-to-action due to template-based output generation
- **Failure Cases:** 
  - Generated description exceeds 300 words due to verbose example replication
  - Use of passive voice in key selling points despite active voice requirement
  - Fabricated review citations disguised as generic benefit statements
  - Missing subheadings causing poor readability despite explicit formatting instructions
  - Repetitive language patterns from example overfitting</pre></div></li>
<li><strong>evalgen_product_grade_Qwen3-32B_optimized_seed42:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">- **Biases:** 
  - Overemphasis on SEO keywords at the cost of natural readability.
  - Preference for active voice even when passive voice is more appropriate.
  - Assumption that all product descriptions require the same structural template.
  - Bias toward lengthier outputs to meet word count thresholds.
  - Tendency to prioritize novelty in language over factual accuracy.
  - Optimization is based on training data which may not represent all use cases or edge scenarios
- **Task Misalignment Risks:** 
  - Focusing on keyword density rather than addressing the product's unique benefits.
  - Confusing features with benefits due to rigid adherence to structural guidelines.
  - Over-reliance on subheadings, making the text feel fragmented rather than cohesive.
  - Ignoring the 'no links' constraint by inadvertently suggesting external resources.
  - Misinterpreting the 'call to action' as a generic template rather than a tailored prompt.
  - MIPROv2 optimization may overfit to the specific training examples and generalize poorly to different domains
- **Failure Cases:** 
  - Output exceeds 300 words while sacrificing clarity or conciseness.
  - Includes prohibited elements like fabricated review quotes or links.
  - Fails to distinguish between features and benefits, leading to repetitive phrasing.
  - Uses generic language (e.g., 'amazing product') instead of specific, actionable details.
  - Omits required subheadings, resulting in a monolithic block of text.
  - Optimized prompts may be sensitive to changes in the underlying LLM model or version</pre></div></li>
<li><strong>GRMRewardModel:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">- **Biases:**  
  Depends on the biases of the preference data (Skywork dataset), which may reflect annotator or cultural preferences.  
  Sensitivity to prompt formatting may affect score stability.

- **Task Misalignment Risks:**  
  Since it is trained on generic preference data, it may not align with task-specific criteria or specialized user needs.

- **Failure Cases:**  
  May output high reward scores for fluent but factually incorrect or manipulative responses, especially outside the training distribution.  
  Does not explicitly verify factual correctness or consistency.</pre></div></li>
<li><strong>FKGL:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">- **Biases:**  
- FKGL does not account for the semantic content, context, or layout of the text, which may impact readability.  
- Polysyllabic words disproportionately influence scores, potentially overestimating difficulty in texts with technical or specialized vocabulary.  

- **Task Misalignment Risks:**  
- May fail to accurately represent the reading comprehension difficulty for non-native speakers or readers with diverse literacy levels.  

- **Failure Cases:**  
- Poorly segmented texts (e.g., incorrect sentence splitting) can lead to inaccurate FKGL scores.</pre></div></li>
<li><strong>Feature-Benefit_Separation_Qwen3-32B:</strong><div class="mt-2"><pre style="white-space: pre-wrap; background:#f8f9fa; padding:8px; border-radius:6px;">- **Biases:** 
  - The model may have a bias toward common or well-known product categories, leading to better performance on familiar items and poorer performance on niche or novel products.
  - The model might prioritize grammatical structure over semantic meaning, potentially misclassifying phrases based on syntax rather than the actual intent of the description.
  - The model could be biased toward certain writing styles or formats, such as preferring bullet points over prose, which may not reflect the actual effectiveness of the feature-benefit separation.
- **Task Misalignment Risks:** 
  - The model may focus too narrowly on the presence of subheadings rather than the actual content under those subheadings, leading to an incomplete assessment of feature-benefit separation.
  - The model might evaluate the description based on keyword frequency rather than the clarity and relevance of the feature-benefit distinction, which could result in misleading scores.
  - The model could misinterpret the task by evaluating the overall quality of the product description rather than specifically focusing on the separation of features and benefits.
- **Failure Cases:** 
  - The model may fail to recognize when a feature is described in a way that inherently includes its benefit, such as 'ergonomic design for comfort,' leading to incorrect classification.
  - The model might incorrectly label a benefit as a feature if the description uses technical terms without explanation, such as 'nanotechnology-infused fabric' without clarifying the benefit (e.g., stain resistance).
  - The model could overlook implicit benefits that are not explicitly stated but are understood in context, such as 'durable materials' implying long-term cost savings.</pre></div></li></ul></div></div>
            </div>
          </div>
        </div>
      </div>

      <div class="col-md-6">
        <div class="card p-3 h-100">
          <h2>Compute Requirements</h2>
          <table class="table table-striped"><thead><tr><th>Metric</th><th>GPU RAM (MB)</th><th>CPU RAM (MB)</th></tr></thead>
            <tbody><tr><td>grade_Qwen3-32B_examples</td><td>--</td><td>--</td></tr><tr><td>evalgen_product_grade_Qwen3-32B_optimized_seed42</td><td>--</td><td>--</td></tr><tr><td>GRMRewardModel</td><td>6160.84033203125</td><td>2003.9375</td></tr><tr><td>FKGL</td><td>0.0</td><td>894.08203125</td></tr><tr><td>Feature-Benefit_Separation_Qwen3-32B</td><td>--</td><td>--</td></tr></tbody>
          </table>
        </div>
      </div>
    </div>

    <div class="mt-5 card p-3">
      <h3>Metric Summary</h3>
      <p>The aggregate regression metric evaluates e-commerce product descriptions by balancing structural compliance, SEO effectiveness, and readability. It prioritizes strict adherence to formatting rules (subheadings, 200-300 word limits) and clear feature-benefit separation, as enforced by the example-based LLM judges (grade_Qwen3-32B_examples and evalgen_product_grade). These components ensure SEO optimization and active voice usage while avoiding prohibited elements like links or fabricated reviews. The GRMRewardModel reinforces fluency and user-preference alignment, while the Feature-Benefit_Separation component ensures distinct treatment of product attributes and their value propositions. The negative FKGL coefficient ensures descriptions remain accessible by penalizing complex language. Strengths include consistent formatting and SEO focus, but limitations include potential overfitting to examples, generic phrasing, and readability compromises. The metric is best suited for structured, SEO-driven content but may underperform for creative or niche product categories requiring deeper domain expertise. Overfitting risks and readability trade-offs highlight the need for human review in final outputs.</p>
    </div>

    <div class="mt-4 card p-3">
      <h3>Examples</h3>
      
    </div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
  <script>
    function getThemeLayout() {
      const color = getComputedStyle(document.body).color;
      return { paper_bgcolor: 'rgba(0,0,0,0)', plot_bgcolor: 'rgba(0,0,0,0)', font: { color } };
    }
    document.getElementById('darkModeToggle').addEventListener('change',e=>{document.body.classList.toggle('dark-mode',e.target.checked); drawAll();});
    // Enable tooltips
    const tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]'));
    tooltipTriggerList.map(function (el) {
      const tip = new bootstrap.Tooltip(el, {trigger: 'hover focus', delay: {show: 0, hide: 50}, placement: 'right'});
      el.addEventListener('shown.bs.tooltip', function () {
        try { if (window.MathJax && MathJax.typesetPromise) { MathJax.typesetPromise(); } } catch(_) {}
      });
      return tip;
    });

    // Initialize tooltips; use template content for robustness
    document.addEventListener('DOMContentLoaded', function () {
      document.querySelectorAll('.robust-tip').forEach(function (el) {
        const id = el.getAttribute('data-tip-id');
        let titleHtml = '';
        if (id) {
          const tpl = document.getElementById(id);
          if (tpl) titleHtml = tpl.innerHTML;
        }
        if (!titleHtml) {
          titleHtml = '<div style="max-width: 320px">Robustness tooltip unavailable.</div>';
        }
        const tip = new bootstrap.Tooltip(el, {
          trigger: 'hover focus',
          delay: {show: 0, hide: 50},
          placement: 'right',
          html: true,
          title: titleHtml
        });
        el.addEventListener('shown.bs.tooltip', function () {
          try {
            if (window.MathJax && MathJax.typesetPromise) {
              const tipEl = tip.getTipElement ? tip.getTipElement() : document.querySelector('.tooltip.show');
              if (tipEl) { MathJax.typesetPromise([tipEl]); }
            }
          } catch(_) {}
        });
      });
    });

    function drawCorrelation() {
      const layout = Object.assign({xaxis:{title:'Metric Score (normalized to target scale)'}, yaxis:{title:'Ground Truth'}}, getThemeLayout());
      layout.legend = layout.legend || {}; layout.legend.font = { size: 9 }; layout.margin = {l:40,r:10,t:30,b:40};
      const traces = [];
      if (RC_CORR.metrics) {
        // Determine top 3 metrics by absolute coefficient if available
        let topNames = [];
        try {
          const coeffPairs = ([["grade_Qwen3-32B_examples", 0.09385637595200852], ["evalgen_product_grade_Qwen3-32B_optimized_seed42", 0.09326348061363167], ["GRMRewardModel", 0.06555907661995325], ["Feature-Benefit_Separation_Qwen3-32B", 0.009120800471823606], ["FKGL", -0.0345335775860695], ["(intercept)", 0.475]]);
          const sorted = coeffPairs.filter(p=>p[0] !== '(intercept)').sort((a,b)=>Math.abs(b[1]) - Math.abs(a[1]));
          topNames = sorted.slice(0,3).map(p=>p[0]);
        } catch (e) { topNames = []; }
        for (const m of RC_CORR.metrics) {
          const rlab = (m.r!=null ? (m.r.toFixed ? m.r.toFixed(2) : m.r) : 'NA');
          const tlab = (m.tau!=null ? (m.tau.toFixed ? m.tau.toFixed(2) : m.tau) : 'NA');
          const visible = (topNames.includes(m.name)) ? true : 'legendonly';
          traces.push({ x: m.x_norm || m.x || [], y: m.y || [], mode: 'markers', name: (m.name || '') + ' (r=' + rlab + ', τ=' + tlab + ')', visible });
        }
      }
      if (RC_CORR.regression) {
        const rlab = (RC_CORR.regression.r!=null ? (RC_CORR.regression.r.toFixed ? RC_CORR.regression.r.toFixed(2) : RC_CORR.regression.r) : 'NA');
        const tlab = (RC_CORR.regression.tau!=null ? (RC_CORR.regression.tau.toFixed ? RC_CORR.regression.tau.toFixed(2) : RC_CORR.regression.tau) : 'NA');
        traces.push({ x: RC_CORR.regression.x_norm || RC_CORR.regression.x || [], y: RC_CORR.regression.y || [], mode: 'markers', name: (RC_CORR.regression.name || 'Aggregate') + ' (r=' + rlab + ', τ=' + tlab + ')', marker: { size: 8, color: 'black' } });
        document.getElementById('correlation-stats').innerText = 'Aggregate metric: r=' + rlab + ', τ=' + tlab;
      }
      Plotly.newPlot('correlation-chart', traces, layout, {displayModeBar: false});
    }

    function drawRuntime() {
      const layout = Object.assign({yaxis:{title:'Time per Sample (s)'}}, getThemeLayout());
      const boxes = [];
      if (RC_RUNTIME.per_metric) {
        for (const [name, arr] of Object.entries(RC_RUNTIME.per_metric)) {
          boxes.push({ y: arr, type: 'box', name });
        }
      }
      Plotly.newPlot('runtime-chart', boxes, layout);
      if (RC_RUNTIME.aggregate) {
        const agg = RC_RUNTIME.aggregate;
        var seq = (agg.sequence_mean||0);
        if (typeof seq === 'number' && seq.toFixed) { seq = seq.toFixed(2); }
        var par = (agg.parallel_mean||0);
        if (typeof par === 'number' && par.toFixed) { par = par.toFixed(2); }
        var seqCI = (agg.sequence_ci||0);
        if (typeof seqCI === 'number' && seqCI.toFixed) { seqCI = seqCI.toFixed(2); }
        var parCI = (agg.parallel_ci||0);
        if (typeof parCI === 'number' && parCI.toFixed) { parCI = parCI.toFixed(2); }
        document.getElementById('runtime-info').innerHTML = 'Avg time/sample (sequence): ' + seq + 's ± ' + seqCI + 's' + '<br/>' + 'Avg time/sample (parallel): ' + par + 's ± ' + parCI + 's (95% CI)';
      }
    }

    function drawRobustness() {
      if (!RC_ROB.available || !RC_ROB.scores) {
        document.getElementById('robustness-sens').innerHTML = '<em>Robustness not available.</em>';
        document.getElementById('robustness-stab').innerHTML = '';
        return;
      }
      const names = Object.keys(RC_ROB.scores);
      const sens = names.map(n => (RC_ROB.scores[n] && RC_ROB.scores[n].sensitivity) || 0);
      const stab = names.map(n => (RC_ROB.scores[n] && RC_ROB.scores[n].stability) || 0);
      Plotly.newPlot('robustness-sens', [{x: names, y: sens, type:'bar', name:'Sensitivity'}], Object.assign({yaxis:{title:'Sensitivity'}}, getThemeLayout()));
      Plotly.newPlot('robustness-stab', [{x: names, y: stab, type:'bar', name:'Stability'}], Object.assign({yaxis:{title:'Stability'}}, getThemeLayout()));
    }

    function drawAll() { drawCorrelation(); drawRuntime(); drawRobustness(); }
    drawAll();
  </script>
  <div id="robustness-tip-template" class="d-none">
    <div style="max-width: 360px">
      <strong>What do these mean?</strong><br/><br/>
      <strong>Per-sample pairing</strong>: for each example i, compare the original score to its perturbed score(s). We aggregate per-example deltas (not just differences of means).<br/><br/>
      <strong>Sensitivity</strong> (drop on worse_obvious):
      \[ s_i = \max\!\left(0, rac{y_i^{	ext{orig}} - \overline{y}_i^{	ext{worse}}}{\max\!\left(|y_i^{	ext{orig}}|, arepsilonight)} ight), \quad \overline{s} = rac{1}{N} \sum_i s_i \]
      <br/>
      <strong>Stability</strong> (invariance on same_obvious):
      \[ t_i = \max\!\left(0, 1 - rac{ig| y_i^{	ext{orig}} - \overline{y}_i^{	ext{same}} ig|}{\max\!\left(|y_i^{	ext{orig}}|, arepsilonight)} ight), \quad \overline{t} = rac{1}{N} \sum_i t_i \]
      <br/>
      <em>Interpretation</em>: higher is better for both; 0 means no drop on worse (bad) or large change on neutral (unstable).
    </div>
  </div>
</body>
</html>
