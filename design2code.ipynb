{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec208fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/mryan0/.conda/envs/autometrics/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autometrics.dataset.datasets import Design2Code\n",
    "from autometrics.util.analysis import display_top_5_metrics_by_validation, get_top_metric_by_validation, plot_metric_target_scatterplot\n",
    "from autometrics.aggregator.regression import Ridge\n",
    "from autometrics.generator.LLMJudgeProposer import LLMJudgeProposer\n",
    "import dspy\n",
    "import litellm\n",
    "from tqdm import tqdm\n",
    "\n",
    "litellm.suppress_debug_info = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a00ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_prompt = \"\"\"You are an expert web developer who specializes in HTML and CSS. A user will provide you with a screenshot of a webpage. You need to return a single html file that uses HTML and CSS to reproduce the given website. Include all CSS code in the HTML file itself. If it involves any images, use \"rick.jpg\" as the placeholder. Some images on the webpage are replaced with a blue rectangle as the placeholder, use \"rick.jpg\" for those as well. Do not hallucinate any dependencies to external files. You do not need to include JavaScript scripts for dynamic interactions. Pay attention to things like size, text, position, and color of all the elements, as well as the overall layout. Respond with the content of the HTML+CSS file.\"\"\"\n",
    "\n",
    "task_prompt = design_prompt\n",
    "\n",
    "# %%\n",
    "dataset = Design2Code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b976b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 140 Validation size: 140 Test size: 420\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "train, dev, test = dataset.get_splits(train_ratio=0.2, val_ratio=0.2, seed=42, max_size=1000)\n",
    "\n",
    "print(\"Train size:\", len(train.dataframe), \"Validation size:\", len(dev.dataframe), \"Test size:\", len(test.dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d22cad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>win1</th>\n",
       "      <th>model1</th>\n",
       "      <th>id</th>\n",
       "      <th>html1</th>\n",
       "      <th>ref_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3</td>\n",
       "      <td>gpt4v_text_augmented_prompting</td>\n",
       "      <td>11984.html</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html class=\"\" data-whatinput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>gpt4v_visual_revision_prompting</td>\n",
       "      <td>3004.html</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;\\n&lt;...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n &lt;head&gt;\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0</td>\n",
       "      <td>gemini_visual_revision_prompting</td>\n",
       "      <td>6428.html</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html&gt;\\n&lt;head&gt;\\n&lt;title&gt;Cric...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n &lt;head&gt;\\n  &lt;title&gt;\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3</td>\n",
       "      <td>gemini_visual_revision_prompting</td>\n",
       "      <td>3004.html</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n\\n&lt;html&gt;\\n&lt;head&gt;\\n&lt;title&gt;Jane...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n &lt;head&gt;\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2</td>\n",
       "      <td>design2code-18b-v0</td>\n",
       "      <td>6111.html</td>\n",
       "      <td>&lt;html&gt;\\n&lt;body&gt;\\n    &lt;header&gt;\\n        &lt;nav&gt;\\n ...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html class=\"\" lang=\"en\" styl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     win1                            model1          id  \\\n",
       "170     3    gpt4v_text_augmented_prompting  11984.html   \n",
       "30      5   gpt4v_visual_revision_prompting   3004.html   \n",
       "445     0  gemini_visual_revision_prompting   6428.html   \n",
       "430     3  gemini_visual_revision_prompting   3004.html   \n",
       "544     2                design2code-18b-v0   6111.html   \n",
       "\n",
       "                                                 html1  \\\n",
       "170  <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...   \n",
       "30   <!DOCTYPE html>\\n\\n<html lang=\"en\">\\n<head>\\n<...   \n",
       "445  <!DOCTYPE html>\\n\\n<html>\\n<head>\\n<title>Cric...   \n",
       "430  <!DOCTYPE html>\\n\\n<html>\\n<head>\\n<title>Jane...   \n",
       "544  <html>\\n<body>\\n    <header>\\n        <nav>\\n ...   \n",
       "\n",
       "                                              ref_html  \n",
       "170  <!DOCTYPE html>\\n<html class=\"\" data-whatinput...  \n",
       "30   <!DOCTYPE html>\\n<html lang=\"en\">\\n <head>\\n  ...  \n",
       "445  <!DOCTYPE html>\\n<html>\\n <head>\\n  <title>\\n ...  \n",
       "430  <!DOCTYPE html>\\n<html lang=\"en\">\\n <head>\\n  ...  \n",
       "544  <!DOCTYPE html>\\n<html class=\"\" lang=\"en\" styl...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.model1_dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e22bb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['win1', 'model1', 'id', 'html1', 'ref_html'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.model1_dataset.dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce361bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ref_html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.model1_dataset.get_input_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71b6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "llama33_70b = dspy.LM(\"litellm_proxy/meta-llama/Meta-Llama-3.3-70b-Instruct\", api_base=\"http://future-hgx-1.stanford.edu:7410/v1\", api_key=\"None\")\n",
    "\n",
    "dspy.settings.configure(lm=llama33_70b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2bbf703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autometrics.metrics.reference_based.SARI import SARI\n",
    "\n",
    "train.add_metric(SARI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autometrics.metrics.MetricBank import all_metrics\n",
    "\n",
    "# %%\n",
    "generator = LLMJudgeProposer(train_dataset=train, task_description=task_prompt, proposer_model=llama33_70b, judge_model=llama33_70b)\n",
    "\n",
    "# %%\n",
    "print(llama33_70b.model)\n",
    "\n",
    "for target_column in dataset.target_columns:\n",
    "    train.add_metrics(all_metrics)\n",
    "    dev.add_metrics(all_metrics)\n",
    "    test.add_metrics(all_metrics)\n",
    "\n",
    "df = display_top_5_metrics_by_validation(dev, test, True)\n",
    "print(df)\n",
    "df.to_csv(\"outputs/\" + dataset.name + \"_top_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "new_metrics = all_metrics\n",
    "\n",
    "for target_column in dataset.target_columns:\n",
    "    new_metrics.extend(generator.generate(train, target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c940de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Condense the metrics that have duplicate names\n",
    "new_metrics_names = set()\n",
    "new_metrics_final = []\n",
    "for metric in new_metrics:\n",
    "    if metric.name not in new_metrics_names:\n",
    "        new_metrics_names.add(metric.name)\n",
    "        new_metrics_final.append(metric)\n",
    "\n",
    "# %%\n",
    "train.add_metrics(new_metrics_final)\n",
    "dev.add_metrics(new_metrics_final)\n",
    "test.add_metrics(new_metrics_final)\n",
    "\n",
    "# %%\n",
    "df = display_top_5_metrics_by_validation(dev, test, True)\n",
    "print(df)\n",
    "df.to_csv(\"outputs/\" + dataset.name + \"_top_metrics_dspy.csv\")\n",
    "\n",
    "# %%\n",
    "for target in tqdm(dataset.get_target_columns()):\n",
    "    aggregator = Ridge(dataset=train, name=f'Ridge_{target}_llm')\n",
    "    aggregator.ensure_dependencies(train)\n",
    "    aggregator.ensure_dependencies(dev)\n",
    "    aggregator.ensure_dependencies(test)\n",
    "\n",
    "# %%\n",
    "train.get_metric_columns()\n",
    "\n",
    "# %%\n",
    "for target in tqdm(dataset.get_target_columns()):\n",
    "    aggregator = Ridge(dataset=train, name=f'Ridge_{target}_llm')\n",
    "    aggregator.learn(train, target)\n",
    "    aggregator.predict(train)\n",
    "    aggregator.predict(dev)\n",
    "    aggregator.predict(test)\n",
    "\n",
    "# %%\n",
    "df = display_top_5_metrics_by_validation(dev, test, True)\n",
    "print(df)\n",
    "df.to_csv(\"outputs/\" + dataset.name + \"_top_metrics_dspy_regression.csv\")\n",
    "\n",
    "# all computed values\n",
    "dataset.get_dataframe().to_csv(\"outputs/\" + dataset.name + \"_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
