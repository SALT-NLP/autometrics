{
  "generate_score": {
    "lm": null,
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "Given an input text, the task description that the model was trying to follow, and a metric to rate the text on, return a score from 1-5 on this metric.",
      "fields": [
        {
          "prefix": "Text:",
          "description": "The input text that we want to rate."
        },
        {
          "prefix": "Task Description:",
          "description": "A description of the task that the model was trying to solve when it generated the text.  Could be left blank if not available."
        },
        {
          "prefix": "Metric:",
          "description": "The metric that we want to rate the text on."
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Score:",
          "description": "The score that the text should recieve on this metric (1=low, 5=high)."
        }
      ]
    },
    "extended_signature": {
      "instructions": "Given a text response generated by a chatbot assistant, a task description that outlines the user's query and the expected response, and a metric to evaluate the response on (such as correctness, relevance, or helpfulness), carefully analyze the response and provide a score from 1-5 based on how well the response meets the task description and the specified metric. Consider the clarity, accuracy, and completeness of the response, as well as its overall helpfulness in addressing the user's query. Provide a detailed reasoning for your score, explaining the strengths and weaknesses of the response and how it could be improved. Your goal is to provide a fair and informative evaluation of the chatbot's performance, highlighting areas of strength and weakness and providing actionable feedback for improvement.",
      "fields": [
        {
          "prefix": "Text:",
          "description": "The input text that we want to rate."
        },
        {
          "prefix": "Task Description:",
          "description": "A description of the task that the model was trying to solve when it generated the text.  Could be left blank if not available."
        },
        {
          "prefix": "Metric:",
          "description": "The metric that we want to rate the text on."
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Score:",
          "description": "The score that the text should recieve on this metric (1=low, 5=high)."
        }
      ]
    }
  }
}