{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/auto_eval/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autometrics.dataset.datasets import HelpSteer\n",
    "from autometrics.util.analysis import display_top_5_metrics_by_validation, get_top_metric_by_validation, plot_metric_target_scatterplot\n",
    "from autometrics.aggregator.regression import Ridge\n",
    "from autometrics.generator.LLMJudgeRubricProposer import LLMJudgeRubricProposer\n",
    "import dspy\n",
    "import litellm\n",
    "from prometheus_eval.litellm import LiteLLM\n",
    "\n",
    "litellm.suppress_debug_info = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HelpSteer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = dataset.get_splits(train_ratio=0.2, val_ratio=0.1, seed=42, max_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama31_70b = dspy.LM(\"openai/meta-llama/Meta-Llama-3.1-70b-Instruct\", api_base=\"http://future-hgx-1:7410/v1\", api_key=\"None\")\n",
    "\n",
    "dspy.settings.configure(lm=llama31_70b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama31_70b_litellm = LiteLLM('openai/meta-llama/Meta-Llama-3.1-70b-Instruct', api_base=\"http://future-hgx-1:7410/v1\", api_key='None') # VLLM endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = LLMJudgeRubricProposer(train_dataset=train, task_description=\"Answer the user query as a helpful chatbot assistant.\", proposer_model=llama31_70b, judge_model=llama31_70b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openai/meta-llama/Meta-Llama-3.1-70b-Instruct'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama31_70b.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metrics = []\n",
    "\n",
    "for target_column in dataset.target_columns:\n",
    "    new_metrics.extend(generator.generate(train, target_column, use_prometheus=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condense the metrics that have duplicate names\n",
    "new_metrics_names = set()\n",
    "new_metrics_final = []\n",
    "for metric in new_metrics:\n",
    "    if metric.name not in new_metrics_names:\n",
    "        new_metrics_names.add(metric.name)\n",
    "        new_metrics_final.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Completeness_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_af433 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_af433\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_af433_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_af433_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_af433_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_af433_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_af433_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_af433_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_af433_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_af433_row0_col0\" class=\"data row0 col0\" >Completeness: The extent to which the output provides a thorough and detailed answer to the prompt.</td>\n",
       "      <td id=\"T_af433_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the response is incomplete and lacks essential information. The output may be brief, vague, or fail to address key aspects of the prompt. A response scoring 1 may demonstrate a limited understanding of the topic or may not provide sufficient detail to be considered a complete answer.</td>\n",
       "      <td id=\"T_af433_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the response is partially complete but lacks significant information or clarity. The output may address some aspects of the prompt but omit important details or fail to provide a clear explanation. A response scoring 2 may demonstrate a basic understanding of the topic but may not provide sufficient depth or breadth to be considered a complete answer.</td>\n",
       "      <td id=\"T_af433_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the response is generally complete but may lack some details or clarity. The output may address most aspects of the prompt but may omit some important information or provide a somewhat vague explanation. A response scoring 3 may demonstrate a good understanding of the topic but may not provide sufficient depth or breadth to be considered a comprehensive answer.</td>\n",
       "      <td id=\"T_af433_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the response is mostly complete and provides a good level of detail and clarity. The output may address all aspects of the prompt and provide a clear explanation, but may lack some nuance or depth. A response scoring 4 may demonstrate a strong understanding of the topic and provide a comprehensive answer, but may not be perfect in terms of detail or clarity.</td>\n",
       "      <td id=\"T_af433_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the response is complete, providing a thorough and detailed answer to the prompt. The output addresses all aspects of the question, provides relevant information, and demonstrates a clear and comprehensive understanding of the topic. A response scoring 5 is well-written, clear, and concise, and provides a complete and accurate answer to the prompt.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16a0c66c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Coherence_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c459c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c459c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c459c_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_c459c_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_c459c_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_c459c_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_c459c_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_c459c_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c459c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c459c_row0_col0\" class=\"data row0 col0\" >Coherence: The clarity and logical flow of the output, making it easy to understand.</td>\n",
       "      <td id=\"T_c459c_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the output is incoherent and lacks logical flow. The output may be disjointed, with sentences or paragraphs that do not relate to each other. The language may be ambiguous, making it difficult to understand the intended meaning. The output may also be overly verbose, with unnecessary words or phrases that detract from the overall clarity.</td>\n",
       "      <td id=\"T_c459c_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the output is somewhat incoherent, with some logical flow but also some areas of confusion. The output may be poorly organized, with sentences or paragraphs that do not follow a clear structure. The language may be somewhat ambiguous, with some words or phrases that are unclear. However, the overall meaning of the output may still be discernible with some effort.</td>\n",
       "      <td id=\"T_c459c_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the output is moderately coherent, with a clear structure and logical flow. The output may be well-organized, with sentences or paragraphs that follow a clear and logical sequence. The language may be clear and concise, with few areas of ambiguity. However, the output may still contain some minor errors or areas of confusion.</td>\n",
       "      <td id=\"T_c459c_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the output is highly coherent, with a clear and logical structure. The output may be well-organized, with sentences or paragraphs that follow a clear and logical sequence. The language may be clear and concise, with few areas of ambiguity. The output may also be engaging and easy to read, with a clear and concise writing style.</td>\n",
       "      <td id=\"T_c459c_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the output is exceptionally coherent, with a clear and logical structure that is easy to follow. The output may be extremely well-organized, with sentences or paragraphs that follow a clear and logical sequence. The language may be clear and concise, with no areas of ambiguity. The output may also be engaging and easy to read, with a clear and concise writing style that is free of errors.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x167644290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Relevance_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_25b58 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_25b58\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_25b58_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_25b58_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_25b58_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_25b58_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_25b58_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_25b58_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_25b58_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_25b58_row0_col0\" class=\"data row0 col0\" >Relevance: The ability of the output to stay on topic and address the given prompt.</td>\n",
       "      <td id=\"T_25b58_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the response is completely off-topic and fails to address the input prompt. The response may be unrelated to the subject matter, or it may provide unnecessary information that is not relevant to the prompt.</td>\n",
       "      <td id=\"T_25b58_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the response is somewhat off-topic, but may provide some tangential information that is loosely related to the prompt. The response may be overly verbose or provide unnecessary details that detract from the main topic.</td>\n",
       "      <td id=\"T_25b58_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the response is partially relevant, but may not fully address the input prompt. The response may provide some useful information, but may also include unnecessary details or tangents that detract from the main topic.</td>\n",
       "      <td id=\"T_25b58_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the response is mostly relevant and provides useful information that directly addresses the input prompt. The response may be concise and to the point, but may also include some minor tangents or unnecessary details.</td>\n",
       "      <td id=\"T_25b58_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the response is highly relevant and provides a clear, concise, and direct answer to the input prompt. The response is on-topic, provides useful information, and is free of unnecessary details or tangents.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x167647fb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_53904 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_53904\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_53904_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_53904_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_53904_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_53904_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_53904_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_53904_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_53904_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_53904_row0_col0\" class=\"data row0 col0\" >Contextual understanding: The ability of the output to demonstrate an understanding of the context and background information provided.</td>\n",
       "      <td id=\"T_53904_row0_col1\" class=\"data row0 col1\" >Score 1: The model's output demonstrates little to no understanding of the context. It may provide a generic or irrelevant response that does not take into account the background information provided.</td>\n",
       "      <td id=\"T_53904_row0_col2\" class=\"data row0 col2\" >Score 2: The model's output shows some understanding of the context, but it is limited or superficial. It may identify some relevant information, but fails to recognize relationships between different pieces of information or use the context to inform its response.</td>\n",
       "      <td id=\"T_53904_row0_col3\" class=\"data row0 col3\" >Score 3: The model's output demonstrates a moderate understanding of the context. It may identify relevant information, recognize some relationships between different pieces of information, and use the context to inform its response, but may not fully capture the nuances and implications of the context.</td>\n",
       "      <td id=\"T_53904_row0_col4\" class=\"data row0 col4\" >Score 4: The model's output shows a strong understanding of the context. It identifies relevant information, recognizes relationships between different pieces of information, and uses the context to inform its response. It may also demonstrate an understanding of the nuances and implications of the context, but may not fully capture the subtleties of the topic.</td>\n",
       "      <td id=\"T_53904_row0_col5\" class=\"data row0 col5\" >Score 5: The model's output demonstrates an exceptional understanding of the context. It identifies all relevant information, recognizes complex relationships between different pieces of information, and uses the context to inform its response. It also demonstrates a deep understanding of the nuances and implications of the context, and provides a response that is insightful and informative.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x167646d80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Tone_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_01e55 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_01e55\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_01e55_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_01e55_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_01e55_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_01e55_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_01e55_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_01e55_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_01e55_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_01e55_row0_col0\" class=\"data row0 col0\" >Tone: The level of formality, sincerity, and respect in the output, avoiding sarcasm and glibness.</td>\n",
       "      <td id=\"T_01e55_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the tone is completely off, with a high level of sarcasm, glibness, or disrespect. The output may come across as unhelpful, dismissive, or even rude, making the reader feel uncomfortable or undervalued.</td>\n",
       "      <td id=\"T_01e55_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the tone is somewhat off, with a noticeable level of sarcasm, glibness, or informality. The output may come across as slightly unhelpful or dismissive, but still attempts to provide some level of assistance.</td>\n",
       "      <td id=\"T_01e55_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the tone is neutral, with a moderate level of formality and sincerity. The output is somewhat helpful, but may lack a clear and engaging tone, making it feel somewhat generic or uninteresting.</td>\n",
       "      <td id=\"T_01e55_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the tone is good, with a high level of formality, sincerity, and respect. The output is helpful, engaging, and makes the reader feel valued and comfortable. However, there may be some minor issues with the tone, such as a slight hint of sarcasm or informality.</td>\n",
       "      <td id=\"T_01e55_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the tone is excellent, with a perfect balance of formality, sincerity, and respect. The output is highly engaging, professional, and makes the reader feel comfortable and valued. The tone is polished and refined, with no noticeable issues or areas for improvement.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x167647920>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Engagement_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_88af1 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_88af1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_88af1_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_88af1_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_88af1_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_88af1_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_88af1_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_88af1_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88af1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_88af1_row0_col0\" class=\"data row0 col0\" >**Engagement**: The output's ability to capture the reader's attention, using tone, language, and style to convey enthusiasm and interest in the topic.</td>\n",
       "      <td id=\"T_88af1_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the output lacks engagement, tone, and style. The language is dull, and the content fails to capture the reader's attention. The output may be too formal, too long, or too boring, leading to a lack of interest in the topic.</td>\n",
       "      <td id=\"T_88af1_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the output shows some attempt at engagement, but it falls short. The tone may be somewhat formal, and the language may be somewhat dry. The content may be mildly interesting, but it fails to capture the reader's attention fully. The output may lack variety in sentence structure, vocabulary, or style.</td>\n",
       "      <td id=\"T_88af1_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the output is moderately engaging. The tone is somewhat informal, and the language is clear and concise. The content is somewhat interesting, and the output shows some attempt at using rhetorical devices, such as metaphors or allusions. However, the output may lack depth, and the language may not be particularly vivid or engaging.</td>\n",
       "      <td id=\"T_88af1_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the output is engaging and well-written. The tone is informal and conversational, and the language is vivid and engaging. The content is interesting, and the output shows a good use of rhetorical devices, such as metaphors, allusions, or repetition. The output may use humor, irony, or other literary devices to capture the reader's attention.</td>\n",
       "      <td id=\"T_88af1_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the output is highly engaging and exceptionally well-written. The tone is informal and conversational, and the language is vivid, engaging, and memorable. The content is fascinating, and the output shows a masterful use of rhetorical devices, such as metaphors, allusions, or repetition. The output may use humor, irony, or other literary devices to capture the reader's attention and leave a lasting impression.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1676473b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Accuracy_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e6ebf td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e6ebf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e6ebf_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_e6ebf_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_e6ebf_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_e6ebf_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_e6ebf_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_e6ebf_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e6ebf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e6ebf_row0_col0\" class=\"data row0 col0\" >**Accuracy**: The output's factual correctness, precision, and attention to detail, ensuring that the information provided is reliable.</td>\n",
       "      <td id=\"T_e6ebf_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the output is completely inaccurate, containing numerous factual errors, and lacks attention to detail. The information provided is unreliable and may be misleading.</td>\n",
       "      <td id=\"T_e6ebf_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the output contains some inaccuracies, with a few factual errors and a lack of attention to detail in certain areas. While some information may be correct, the output is not entirely reliable.</td>\n",
       "      <td id=\"T_e6ebf_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the output is partially accurate, with some correct information and some minor errors or inaccuracies. The output shows some attention to detail but may lack precision in certain areas.</td>\n",
       "      <td id=\"T_e6ebf_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the output is mostly accurate, with a high degree of factual correctness and attention to detail. However, there may be some minor errors or inaccuracies that do not significantly impact the overall reliability of the information.</td>\n",
       "      <td id=\"T_e6ebf_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the output is entirely accurate, with a high degree of factual correctness, precision, and attention to detail. The information provided is reliable and trustworthy, with no errors or inaccuracies.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x167644290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bdbc6 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bdbc6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bdbc6_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_bdbc6_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_bdbc6_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_bdbc6_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_bdbc6_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_bdbc6_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bdbc6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bdbc6_row0_col0\" class=\"data row0 col0\" >**Grammar and syntax**: The quality of the grammar and syntax used in the output, with good examples using proper grammar and syntax and bad examples using poor grammar and syntax.</td>\n",
       "      <td id=\"T_bdbc6_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the output contains severe grammatical errors, making it difficult to understand. The output may contain multiple errors in verb tense, subject-verb agreement, pronoun usage, and sentence structure. The errors are so severe that they hinder the reader's ability to comprehend the intended meaning.</td>\n",
       "      <td id=\"T_bdbc6_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the output contains noticeable grammatical errors, but the meaning is still clear. The output may contain errors in verb tense, subject-verb agreement, pronoun usage, and sentence structure, but they do not significantly impede the reader's understanding. The errors are noticeable but do not dominate the text.</td>\n",
       "      <td id=\"T_bdbc6_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the output contains some minor grammatical errors, but the meaning is clear. The output may contain a few errors in verb tense, subject-verb agreement, pronoun usage, and sentence structure, but they do not significantly affect the reader's understanding. The errors are minor and do not detract from the overall quality of the text.</td>\n",
       "      <td id=\"T_bdbc6_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the output contains only a few minor errors, and the meaning is clear. The output may contain a single error or a few very minor errors in verb tense, subject-verb agreement, pronoun usage, and sentence structure, but they do not affect the reader's understanding. The errors are very minor and do not detract from the overall quality of the text.</td>\n",
       "      <td id=\"T_bdbc6_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the output is free of grammatical errors and is well-written. The output demonstrates a strong command of grammar and syntax, with no errors in verb tense, subject-verb agreement, pronoun usage, and sentence structure. The text is clear, concise, and well-organized, making it easy for the reader to understand the intended meaning.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x167647fb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Informative value_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1126e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1126e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1126e_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_1126e_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_1126e_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_1126e_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_1126e_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_1126e_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1126e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1126e_row0_col0\" class=\"data row0 col0\" >**Informative value**: The amount of useful and accurate information provided in the output, with good examples providing detailed and accurate information and bad examples providing incomplete or inaccurate information.</td>\n",
       "      <td id=\"T_1126e_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the output provides little to no useful information. The response may be incomplete, inaccurate, or lack relevant details.</td>\n",
       "      <td id=\"T_1126e_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the output provides some useful information, but it is incomplete or lacks relevant details. The response may be partially accurate, but it does not fully address the task or prompt.</td>\n",
       "      <td id=\"T_1126e_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the output provides some useful information, but it is not entirely accurate or lacks relevant details. The response may be partially complete, but it does not fully address the task or prompt.</td>\n",
       "      <td id=\"T_1126e_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the output provides a good amount of useful and accurate information. The response is mostly complete and addresses the task or prompt, but it may lack some relevant details or have minor inaccuracies.</td>\n",
       "      <td id=\"T_1126e_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the output provides a high amount of useful and accurate information. The response is complete, accurate, and fully addresses the task or prompt, providing all relevant details and information.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16194d1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='text-align: left;'>Conciseness_Meta-Llama-3.1-70b-Instruct_rubric</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c7f68 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c7f68\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c7f68_level0_col0\" class=\"col_heading level0 col0\" >Criteria</th>\n",
       "      <th id=\"T_c7f68_level0_col1\" class=\"col_heading level0 col1\" >Score 1</th>\n",
       "      <th id=\"T_c7f68_level0_col2\" class=\"col_heading level0 col2\" >Score 2</th>\n",
       "      <th id=\"T_c7f68_level0_col3\" class=\"col_heading level0 col3\" >Score 3</th>\n",
       "      <th id=\"T_c7f68_level0_col4\" class=\"col_heading level0 col4\" >Score 4</th>\n",
       "      <th id=\"T_c7f68_level0_col5\" class=\"col_heading level0 col5\" >Score 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c7f68_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c7f68_row0_col0\" class=\"data row0 col0\" >Conciseness: The ability of the model to provide clear and concise responses that directly address the user's query.</td>\n",
       "      <td id=\"T_c7f68_row0_col1\" class=\"data row0 col1\" >A score of 1 indicates that the model's response is overly verbose and fails to effectively communicate the necessary information. The response may contain irrelevant details, repetitive phrases, or unnecessary tangents that detract from the main point.</td>\n",
       "      <td id=\"T_c7f68_row0_col2\" class=\"data row0 col2\" >A score of 2 indicates that the model's response is somewhat concise but still contains some unnecessary information. The response may be slightly wordy or contain a few irrelevant details, but it still manages to convey the main point.</td>\n",
       "      <td id=\"T_c7f68_row0_col3\" class=\"data row0 col3\" >A score of 3 indicates that the model's response is generally concise and effectively communicates the necessary information. The response may contain a few minor flaws, such as a slight redundancy or a brief tangent, but overall, it is clear and to the point.</td>\n",
       "      <td id=\"T_c7f68_row0_col4\" class=\"data row0 col4\" >A score of 4 indicates that the model's response is very concise and effectively communicates the necessary information in a clear and direct manner. The response is well-structured and free of unnecessary words or phrases.</td>\n",
       "      <td id=\"T_c7f68_row0_col5\" class=\"data row0 col5\" >A score of 5 indicates that the model's response is extremely concise and effectively communicates the necessary information in a clear and direct manner. The response is perfectly structured, and every word is essential to conveying the main point.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x167644290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for metric in new_metrics_final:\n",
    "    metric.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1000/1000 [05:59<00:00,  2.79it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [07:22<00:00,  2.26it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [05:01<00:00,  3.31it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [02:14<00:00,  7.42it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [03:20<00:00,  5.00it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [03:51<00:00,  4.33it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [03:54<00:00,  4.27it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [03:47<00:00,  4.40it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [05:40<00:00,  2.94it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [05:30<00:00,  3.02it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [09:16<00:00,  1.80it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [09:27<00:00,  1.76it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [08:48<00:00,  1.89it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [09:40<00:00,  1.72it/s]\n",
      "Processing Items:  63%|██████▎   | 633/1000 [05:57<03:33,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 140: Expected dict_keys(['reasoning', 'score']) but got dict_keys(['reasoning'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1000/1000 [09:02<00:00,  1.84it/s]\n",
      "Processing Items: 100%|██████████| 1000/1000 [10:51<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 720: Expected dict_keys(['reasoning', 'score']) but got dict_keys(['reasoning'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:  60%|█████▉    | 595/1000 [05:42<01:03,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 606/1000 [05:42<00:47,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 623/1000 [05:43<00:29, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▎   | 637/1000 [05:44<00:33, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 660/1000 [05:45<00:18, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 702/1000 [05:46<00:10, 29.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 708/1000 [05:47<00:10, 27.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 717/1000 [05:47<00:13, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 756/1000 [05:48<00:06, 39.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 766/1000 [05:48<00:07, 32.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 774/1000 [05:49<00:07, 32.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 781/1000 [05:49<00:10, 19.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 816/1000 [05:50<00:02, 61.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 827/1000 [05:50<00:04, 35.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▎ | 836/1000 [05:50<00:04, 36.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 843/1000 [05:51<00:05, 27.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 856/1000 [05:53<00:11, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 900/1000 [05:54<00:02, 38.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 917/1000 [05:55<00:03, 22.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 923/1000 [05:55<00:03, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▎| 936/1000 [05:56<00:03, 19.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 963/1000 [05:57<00:01, 32.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 972/1000 [05:57<00:01, 27.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 985/1000 [05:58<00:00, 26.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 990/1000 [05:58<00:00, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 994/1000 [05:59<00:00, 19.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1000/1000 [05:59<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:   0%|          | 1/1000 [00:00<08:28,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 9/1000 [00:01<01:53,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|▏         | 13/1000 [00:01<01:27, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   2%|▏         | 17/1000 [00:03<03:54,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   2%|▏         | 19/1000 [00:04<05:03,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   6%|▌         | 62/1000 [00:04<00:26, 35.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 72/1000 [00:05<00:45, 20.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 84/1000 [00:07<01:07, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 88/1000 [00:07<01:16, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 138/1000 [00:09<00:25, 33.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 151/1000 [00:10<00:37, 22.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 172/1000 [00:13<01:01, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▊        | 187/1000 [00:14<01:13, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 192/1000 [00:16<01:56,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 202/1000 [00:18<01:55,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 204/1000 [00:18<01:58,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 210/1000 [00:19<01:35,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██▏       | 214/1000 [00:22<04:40,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 216/1000 [00:27<13:39,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 273/1000 [00:28<00:42, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 284/1000 [00:30<01:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 294/1000 [00:43<01:10, 10.03it/s]IOStream.flush timed out\n",
      "Processing Items:  30%|██▉       | 297/1000 [00:43<04:40,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 308/1000 [00:43<02:46,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███▏      | 313/1000 [01:51<39:47,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 307: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 311: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 309: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 320/1000 [01:52<24:45,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 323: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 303: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 319: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 329: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 312: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 330: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 324/1000 [01:52<18:18,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 328: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 333: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 321: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 290: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 317: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 332: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 335: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 334: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 288: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 286: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 314: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 302: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 334/1000 [01:52<09:29,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 325: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 298: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 308: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 341: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 339/1000 [03:01<44:44,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 336: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 340: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 342/1000 [03:01<34:14,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 339: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 338: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 342: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 343: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▍      | 348/1000 [03:01<18:57,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 345: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 346: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 348: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 337: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 344: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 351/1000 [03:01<13:56,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 347: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 349: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 350: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 352/1000 [04:09<1:37:03,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 356: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 351: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 352: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 355/1000 [04:10<1:04:55,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 366: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 360: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 370: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 357: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 363: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 371/1000 [04:10<12:09,  1.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 362: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 355: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 361: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 358: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 364: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 369: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 375: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 353: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 365: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 354: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 359: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 368: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 372: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 367: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 373: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 374: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 371: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 377/1000 [05:18<47:53,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 378: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 376: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 377: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 384/1000 [05:18<27:54,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 380: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 383: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 381: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 379: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 385: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 386: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 393/1000 [05:18<13:20,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 389: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 387: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 382: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 391: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 396: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 384: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 394: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 388: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 392: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 397/1000 [05:18<09:44,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 393: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 395: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 390: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 398: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 397: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 400/1000 [05:19<07:45,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 399: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 400: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 404/1000 [06:27<53:14,  5.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 401: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 402: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 403: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 406: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 410/1000 [06:27<25:51,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 408: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 407: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 404: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 405: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 409: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 410: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████▏     | 413/1000 [06:28<18:23,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 413: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 412: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 411: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 415/1000 [06:28<14:22,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 414: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 416/1000 [07:35<1:43:00, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 416: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 420/1000 [07:36<50:40,  5.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 415: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 417: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 418: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 419: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 423/1000 [07:36<31:52,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 422: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 420: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 426: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 421: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 432: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 428: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 434/1000 [07:36<08:18,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 431: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 430: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 429: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 437: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 434: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 424: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 436: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 425: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 438: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 423: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 433: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 427: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 435: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 439: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 442/1000 [08:44<43:11,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 441: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 442: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 440: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 443: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 449/1000 [08:44<20:26,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 445: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 446: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 444: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 448: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 450: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 451: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 447: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 449: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 455: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 461/1000 [08:45<07:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 458: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 452: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 454: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 456: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 453: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 459: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 460: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 461: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 457: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 462: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 463: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▋     | 465/1000 [08:45<05:40,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 464: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 468/1000 [09:53<45:30,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 465: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 467: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 468: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 466: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 469: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 474: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 472/1000 [09:53<29:04,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 470: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 472: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 471: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 473: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 477/1000 [09:54<16:51,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 477: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 476: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 475: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 478: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 480/1000 [11:02<1:12:13,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 479: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 496/1000 [11:03<16:33,  1.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 486: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 482: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 492: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 483: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 481: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 490: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 484: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 480: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 489: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 488: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 494: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 496: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 487: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 491: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 485: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 493: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 499: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 502: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 498: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 495: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 501: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 497: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 503/1000 [11:03<11:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 503: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 500: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 505/1000 [12:10<42:20,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 504: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 506/1000 [12:10<39:06,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 505: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 506: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 507: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 508: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 514/1000 [12:11<18:43,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 510: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 509: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 512: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 511: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 515: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 523/1000 [12:11<08:24,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 513: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 514: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 519: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 516: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 522: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 525: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 517: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 518: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 521: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 520: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 524: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 523: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 527/1000 [12:11<06:09,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 526: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 527: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 528: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 532/1000 [13:20<37:58,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 530: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 529: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 533: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 534: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 532: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▎    | 535/1000 [13:20<27:11,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 536: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 531: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 535: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 540/1000 [13:21<15:40,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 541: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 540: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 542: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 538: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 539: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 537: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 544/1000 [14:28<58:15,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 543: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 548/1000 [14:29<34:15,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 548: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 556: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 550: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 554: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 545: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 544: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 562: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 553: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 555: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 549: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 560/1000 [14:29<10:15,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 546: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 560: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 564: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 551: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 547: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 561: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 559: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 557: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 566: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 567: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 552: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 563: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 558: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 565: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 570/1000 [15:36<28:31,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 568: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 571: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 569: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 570: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 577/1000 [15:37<15:16,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 578: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 574: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 573: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 577: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 579: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 591/1000 [15:37<05:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 575: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 584: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 572: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 580: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 576: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 586: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 587: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 582: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 588: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 583: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 589: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 581: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 585: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 590: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 591: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 592: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 594/1000 [16:46<33:54,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 593: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 596: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 599/1000 [16:46<21:25,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 595: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 597: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 594: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 599: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 598: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 600: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 605/1000 [16:47<11:39,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 601: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 602: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 605: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 606: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 603: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 604: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 608/1000 [17:55<49:38,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 607: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 617/1000 [17:55<18:33,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 621: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 610: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 608: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 618: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 609: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 619: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 613: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 622: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 612: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 611: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 615: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 614: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 617: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 616: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 626/1000 [17:56<09:28,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 623: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 628: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 630: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 629: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 620: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 627: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 625: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 631: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 624: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 626: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 633/1000 [19:02<26:22,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 632: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 634/1000 [19:03<24:40,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 633: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 634: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 635: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 638/1000 [19:03<17:57,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 639: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 636: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 637: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 643/1000 [19:04<11:24,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 640: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 652: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 649: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 653: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 651: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 642: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 641: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 643: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 646: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 644: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 650: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 638: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 645: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 648: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 647: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 654: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 656/1000 [19:05<04:21,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 655: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 656: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 658/1000 [20:12<26:58,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 657: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 658: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 661/1000 [20:12<20:13,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 659: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 661: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 662: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 660: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 663: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▋   | 665/1000 [20:13<13:10,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 664: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 667/1000 [20:13<10:51,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 665: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 668: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 666: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 670: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 670/1000 [20:13<07:36,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 669: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 667: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 672/1000 [21:21<46:43,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 671: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 678/1000 [21:22<20:25,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 675: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 672: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 674: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 683: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 679: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 676: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 688: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 673: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 684/1000 [21:22<09:04,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 682: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 680: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 692: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 693: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 681: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 690: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 687: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 678: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 689: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 685: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 686: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 684: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 695: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 677: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 694: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 691: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 697/1000 [22:29<20:45,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 696: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 697: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 699/1000 [22:29<17:58,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 698: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 699: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 703/1000 [22:30<12:18,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 700: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 701: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 702: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 703: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 708/1000 [22:30<06:43,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 708: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 706: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 718: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 707: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 715: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 704: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 716: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 717: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 711: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 714: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 713: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 709: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 718/1000 [22:30<02:40,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 705: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 712: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 710: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 719: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 721/1000 [22:31<02:22,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 720: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 722/1000 [23:38<29:41,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 721: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 726/1000 [23:39<17:43,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 722: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 723: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 724: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 727: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 728: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 725: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 729/1000 [23:39<12:01,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 726: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 731/1000 [23:39<09:29,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 729: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 733: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 730: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 731: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 734/1000 [23:40<06:22,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 734: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 732: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▎  | 736/1000 [24:47<40:30,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 735: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 739/1000 [24:48<24:28,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 736: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 739: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 738: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 737: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 742/1000 [24:48<14:56,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 740: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 741: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 752/1000 [24:48<04:11,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 742: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 758: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 747: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 744: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 756: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 752: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 746: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 757: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 748: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 759: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 743: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 745: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 749: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 751: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 750: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 758/1000 [24:49<02:31,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 754: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 755: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 753: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 761/1000 [25:55<21:20,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 760: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 761: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 763/1000 [25:55<17:35,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 763: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 762: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 766/1000 [25:56<12:49,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 764: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 765: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 766: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 773/1000 [25:56<05:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 769: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 767: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 770: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 768: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 774: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 771: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 775: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 776/1000 [25:56<04:15,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 777: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 779: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 779/1000 [25:57<03:13,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 772: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 776: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 782: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 773: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 778: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 780: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 781: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 783: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 784/1000 [25:57<01:58,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 784: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▊  | 786/1000 [27:05<23:48,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 785: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▊  | 787/1000 [27:05<21:03,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 787: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 786: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 789/1000 [27:05<15:50,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 790: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 792: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 788: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 789: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 791: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 794/1000 [27:06<08:16,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 793: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 795: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 794: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 797/1000 [27:06<05:54,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 798: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 796: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 797: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 800/1000 [28:13<25:57,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 799: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 804/1000 [28:15<15:01,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 803: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 802: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 805: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 801: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 815: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 804: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 807/1000 [28:15<09:59,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 806: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 800: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 810: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 811/1000 [28:15<05:45,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 820: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 811: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 808: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 814: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 812: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 807: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 809: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 817: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 822: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 816: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 819: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 813: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 823: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 818: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 821: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▎ | 825/1000 [29:22<11:24,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 825: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 824: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 826: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 828/1000 [29:22<09:14,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 827: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 828: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 832/1000 [29:22<06:28,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 830: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 829: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 832: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 834/1000 [29:23<05:09,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 833: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 835: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 834: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 839/1000 [29:23<02:44,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 831: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 838: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 840: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 836: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 837: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 839: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 847/1000 [29:24<01:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 844: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 841: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 842: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 843: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 846: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 845: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 849/1000 [29:24<00:56,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 848: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 847: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 850/1000 [30:31<21:34,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 849: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 850: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 852/1000 [30:32<15:51,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 851: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 859/1000 [30:32<05:41,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 856: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 857: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 852: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 854: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 855: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 853: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 859: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 858: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 862/1000 [30:32<03:58,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 862: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 861: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 860: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▋ | 864/1000 [31:40<19:53,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 863: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▋ | 865/1000 [31:41<17:22,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 864: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 865: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 869/1000 [31:42<08:50,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 866: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 871: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 869: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 870: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 873: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 868: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 876/1000 [31:42<03:11,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 867: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 876: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 881: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 878: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 878/1000 [31:42<02:28,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 887: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 885: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 880: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 877: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 879: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 874: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 884: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 882: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 872: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 875: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 883: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 886: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 889/1000 [32:48<07:59,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 889: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 890: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 888: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 892/1000 [32:48<06:14,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 891: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 892: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 898/1000 [32:49<03:26,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 893: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 897: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 894: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 895: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 896: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 903/1000 [32:49<01:58,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 902: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 898: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 899: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 900: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 903: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 901: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 904: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 906/1000 [32:50<01:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 909: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 910: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 905: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 909/1000 [32:50<01:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 907: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 906: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 911/1000 [32:50<00:49,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 912: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 911: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 908: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████▏| 914/1000 [33:58<10:44,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 914: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 913: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 917/1000 [33:58<06:55,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 915: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 920: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 916: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 921/1000 [33:58<03:39,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 917: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 918: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 921: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 923: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 922: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 919: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▎| 925/1000 [33:59<02:08,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 924: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 925: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 927/1000 [33:59<01:40,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 926: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 928/1000 [35:06<12:17, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 927: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 929/1000 [35:07<10:21,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 928: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 929: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 932/1000 [35:08<05:39,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 930: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 931: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 932: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 935: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 934: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 938/1000 [35:08<01:52,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 936: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 933: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 938: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 945/1000 [35:08<00:37,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 943: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 944: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 940: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 937: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 939: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 950: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 941: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 949: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 946: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 947: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 952/1000 [35:09<00:15,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 951: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 948: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 945: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 942: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 953/1000 [36:14<06:17,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 953: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 952: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 954: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 956/1000 [36:15<03:56,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 956: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 955: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 959/1000 [36:15<02:30,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 960: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 961: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 957: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 959: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 958: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 970/1000 [36:16<00:36,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 967: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 963: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 965: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 964: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 966: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 968: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 962: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 970: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 969: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 971: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 976/1000 [36:17<00:17,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 973: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 972: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 976: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 974: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 975: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 978/1000 [37:24<02:34,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 978: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 979/1000 [37:24<02:10,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 977: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 979: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 989/1000 [37:25<00:21,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 982: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 984: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 985: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 981: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 987: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 980: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 986: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 983: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 988: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 990: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 989: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 992/1000 [38:39<00:59,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 991: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 993/1000 [38:40<00:47,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 992: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 993: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|█████████▉| 995/1000 [38:41<00:26,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 995: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 994: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1000/1000 [38:41<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 999: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 998: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 996: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 997: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:   0%|          | 5/1000 [03:45<9:16:28, 33.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 4: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 0: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 2: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 6: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 5: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 9/1000 [03:45<4:10:31, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 8: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 3: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 15: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 13: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 18: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 17: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 12: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   3%|▎         | 27/1000 [03:45<35:25,  2.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 11: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 7: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 9: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 21: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 14: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 16: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 20: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 27: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 32: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 10: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 30: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 23: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 22: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 24: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 25: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▎         | 35/1000 [03:45<21:19,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 19: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 36: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 28: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 26: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 29: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 31: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 34: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 46: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 35: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▍         | 48/1000 [03:46<10:12,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 33: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 45: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 37: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 41: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 52: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 38: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 39: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 44: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 48: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 54: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 42: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 40: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 49: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 50: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 56: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 43: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 53: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 47: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   6%|▌         | 56/1000 [03:46<06:36,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 60: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 59: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 55: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 62: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 51: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 57: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 58: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 61: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   6%|▋         | 63/1000 [03:46<04:40,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 63: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 69/1000 [07:31<2:30:48,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 66: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 65: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 64: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 71: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 67: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 72: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 68: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 74/1000 [07:31<1:44:54,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 73: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 69: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 75: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 70: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 78: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 86: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 81: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 79/1000 [07:32<1:13:14,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 79: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 89/1000 [07:33<33:15,  2.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 76: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 82: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 80: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 74: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 77: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 85: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 90: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 88: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 94: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 87: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 92/1000 [07:33<25:02,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 84: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 91: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 96: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 97: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 95: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 93: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 83: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 111: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 100: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 126: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 105: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 99: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 102: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 107: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 125: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 104: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 119: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 117: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 112: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 120: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 89: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 113: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 101: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 103: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 122: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 124: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 106: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 127: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 116: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 109: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 114: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 123: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 98: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 115: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 92: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 110: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 118: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 108: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 121: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 132/1000 [11:17<1:09:24,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 128: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 131: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 132: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 129: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 130: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▎        | 135/1000 [11:18<1:01:40,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 133: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 137: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 139: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 134: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 138: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 135: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 143/1000 [11:18<41:17,  2.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 136: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 144: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 142: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 143: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 140: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 141: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 147/1000 [11:18<32:06,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 146: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 145: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 154/1000 [11:19<19:07,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 148: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 150: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 147: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 158: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 152: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 151: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 157: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 160: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 161: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 161/1000 [11:19<10:33,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 149: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 155: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 154: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 166: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 153: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 168/1000 [11:19<05:42,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 165: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 169: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 173: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 159: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 179: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 167: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 162: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 179/1000 [11:19<02:17,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 176: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 163: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 172: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 187: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 156: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 171: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 175: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 180: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 181: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 164: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 185: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 183: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 168: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 189/1000 [11:19<01:16, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 184: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 174: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 189: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 170: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 178: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 182: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 186: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 190: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 188: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 177: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 191: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 193/1000 [15:04<2:39:46, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 193: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 192: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 194: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 201/1000 [15:04<1:29:58,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 195: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 196: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 199: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 201: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 197: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 198: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 200: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 206/1000 [15:04<1:02:25,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 203: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 202: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 205: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 204: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 206: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 207: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 209: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 208: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 211/1000 [15:04<43:30,  3.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 210: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 218/1000 [15:05<25:26,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 212: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 214: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 213: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 215: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 218: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 216: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 211: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 221/1000 [15:05<19:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 219: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 217: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 223: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 220: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 221: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 222: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 227/1000 [15:05<11:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 224: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 227: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 226: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 228: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 229: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 231/1000 [15:05<07:23,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 225: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 230: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 231: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 234: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 232: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 237: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 239/1000 [15:06<03:36,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 240: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 241: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 250: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 247: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 242/1000 [15:06<02:55,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 253: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 244: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 233: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 239: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 251: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 248: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 242: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 238: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 245: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 243: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 235: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 254: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 252: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 249: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 236: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 246: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 255: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 259/1000 [18:50<1:46:45,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 256: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 257: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 258: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 262/1000 [18:50<1:26:20,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 259: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 260: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 262: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▋       | 265/1000 [18:50<1:07:45,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 268: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 264: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 263: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 265: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 261: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 266: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 272: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 270: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 275/1000 [18:51<30:44,  2.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 267: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 273: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 269: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 271: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 274: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 282/1000 [18:51<16:58,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 277: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 276: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 279: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 275: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 281: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 280: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 282: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 278: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 285/1000 [18:51<12:56,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 283: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 284: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 286: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 291/1000 [18:52<07:14,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 287: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 285: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 288: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 291: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 289: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 290: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 294/1000 [18:52<05:25,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 292: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 293: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 295: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 294: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 296: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 303/1000 [18:52<02:25,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 297: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 299: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 300: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 298: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 301: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 304: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 302: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 303: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 306: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 313: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 315/1000 [18:52<01:01, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 315: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 312: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 314: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 316: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 311: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 305: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 308: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 309: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 318: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 310: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 307: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 319: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 320/1000 [18:52<00:49, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 317: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 322/1000 [22:36<2:58:37, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 320: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 321: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 322: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 324: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 323: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 331/1000 [22:37<1:08:05,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 327: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 325: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 329: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 326: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 328: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 330: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 334: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 339/1000 [22:37<32:18,  2.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 332: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 331: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 337: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 338: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 333: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 336: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 335: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 343/1000 [22:37<22:38,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 339: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 341: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 340: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 346: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 343: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 345: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 350/1000 [22:38<11:58,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 344: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 342: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 348: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 352: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 347: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 354/1000 [22:38<08:11,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 351: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 349: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 354: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 350: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 353: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 355: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 361/1000 [22:38<04:22,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 357: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 361: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 356: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 360: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 358: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 359: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 369/1000 [22:38<02:11,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 366: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 362: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 364: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 370: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 369: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 367: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 365: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 363: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 368: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 379/1000 [22:39<00:59, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 372: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 381: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 378: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 374: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 379: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 382: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 371: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 377: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 376: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 373: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 383: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 375: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 380: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 388/1000 [26:23<1:49:07, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 384: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 385: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 387: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 386: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 392/1000 [26:23<1:18:17,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 388: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 389: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 393: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 391: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 390: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 394: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 396/1000 [26:23<55:39,  5.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 395: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 392: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 396: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 401: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 403/1000 [26:24<30:04,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 399: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 397: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 398: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 400: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 402: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 406/1000 [26:24<22:28,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 404: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 403: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 406: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 409: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 408: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 409/1000 [26:24<16:33,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 405: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 407: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 412/1000 [26:24<12:09,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 417: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 410: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 415: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 414: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 418: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 413: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 412: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 411: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 419/1000 [26:24<06:23,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 416: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 419: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 420: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 426/1000 [26:25<03:40,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 424: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 421: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 423: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 422: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 429: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 425: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 426: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 428: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 427: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▎     | 436/1000 [26:25<01:40,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 431: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 435: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 432: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 434: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 440: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 439: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 430: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 433: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 438: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 441: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 444: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 447/1000 [26:25<00:52, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 436: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 443: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 437: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 445: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 446: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 447: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 442: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 450/1000 [30:09<2:17:18, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 449: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 450: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 448: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 456/1000 [30:09<1:08:29,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 451: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 452: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 453: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 454: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 456: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 455: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 462/1000 [30:10<33:48,  3.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 459: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 458: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 460: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 457: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 461: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 462: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 464: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 468/1000 [30:10<16:42,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 465: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 463: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 467: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 466: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 471/1000 [30:10<11:53,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 468: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 469: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 471: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 472: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 470: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 479/1000 [30:10<04:58,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 474: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 479: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 473: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 477: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 475: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 480: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 476: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 478: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 483/1000 [30:11<03:26,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 483: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 481: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 482: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 484: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 489/1000 [30:11<02:04,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 485: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 489: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 487: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 486: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 490: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 488: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 493: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 496/1000 [30:11<01:09,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 491: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 495: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 496: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 498: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 492: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 499: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 509/1000 [30:11<00:29, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 501: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 505: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 494: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 500: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 506: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 503: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 504: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 497: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 502: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 507: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 510: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 511: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 509: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 508: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 515/1000 [33:55<1:40:03, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 513: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 512: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 514: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 519/1000 [33:56<1:08:36,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 517: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 516: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 515: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 519: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 518: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 520: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 526/1000 [33:56<34:36,  4.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 521: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 523: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 524: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 522: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 525: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 528: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 526: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 530/1000 [33:56<23:35,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 527: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 530: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 529: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 531: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▎    | 536/1000 [33:56<12:58,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 533: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 532: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 534: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 536: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 535: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 542/1000 [33:57<06:51,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 537: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 538: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 539: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 546: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 541: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 542: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 545: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 543: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 548/1000 [33:57<03:50,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 540: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 544: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 547: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 548: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 551/1000 [33:57<03:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 552: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 549: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 550: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 553: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 551: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 554/1000 [33:57<02:22,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 556: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 560: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 557: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 558: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 559/1000 [34:00<02:44,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 555: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 554: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 574: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 564: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 565: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 562: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 559: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 566: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 573: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 561: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 567: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 572: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 570: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 575: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 571: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 569: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 563: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 568: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 579/1000 [37:42<52:35,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 576: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 578: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 577: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 581/1000 [37:42<46:08,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 580: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 581: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 579: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 585/1000 [37:42<32:27,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 582: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 583: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 584: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 586: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 585: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 592/1000 [37:42<15:31,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 587: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 588: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 589: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 594: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 591: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 590: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 592: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 593: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 599/1000 [37:43<07:47,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 596: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 597: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 595: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 598: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 602/1000 [37:43<05:44,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 599: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 600: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 602: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 601: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 606/1000 [37:44<03:57,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 606: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 608: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 605: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 604: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 609: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 603: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 607: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 610: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 612: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 611: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 614: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 613: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 616: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 615: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 617: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 619/1000 [37:44<01:19,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 618: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 622/1000 [37:46<01:51,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 619: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 628: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 623: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▎   | 636/1000 [37:46<00:45,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 625: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 638: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 624: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 622: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 626: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 634: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 621: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 627: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 631: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 637: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 635: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 632: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 630: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 629: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 639: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 636: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 633: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 620: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 642/1000 [41:28<1:04:05, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 640: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 641: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 644: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 642: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 643: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 650/1000 [41:28<32:14,  5.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 646: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 647: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 645: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 648: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 649: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 650: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 653/1000 [41:29<24:36,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 656: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 654: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 658/1000 [41:30<15:02,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 658: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 657: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 651: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 653: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 659: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 660: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 655: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 661: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 663: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 665: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 662: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 664: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 652: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 666: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 668/1000 [41:30<06:11,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 668: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 669: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 674: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 674/1000 [41:31<04:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 667: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 672: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 670: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 680: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 673: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 676: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 671: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 679: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 675: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 678: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 677: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 682: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 683/1000 [41:31<02:03,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 681: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▊   | 686/1000 [41:32<02:10,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 683: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 686: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 685: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 684: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 694/1000 [41:33<01:09,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 687: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 692: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 691: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 697: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 689: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 695: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 688: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 690: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 696: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 701: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 698/1000 [41:33<00:52,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 699: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 693: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 700: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 694: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 698: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 702: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 704/1000 [41:33<00:38,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 703: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 705/1000 [45:14<1:28:24, 17.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 704: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████▏  | 713/1000 [45:15<33:01,  6.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 705: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 710: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 707: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 708: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 711: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 706: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 712: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 709: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 713: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 714: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 718/1000 [45:16<18:46,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 717: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 722: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 715: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 723: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 718: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 724/1000 [45:16<08:53,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 719: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 716: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 721: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 720: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 727: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 729: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 730/1000 [45:16<04:18,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 726: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 728: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 725: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 732: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 730: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 731: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 724: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▎  | 736/1000 [45:17<02:19,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 737: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 734: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 736: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 740: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 738: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 733: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 743/1000 [45:17<01:07,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 744: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 739: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 735: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 742: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 741: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 745: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 747/1000 [45:17<00:46,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 746: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 743: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 748: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 754/1000 [45:19<00:49,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 749: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 750: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 747: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 751: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 754: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 760: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 758/1000 [45:19<00:37,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 766: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 763: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 765: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 752: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 761: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 759: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 755: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 756: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 762: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 757: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 753: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 764: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 766/1000 [45:19<00:18, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 758: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 767: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 769/1000 [49:00<1:05:15, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 768: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 773/1000 [49:01<40:54, 10.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 771: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 772: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 774: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 777: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 769: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 778: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 775: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 777/1000 [49:01<25:42,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 776: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 770: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 773: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 783/1000 [49:03<13:12,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 785: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 787: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 783: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 781: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 784: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 789: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 786: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 790/1000 [49:04<05:47,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 788: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 782: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 795: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 792: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 779: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 780: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 790: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 797: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 791: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 793: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 794: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 796: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 800: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 801: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 805: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 799: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 806: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 798: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 802: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 803: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 804: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 807: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 808: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 810: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 809: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 817/1000 [49:05<00:59,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 815: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 811: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 816: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 812: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 813: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 814: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 818: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 821: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 817: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 831/1000 [49:06<00:27,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 831: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 823: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 822: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 826: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 828: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 825: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 827: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 819: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 830: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 824: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 820: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 829: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 833/1000 [52:47<49:08, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 832: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 839/1000 [52:48<24:47,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 835: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 834: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 841: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 836: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 833: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 837: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 838: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 840: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 842/1000 [52:48<17:54,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 842: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 839: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 845/1000 [52:49<12:58,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 844: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 843: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 851/1000 [52:49<06:18,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 852: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 849: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 845: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 854: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 846: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 858: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 856/1000 [52:50<03:22,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 857: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 847: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 860: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 848: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 850: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 851: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 853: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 855: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 862/1000 [52:50<01:44,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 859: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 856: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 862: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 861: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 868/1000 [52:50<00:57,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 863: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 864: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 866: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 865: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 868: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 870: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 875/1000 [52:50<00:28,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 871: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 874: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 869: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 873: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 867: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 872: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 878/1000 [52:52<00:32,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 880: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 875: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 878: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 877: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 876: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 881/1000 [52:52<00:24,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 879: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 881: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 883/1000 [52:52<00:25,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 882: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 883: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 888/1000 [52:53<00:17,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 894: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 888: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 892: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 886: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 893/1000 [52:53<00:10,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 890: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 895: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 885: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 884: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 891: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 889: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 893: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 887: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 897/1000 [56:33<37:56, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 896: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 902/1000 [56:34<18:32, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 897: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 903: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 899: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 902: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 901: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 904: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 898: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 906/1000 [56:34<11:10,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 900: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 906: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 905: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 909/1000 [56:35<07:51,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 907: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 908: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████▏| 913/1000 [56:36<04:35,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 914: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 910: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 909: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 911: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 913: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 918/1000 [56:36<02:10,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 915: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 912: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 918: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 919: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 922/1000 [56:37<01:11,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 922: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 923: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 924: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 920: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 924/1000 [56:37<00:56,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 921: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 916: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 917: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 926: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 927: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 925: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 930: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 928: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 929: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 937: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 931: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 934: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 935: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 932: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 933: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 936: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 938: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 940/1000 [56:38<00:12,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 939: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 941: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 944/1000 [56:38<00:10,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 942: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 940: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 943: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 945: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 944: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 949/1000 [56:39<00:08,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 946: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 947: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 948: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 949: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 951/1000 [56:39<00:07,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 950: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 957: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 959/1000 [56:39<00:03, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 959: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 955: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 952: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 956: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 951: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 953: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 954: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 958: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 961/1000 [1:00:20<13:42, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 960: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 964/1000 [1:00:21<08:20, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 963: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 961: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 962: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 968: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 966: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 971/1000 [1:00:21<02:36,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 969: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 964: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 965: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 967: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 970: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 971: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 972: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 974/1000 [1:00:22<01:41,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 974: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 973: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 975: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 980/1000 [1:00:22<00:38,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 976: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 977: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 978: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 979: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 982/1000 [1:00:23<00:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 981: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 980: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 983: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▊| 987/1000 [1:00:23<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 988: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 984: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 982: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 987: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 993/1000 [1:00:23<00:02,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 986: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 992: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 985: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 991: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 989: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 998: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1000/1000 [1:00:24<00:00,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 996: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 999: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 997: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 993: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 990: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 994: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 995: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:   0%|          | 1/1000 [03:46<62:42:56, 226.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 9: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 0: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 4: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 7/1000 [03:46<5:22:39, 19.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 22: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 32: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 14: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   6%|▌         | 58/1000 [03:46<15:58,  1.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 13: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 26: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 47: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 29: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 11: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 8: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 25: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 3: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 31: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 21: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 12: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 6: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 39: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 18: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 35: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 48: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 10: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 23: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 38: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 49: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 34: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 17: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 36: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 42: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 7: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 30: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 28: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 20: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 15: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 33: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 37: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 52: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 60: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 43: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 2: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 5: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 45: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 61: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 44: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 57: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 46: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 53: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 54: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 51: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 55: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 56: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 16: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 19: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 58: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 63: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 40: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 27: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 41: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 62: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 59: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 50: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 24: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   6%|▋         | 65/1000 [07:32<1:32:14,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 65: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 64: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 66: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 68: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 69/1000 [07:33<1:21:32,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 67: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 120: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 111: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 82: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 110/1000 [07:34<24:50,  1.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 115: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 103: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 127: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 116: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 118: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 112: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 89: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 73: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 76: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 105: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 101: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 83: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 125: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 122: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 75: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 97: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 102: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 104: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 124: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 96: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 117: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 94: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 85: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 81: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 80: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 86: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 109: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 79: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 95: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 92: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 99: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 114: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 71: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 91: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 100: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 87: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 98: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 70: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 120/1000 [07:34<19:30,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 119: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 74: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 78: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 107: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 110: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 126: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 121: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 72: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 106: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 84: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 123: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 77: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 113: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 90: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 69: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 108: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 88: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 93: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 131/1000 [11:19<1:25:41,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 130: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 129: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 128: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 131: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 132: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 134: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 133: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 135: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 139/1000 [11:20<1:02:56,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 144: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 157: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 136: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 158: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 145: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 150: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 151/1000 [11:20<36:56,  2.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 143: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 140: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 147: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 152: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 148: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 162: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 142: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 138: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 165: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 161: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 149: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 146: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 139: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 151: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 167: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 137: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 169/1000 [11:21<15:01,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 175: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 159: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 141: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 186: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 190: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 183: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 163: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 189: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 154: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 176: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 153: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 168: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 177: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 169: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 178: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 173: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 174: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 188: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 160: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 172: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 191: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 164: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 155: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 156: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 166: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 187: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 170: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 184: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 180: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 171: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 181: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 185: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 179: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 182: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 193/1000 [15:05<1:23:35,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 194: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 193: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 195: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 192: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 196: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 198/1000 [15:06<1:10:14,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 197: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 199: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 198: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 202/1000 [15:06<59:37,  4.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 200: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 204: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 205/1000 [15:06<51:13,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 203: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 205: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 201: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 202: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 207: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 215: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 206: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 208: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 209: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 215/1000 [15:07<28:37,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 211: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 217: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 210: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 218: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 220: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 221: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 214: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 212: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 213: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 216: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 227: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 227/1000 [15:07<13:58,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 228: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 223: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 229: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 230: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 225: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 237: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 219: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 255: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 232: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 246/1000 [15:07<04:47,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 224: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 231: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 252: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 226: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 240: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 234: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 235: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 254: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 222: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 244: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 246: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 242: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 239: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 251: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 245: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 249: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 243: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 241: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 250: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 233: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 236: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 247: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 238: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 253: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 248: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 261/1000 [18:52<1:20:38,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 259: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 257: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 256: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 260: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 258: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 261: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 262: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 263: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 265: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 264: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 272/1000 [18:53<45:35,  3.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 267: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 266: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 268: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 269: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 273: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 271: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 272: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 282/1000 [18:53<24:32,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 274: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 270: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 281: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 275: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 282: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 283: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 285: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 277: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 276: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 280: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▊       | 287/1000 [18:53<17:54,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 278: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 279: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 284: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 286: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 289: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 290: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 300/1000 [18:53<07:46,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 287: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 302: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 288: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 294: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 292: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 300: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 314: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 310: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 298: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 293: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 291: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 311: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 305: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 297: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 312: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 319/1000 [18:54<02:55,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 295: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 304: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 299: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 296: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 313: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 315: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 319: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 301: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 309: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 308: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 316: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 307: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 318: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 317: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 303: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 306: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 324/1000 [22:38<1:42:17,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 322: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 320: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 324: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 321: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 323: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 326: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 325: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 327: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 330/1000 [22:39<1:08:41,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 328: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 329: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 331: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 332: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▎      | 335/1000 [22:39<49:15,  4.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 336: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 330: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 335: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 333: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 345/1000 [22:39<24:20,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 340: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 339: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 345: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 343: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 334: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 338: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 341: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 342: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 337: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 349: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 346: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 344: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 348: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 354/1000 [22:40<12:58,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 352: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 350: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 356: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 347: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 351: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 355: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 358: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 354: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▋      | 365/1000 [22:40<05:48,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 359: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 360: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 364: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 365: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 361: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 353: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 372: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 367: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 357: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 366: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 362: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 368: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 374: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 377/1000 [22:40<02:42,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 363: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 382: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 373: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 371: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 381: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 377: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 380: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 376: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 369: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 370: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 378: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 375: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 379: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 384/1000 [22:40<01:49,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 383: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 385/1000 [26:24<2:33:19, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 384: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 385: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 386: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 388/1000 [26:24<1:59:05, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 388: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 387: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 389: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 392/1000 [26:25<1:23:37,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 390: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 391: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 396/1000 [26:25<58:37,  5.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 393: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 392: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 396: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 395: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 394: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 399/1000 [26:25<44:26,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 399: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 397: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 398: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 407/1000 [26:26<20:24,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 406: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 400: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 409: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 402: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 404: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 405: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 401: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 410: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 414: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 407: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 411: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 403: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 417/1000 [26:26<08:58,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 408: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 417: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 412: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 415: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 418: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 423: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 427/1000 [26:26<04:05,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 413: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 421: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 416: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 424: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 422: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 428: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 419: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 425: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 431: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 420: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 441/1000 [26:26<01:40,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 429: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 436: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 426: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 430: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 433: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 427: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 434: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 442: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 438: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 432: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 435: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 437: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 443: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 439: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 447/1000 [26:27<01:14,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 445: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 440: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 441: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 444: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 447: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 446: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 451/1000 [30:11<1:50:25, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 448: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 449: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 450: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 451: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 452: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 453: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 458/1000 [30:11<57:42,  6.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 455: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 456: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 454: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 459: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 461/1000 [30:12<42:41,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 458: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 457: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 460: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 462: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▋     | 464/1000 [30:12<31:05,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 463: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 461: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 465: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 472/1000 [30:12<13:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 467: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 464: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 473: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 468: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 466: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 475: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 477: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 474: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 472: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 470: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 469: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 471: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 480: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 484/1000 [30:12<05:09,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 482: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 478: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 476: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 479: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 484: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 488: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 497/1000 [30:13<02:05,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 486: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 490: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 483: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 492: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 481: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 496: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 487: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 485: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 489: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 494: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 498: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 499: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 491: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 495: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 501: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 510/1000 [30:13<01:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 500: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 504: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 497: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 505: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 493: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 506: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 502: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 503: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 511: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 509: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 510: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 507: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 508: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 514/1000 [33:57<1:36:16, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 512: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 514: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 513: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 515: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 516: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 517: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 519/1000 [33:58<1:02:22,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 519: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 518: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 521: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 523/1000 [33:58<44:23,  5.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 520: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 522: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 524: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 523: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 529/1000 [33:58<25:21,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 525: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 528: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 526: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 531: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 533/1000 [33:58<17:07,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 529: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 527: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 535: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 539: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 540: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 541: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 532: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 530: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 533: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 544: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 546/1000 [33:59<06:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 538: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 536: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 542: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 546: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 545: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 534: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 537: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 543: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 555/1000 [33:59<03:10,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 549: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 550: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 558: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 554: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 547: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 555: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 553: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 551: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 552: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 548: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 557: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 572: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 556: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 570/1000 [33:59<01:13,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 560: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 563: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 565: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 559: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 564: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 561: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 568: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 570: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 569: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 567: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 562: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 566: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 576/1000 [33:59<00:54,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 574: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 573: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 575: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 571: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 578/1000 [37:43<1:34:41, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 576: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 578: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 577: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 579: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 580: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 582/1000 [37:44<1:03:21,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 581: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 582: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 585/1000 [37:44<46:47,  6.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 583: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 584: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 586: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 587: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 585: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 588: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 592/1000 [37:44<22:55,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 590: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 591: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 592: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 589: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 595/1000 [37:45<16:40,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 593: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 601: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 595: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 603: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 594: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 604: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 605/1000 [37:45<06:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 600: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 596: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 599: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 602: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 597: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 605: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 598: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 609: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 608: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 606: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████▏   | 614/1000 [37:45<03:04,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 607: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 610: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 618: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 620: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 613: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 612: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 625: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 615: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 611: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 629/1000 [37:45<01:04,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 626: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 630: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 621: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 614: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 632: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 627: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 619: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 616: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 617: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 623: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 622: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 624: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 635: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 634: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▎   | 635/1000 [37:46<00:48,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 637: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 631: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 628: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 629: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 636: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 638: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 633: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 639: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 641/1000 [41:29<1:07:11, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 640: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 641: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 643/1000 [41:30<58:35,  9.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 642: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 644: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 643: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 645: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 650/1000 [41:30<33:19,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 648: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 646: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 649: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 647: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 651: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 650: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 653/1000 [41:31<25:12,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 652: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 653: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 660/1000 [41:31<12:33,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 655: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 659: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 654: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 656: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 657: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 658: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 661: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 663: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 660: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 668/1000 [41:31<05:49,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 666: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 662: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 668: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 664: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 665: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 670: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 672: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 667: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 671: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 674/1000 [41:31<03:28,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 669: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 676: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 678: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 675: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 680: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 684/1000 [41:32<01:36,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 674: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 673: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 679: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 686: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 682: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 677: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 681: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 690: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 693: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 683: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 685: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 696/1000 [41:32<00:43,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 696: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 688: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 687: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 692: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 691: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 697: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 684: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 694: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 689: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 702: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 701: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 698: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 703: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 704/1000 [41:32<00:28, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 700: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 695: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 699: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 706/1000 [45:16<1:05:21, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 704: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 705: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 706: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 707: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 708: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 710/1000 [45:16<43:38,  9.03s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 709: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████▏  | 713/1000 [45:17<32:09,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 710: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 711: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 713: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 715: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 716/1000 [45:17<23:19,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 716: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 712: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 714: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 717: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 721/1000 [45:17<13:12,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 719: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 721: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 718: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 722: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 720: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 726: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 730/1000 [45:18<04:52,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 723: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 728: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 724: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 725: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 727: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 729: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 734: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 730: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 742/1000 [45:18<01:42,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 738: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 736: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 732: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 737: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 731: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 735: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 733: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 740: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 739: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 746: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 747: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 741: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 744: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 751/1000 [45:18<00:54,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 745: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 743: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 748: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 742: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 755: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 750: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 754: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 751: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 749: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 753: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 760: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 763/1000 [45:18<00:25,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 757: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 752: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 763: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 756: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 762: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 758: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 761: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 764: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 766: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 759: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 768/1000 [45:18<00:20, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 765: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 767: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 769/1000 [49:02<1:04:35, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 768: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 770/1000 [49:02<58:11, 15.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 769: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 770: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 771: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 772: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 774/1000 [49:03<37:00,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 773: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 777/1000 [49:03<26:35,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 774: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 777: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 775: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 782/1000 [49:03<14:19,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 776: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 779: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 778: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 780: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 781: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 784/1000 [49:04<11:01,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 782: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 786: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 784: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 783: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 788: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 791/1000 [49:04<04:37,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 789: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 790: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 787: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 791: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 785: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 792: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 793: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 794: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 799/1000 [49:04<01:59,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 796: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 799: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 802: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 795: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 797: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 798: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 806/1000 [49:04<00:58,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 804: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 800: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 806: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 805: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 801: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 813: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 803: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 811: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 818: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 809: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 819/1000 [49:05<00:20,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 819: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 807: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 808: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 812: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 816: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 810: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 817: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 824: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 814: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 823: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 815: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 826/1000 [49:05<00:13, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 820: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 821: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 822: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 825: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 826: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 830: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 828: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 829: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 831/1000 [49:05<00:11, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 827: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 831: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▎ | 836/1000 [52:49<32:18, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 832: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 835: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 834: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 833: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 836: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 837: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 840/1000 [52:50<22:12,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 840: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 838: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 841: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 842: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 844/1000 [52:50<15:11,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 839: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 844: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 843: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 845: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 850/1000 [52:50<08:15,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 846: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 851: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 849: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 848: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 847: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 854: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 856/1000 [52:50<04:34,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 856: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 850: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 853: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 852: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 855: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 860: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 858: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 860/1000 [52:50<03:12,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 857: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 859: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 861: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 885/1000 [52:53<00:41,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 893: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 862: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 871: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 873: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 874: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 876: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 879: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 878: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 869: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 885: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 892: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 888: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 875: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 881: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 870: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 894: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 895: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 872: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 884: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 882: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 891: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 889: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 890: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 867: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 883: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 877: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 880: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 887: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 863: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 866: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 868: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 893/1000 [52:53<00:28,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 864: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 886: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 865: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 900/1000 [56:35<13:04,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 898: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 896: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 900: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 897: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 899: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 901: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 902: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 904: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 909/1000 [56:36<06:51,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 906: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 903: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 905: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 910: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 908: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 909: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████▏| 913/1000 [56:36<04:57,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 907: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 916: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 915: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 914: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 911: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 919/1000 [56:37<02:49,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 913: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 912: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 917: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 922: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 920: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 919: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 918: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 921: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 924/1000 [56:37<01:43,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 923: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 924: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▎| 935/1000 [56:39<00:43,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 927: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 938: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 928: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 937: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 933: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 934: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 931: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 926: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 945: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 939: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 957/1000 [56:39<00:09,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 958: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 946: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 936: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 951: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 929: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 955: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 942: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 935: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 956: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 950: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 947: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 943: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 930: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 940: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 941: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 952: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 949: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 932: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 944: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 948: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 957: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 954: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 959: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 953: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 925: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 962/1000 [1:00:21<06:06,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 962: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 961: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 960: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 963: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 964: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 965: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 967/1000 [1:00:22<03:43,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 966: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 970: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 967: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 971: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 969: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 972/1000 [1:00:22<02:12,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 968: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 972: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 973: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 976: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 983/1000 [1:00:23<00:36,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 974: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 977: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 975: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 978: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 984: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 980: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 979: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 981: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 983: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 982: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 986: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▊| 987/1000 [1:00:23<00:21,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 985: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 987: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 988: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 991/1000 [1:00:25<00:12,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 991: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 990: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 989: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 997: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 996: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 992: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1000/1000 [1:00:26<00:00,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 994: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 998: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 995: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 993: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 999: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:   0%|          | 6/1789 [03:46<13:45:29, 27.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 5: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 3: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 0: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 18: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 2: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 7: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 4: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 23: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 12: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 14: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 25: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 20: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 15: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 19/1789 [03:46<2:47:40,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 10: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 8: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 19: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 28: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 13: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 16: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   2%|▏         | 28/1789 [03:46<1:19:30,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 11: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 26: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 36: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 6: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 22: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 61: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 41: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 17: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 24: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 33: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 54: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 40: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 31: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 39: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 52: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 34: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 21: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 37: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 45: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 57: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 43: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 47: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 27: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 29: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 53: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 49: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 63: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 58: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 48: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 59: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 60: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 55: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 9: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 38: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 50: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 46: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 51: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 30: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 35: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 62: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 32: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 42: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 44: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 56: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 68/1789 [07:32<2:21:27,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 67: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 64: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 68: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 65: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 72: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 70: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 66: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 74: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 71: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 76/1789 [07:32<1:46:53,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 69: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 76: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 73: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 75: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 80: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 77: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▍         | 86/1789 [07:32<1:09:11,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 85: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 78: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 79: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 89: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 81: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 90: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 96: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 86: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 91: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 83: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 95/1789 [07:33<42:21,  1.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 100: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 107: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 102: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 106: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 93: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 105: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 82: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 97: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 101: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 126: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   6%|▌         | 103/1789 [07:33<25:35,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 110: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 127: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 108: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 87: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 115: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 121: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 104: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 94: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 99: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 116: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 92: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 125: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 103: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 95: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 88: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 84: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 124: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 114: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 109: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 113: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 111: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 98: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 119: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 117: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 112: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 122: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 118: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 123: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 120: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 133/1789 [11:18<2:30:08,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 128: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 130: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 137: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 131: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 129: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 136: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 135: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 132: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 138: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 142/1789 [11:19<1:39:31,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 133: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 134: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 140: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 139: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 143: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 142: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 150/1789 [11:19<1:01:26,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 151: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 141: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 148: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 150: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 144: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 149: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 145: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▊         | 155/1789 [11:19<43:56,  1.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 153: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 152: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 147: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 146: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 159: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 158: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 160: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 163/1789 [11:19<24:41,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 157: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 156: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 155: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 154: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 161: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 166: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 165: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|▉         | 172/1789 [11:20<12:26,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 180: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 168: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 163: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 164: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 170: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 169: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 182: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 173: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|▉         | 176/1789 [11:20<09:13,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 184: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 171: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 175: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 162: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 178: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 181: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 179: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 174: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 172: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 177: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 186: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 188: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 176: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 191: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 189: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 167: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 185: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 187: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 183: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 190: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 197/1789 [15:05<3:03:45,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 193: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 195: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 196: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 197: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 194: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█▏        | 205/1789 [15:05<1:54:34,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 198: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 192: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 200: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 204: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 199: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 201: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 206: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 203: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 202: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 213/1789 [15:05<1:04:56,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 208: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 205: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 207: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 209: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 212: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 210: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 216: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 213: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 217/1789 [15:05<47:40,  1.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 217: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 219: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 211: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 220: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 214: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 215: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 223: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 224: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 218: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 230/1789 [15:06<19:27,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 226: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 221: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 222: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 227: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 225: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 228: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 230: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▎        | 242/1789 [15:06<09:02,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 231: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 229: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 234: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 246: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 243: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 235: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 248: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 237: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 233: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 247: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 242: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 232: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 245: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 250: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 249: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 256/1789 [15:06<04:18,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 241: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 240: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 244: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 238: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 236: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 239: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 255: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 252: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 251: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 254: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 253: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 259/1789 [18:51<5:09:21, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 256: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 260: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 257: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 263: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 264/1789 [18:51<3:19:59,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 258: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 262: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 259: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 261: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 265: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 267: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 269: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 266: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 264: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 275/1789 [18:52<1:25:51,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 268: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 273: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 270: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 274: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 277: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 271: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 272: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 281/1789 [18:52<56:03,  2.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 275: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 276: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 280: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 278: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 281: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 279: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 282: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 289: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 283: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 286/1789 [18:52<39:43,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 284: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 287: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 286: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 288: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 285: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▋        | 295/1789 [18:52<21:16,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 290: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 291: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 294: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 293: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 292: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 304: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 298: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 307/1789 [18:52<09:07,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 301: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 297: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 296: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 299: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 303: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 306: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 295: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 305: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 300: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 309: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 311: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 302: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 307: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 313: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 317: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 308: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 310: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 315/1789 [18:53<05:46,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 315: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 318: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 312: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 314: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 316: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 320/1789 [18:53<04:33,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 319: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 324/1789 [22:37<4:50:53, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 322: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 325: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 320: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 326: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 324: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 323: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 321: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▊        | 332/1789 [22:38<2:22:11,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 332: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 329: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 331: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 330: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 327: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 328: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 335: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 340/1789 [22:38<1:09:44,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 338: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 334: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 333: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 337: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 336: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 340: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 343: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 351/1789 [22:38<29:02,  1.21s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 341: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 346: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 347: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 345: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 339: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 344: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 342: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 348: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 353: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 351: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 349: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 356/1789 [22:38<20:13,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 350: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 356: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 352: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 354: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 358: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 355: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 364/1789 [22:39<11:05,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 360: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 357: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 359: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 361: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 362: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 368: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 364: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 372: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 367: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 375/1789 [22:39<05:05,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 365: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 370: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 371: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 369: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 363: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 378: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 373: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 380: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 366: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 381: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 374: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 376: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██▏       | 383/1789 [22:39<03:07,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 375: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 377: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 379: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 383: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 382: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 389/1789 [26:24<4:07:53, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 384: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 389: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 388: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 386: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 385: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 387: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 394/1789 [26:24<2:47:29,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 390: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 392: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 391: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 400: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 394: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 396: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 393: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 397: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 401: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 405/1789 [26:24<1:15:18,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 395: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 403: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 399: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 398: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 409: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 405: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 406: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 404: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 402: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 415/1789 [26:25<37:04,  1.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 408: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 407: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 413: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 412: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 411: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 414: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 410: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▎       | 423/1789 [26:25<20:31,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 416: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 417: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 415: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 419: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 418: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 420: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 421: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 422: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 429/1789 [26:25<13:12,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 427: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 424: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 423: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 426: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 430: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 429: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 433: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 431: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 437: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 432: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 428: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 441/1789 [26:25<06:07,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 425: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 440: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 435: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 434: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 443: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 439: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 436: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 446: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 445: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 438: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 446/1789 [26:25<04:32,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 441: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 442: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 444: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 447: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 451/1789 [30:10<4:38:57, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 449: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 450: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 452: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 448: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 453: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 451: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 459/1789 [30:10<2:12:58,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 455: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 456: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 463: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 457: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 454: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 458: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 461: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 460: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 459: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 462: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 469/1789 [30:11<58:11,  2.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 464: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 467: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 472: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 466: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 468: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 465: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 477/1789 [30:11<32:36,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 474: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 470: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 475: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 469: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 471: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 473: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 477: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 476: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 479: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 478: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 485/1789 [30:11<18:44,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 481: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 484: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 480: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 482: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 489: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 494/1789 [30:11<09:30,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 486: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 483: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 493: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 490: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 485: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 491: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 487: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 488: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 498: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 497: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 505/1789 [30:12<04:21,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 500: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 501: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 492: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 494: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 496: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 506: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 495: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 502: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 503: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 499: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 505: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▊       | 510/1789 [30:12<03:19,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 507: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 510: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 504: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 509: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 508: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 511: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 517/1789 [33:57<3:51:42, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 514: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 512: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 513: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 516: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 515: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 517: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 519: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 525/1789 [33:57<1:58:02,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 523: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 527: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 518: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 520: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 526: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 524: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 525: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 521: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 522: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|██▉       | 533/1789 [33:57<59:01,  2.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 528: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 529: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 531: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 535: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 532: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 537: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 538: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 533: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 541/1789 [33:57<29:20,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 530: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 534: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 540: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 536: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 539: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 544: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 546: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 543: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 541: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 542: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 547/1789 [33:57<18:01,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 548: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 549: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 547: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 545: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 559/1789 [33:58<07:39,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 550: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 551: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 553: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 555: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 554: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 563: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 564: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 557: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 562: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 560: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 558: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 556: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 552: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 569/1789 [33:58<04:10,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 565: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 559: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 568: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 569: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 561: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 566: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 571: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 574/1789 [33:58<03:11,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 567: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 572: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 570: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 573: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 574: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 575: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 580/1789 [37:43<3:55:55, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 577: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 578: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 579: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 576: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 584: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 588/1789 [37:43<1:56:07,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 580: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 583: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 582: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 581: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 586: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 588: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 585: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 587: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 589: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 590: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 598/1789 [37:43<51:35,  2.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 592: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 594: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 591: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 597: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 598: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 593: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 596: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 606/1789 [37:44<26:41,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 601: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 602: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 595: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 603: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 599: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 600: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 606: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 609: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 610/1789 [37:44<19:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 604: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 612: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 607: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 610: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 608: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 605: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 611: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▍      | 618/1789 [37:44<09:48,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 613: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 620: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 618: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 615: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 621: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 622: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 614: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 616: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 626: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 630/1789 [37:44<04:03,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 619: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 628: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 623: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 617: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 629: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 624: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 625: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 633: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 630: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 627: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 637/1789 [37:44<02:40,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 634: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 631: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 638: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 632: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 636: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 637: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 635: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 639: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 644/1789 [41:29<3:20:25, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 642: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 640: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 641: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 644: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 643: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 649: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 647: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 651: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 655/1789 [41:30<1:27:10,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 646: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 654: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 648: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 650: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 657: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 645: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 659: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 655: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 653: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 658: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 652: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 660/1789 [41:30<1:01:10,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 663: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 656: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 660: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 661: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 664: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 670/1789 [41:30<30:11,  1.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 662: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 667: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 668: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 665: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 671: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 669: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 672: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 674: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 676/1789 [41:30<20:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 666: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 675: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 673: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 670: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 678: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 677: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 676: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 684/1789 [41:30<11:23,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 679: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 681: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 686: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 689: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 685: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 684: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 682: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 687: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 680: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 683: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 694/1789 [41:31<05:42,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 688: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 692: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 690: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 691: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 699: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 693: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 698: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 695: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 701/1789 [41:31<03:35,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 694: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 696: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 702: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 697: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 701: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 700: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 703: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 707/1789 [45:16<3:30:19, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 705: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 704: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 710: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 707: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 712: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 706: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 718/1789 [45:16<1:27:50,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 711: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 709: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 708: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 716: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 714: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 719: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 717: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 713: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 721: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 715: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 723/1789 [45:16<1:00:30,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 718: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 720: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 724: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 722: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 727: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 725: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 723: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 726: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 732/1789 [45:16<31:03,  1.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 728: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 732: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 731: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 736: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 734: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 730: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████▏     | 741/1789 [45:17<15:21,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 729: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 733: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 737: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 742: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 735: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 738: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 744: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 740: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 739: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 741: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 745/1789 [45:17<11:18,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 743: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 749: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 745: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 748: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 756/1789 [45:17<05:02,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 747: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 751: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 746: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 750: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 754: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 753: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 752: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 761: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 762: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 760: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 755: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 756: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 765/1789 [45:17<02:49,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 758: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 759: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 757: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 763: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 764: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 765: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 766: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 767: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 772/1789 [49:02<3:18:13, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 768: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 772: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 771: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 769: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 775: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 770: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 773: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 776: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 783/1789 [49:02<1:20:59,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 778: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 777: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 774: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 782: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 783: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 779: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 787: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 781: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 780: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 791/1789 [49:03<43:26,  2.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 785: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 786: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 788: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 790: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 784: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 789: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 794: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 799/1789 [49:03<22:27,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 793: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 795: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 791: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 792: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 796: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 803: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 797: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 798: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 802: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 799: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 810/1789 [49:03<09:31,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 805: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 800: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 807: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 801: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 806: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 808: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 804: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 809: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 814/1789 [49:03<07:15,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 810: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 816: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 811: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 813: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 812: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 815: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 822/1789 [49:03<04:14,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 818: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 823: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 819: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 817: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 814: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 822: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 820: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 828: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 825: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▋     | 831/1789 [49:04<02:36,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 821: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 829: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 824: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 827: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 826: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 830: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 831: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 839/1789 [52:48<2:41:02, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 832: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 833: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 839: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 835: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 837: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 834: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 836: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 840: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 847/1789 [52:49<1:24:47,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 843: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 841: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 838: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 842: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 844: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 848: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 845: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 851/1789 [52:49<1:00:37,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 846: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 847: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 849: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 852: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 850: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 851: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 853: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 855: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 859/1789 [52:49<30:31,  1.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 854: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 858: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 856: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 860: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 859: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 857: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 865: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 862: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▊     | 872/1789 [52:49<11:19,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 870: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 861: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 864: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 868: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 866: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 863: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 867: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 874: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 869: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 871: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 872: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 877/1789 [52:50<08:17,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 873: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 876: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 878: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 885: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 877: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 886/1789 [52:50<04:36,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 875: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 882: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 879: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 880: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 881: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 883: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 884: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 892: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 892/1789 [52:50<03:05,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 887: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 888: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 889: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 891: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 893: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 886: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 894: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 890: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 895: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 899/1789 [56:35<2:48:35, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 900: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 897: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 901: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 899: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 898: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 903/1789 [56:35<1:59:18,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 896: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 903: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 902: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 915/1789 [56:35<45:31,  3.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 909: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 904: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 905: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 911: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 912: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 914: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 906: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 913: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 907: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 915: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 910: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 920/1789 [56:35<32:23,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 908: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 917: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 926: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 916: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 918: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 931/1789 [56:36<14:59,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 919: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 928: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 923: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 921: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 920: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 927: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 922: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 924: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 932: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 929: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 925: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 938/1789 [56:36<09:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 935: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 934: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 931: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 930: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 936: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 938: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 933: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 937: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 943/1789 [56:36<07:20,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 939: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 941: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 942: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 948: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 948/1789 [56:36<05:22,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 940: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 943: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 944: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 945: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 946: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 947: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 951: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 954: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▎    | 958/1789 [56:36<02:53,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 952: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 950: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 957: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 953: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 955: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 949: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 958: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 956: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 959: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 963/1789 [1:00:21<2:53:18, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 961: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 960: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 962: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 964: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 963: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 967/1789 [1:00:21<1:58:59,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 965: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 966: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 967: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 975: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 977: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 968: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 979/1789 [1:00:22<44:07,  3.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 971: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 976: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 969: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 973: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 974: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 972: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 978: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 979: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 980: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 970: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 981: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 984/1789 [1:00:22<30:54,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 982: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 984: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 985: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 991: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 998/1789 [1:00:22<12:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 998: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 989: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 986: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 983: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 992: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 987: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 990: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 988: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1001: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 993: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 995: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 997: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 999: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 996: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1004/1789 [1:00:22<08:36,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 994: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1000: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1002: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1004: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1003: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1013/1789 [1:00:23<05:05,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1006: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1007: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1012: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1005: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1010: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1008: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1017: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1013: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1018/1789 [1:00:23<03:40,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1016: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1014: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1009: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1011: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1018: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1015: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1019: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1021: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1023/1789 [1:00:23<02:47,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1020: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1022: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1023: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1027/1789 [1:04:07<2:51:00, 13.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1024: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1028: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1025: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1030/1789 [1:04:08<2:05:14,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1027: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1026: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1031: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1029: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1033/1789 [1:04:08<1:30:35,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1030: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1034: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1035: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1033: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1038: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1032: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1036: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1044: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1037: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1045: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1045/1789 [1:04:08<32:00,  2.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1040: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1039: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1043: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1041: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1047: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1046: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▊    | 1049/1789 [1:04:08<23:09,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1042: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1048: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1049: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1053: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1061: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1064/1789 [1:04:08<07:50,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1063: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1055: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1060: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1059: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1058: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1056: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1054: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1062: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1052: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1050: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1051: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1057: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 1070/1789 [1:04:09<05:39,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1067: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1066: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1068: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1064: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1065: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1069: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 1075/1789 [1:04:09<04:17,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1071: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1070: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1073: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1076: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1072: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1075: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1080: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1077: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1085/1789 [1:04:09<02:20,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1082: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1078: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1074: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1081: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1085: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1084: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1079: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1083: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1086: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1087: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1091/1789 [1:07:54<2:14:14, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1088: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1090: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1089: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1095/1789 [1:07:54<1:34:35,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1091: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1092: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1095: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1099: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1094: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1103/1789 [1:07:54<45:29,  3.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1093: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1096: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1103: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1100: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1105: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1098: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1102: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1104: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1107/1789 [1:07:54<32:04,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1109: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1097: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1101: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1110: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1107: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1111: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1115/1789 [1:07:55<15:56,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1108: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1112: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1106: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1113: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1114: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1120: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1127: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1127/1789 [1:07:55<06:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1116: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1117: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1124: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1123: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1115: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1125: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1126: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1121: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1118: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1128: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1119: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1132/1789 [1:07:55<04:25,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1122: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1132: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1129: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1131: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1133: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1141/1789 [1:07:55<02:27,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1130: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1134: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1137: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1136: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1141: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1135: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1144: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1139: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1145/1789 [1:07:55<01:54,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1138: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1146: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1143: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1142: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1140: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1147: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1148: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1145: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1149: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1151/1789 [1:07:56<01:19,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1150: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1151: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1154/1789 [1:11:40<2:38:46, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1153: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1152: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1157/1789 [1:11:40<1:52:35, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1155: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1156: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1154: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1164/1789 [1:11:40<50:49,  4.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1158: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1160: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1157: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1163: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1159: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1165: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1167: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1162: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1166: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1174/1789 [1:11:41<19:45,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1161: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1168: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1164: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1169: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1173: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1171: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1172: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1170: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1174: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1178/1789 [1:11:41<14:03,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1175: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1180: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1177: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1176: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1178: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1179: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1182: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▋   | 1187/1789 [1:11:41<06:44,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1184: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1181: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1183: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1187: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1188: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1192: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1185: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1186: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1191: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1190: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1197/1789 [1:11:41<03:12,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1189: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1193: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1194: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1195: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1196: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1199: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1197: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1198: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1203/1789 [1:11:42<02:05,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1201: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1202: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1200: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1204: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1203: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1213/1789 [1:11:42<01:10,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1210: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1209: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1207: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1206: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1208: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1205: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1211: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1213: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1212: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1214: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1215: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1219/1789 [1:15:26<1:54:36, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1217: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1216: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1218: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1222/1789 [1:15:27<1:26:06,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1220: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1223: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1222: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▊   | 1227/1789 [1:15:29<52:19,  5.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1219: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1224: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1256: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1253: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1258: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1254: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1235: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1261: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1234: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1241: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1252: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1266: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1255: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1259: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1272: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1226: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1275: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1246: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1238: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1245: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1247: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1278: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1277: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1276: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1242: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1233: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1225: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1271: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1231: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1265: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1273: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1267: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1268: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1264: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1269: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1237: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1230: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1221: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1244: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1251: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1249: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1240: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1262: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1260: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1243: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1239: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1236: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1228: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1274: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1232: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1263: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1270: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1229: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1250: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1248: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1227: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1257: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1279: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1283/1789 [1:19:13<46:07,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1281: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1280: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1282: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1283: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1284: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1285: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1287: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1293/1789 [1:19:15<30:26,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1295: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1290: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1293: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1323: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1298: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1296: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1300/1789 [1:19:16<20:14,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1324: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1294: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1320: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1288: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1314: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1315: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1329: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1308: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1328: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1299: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1307: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1312: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1306: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1326: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1302: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1297: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1309: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1330: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1304: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1316: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1338: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1333: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1310: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1311: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1291: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1318: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1332: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1289: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1301: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1321: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1335: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1319: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1300: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1305: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1322: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1331: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1327: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1303: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1341: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1337: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1325: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1292: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1342: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1313: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1317: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1336: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1343: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1339: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1334: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1340: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1286: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 1348/1789 [1:22:59<30:16,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1345: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1344: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1346: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1347: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1348: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1351/1789 [1:23:01<27:53,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1349: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1350: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1356/1789 [1:23:02<21:46,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1351: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1352: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1355: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1353: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1354: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1362/1789 [1:23:02<14:07,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1356: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1360: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1364: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1357: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1361: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1365: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1363: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1358: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1378: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1379: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1375/1789 [1:23:02<05:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1367: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1376: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1362: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1390: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1389: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1375: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1372: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1371: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1385: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1382: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1380: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1386: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1370: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1368: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1384/1789 [1:23:03<03:06,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1405: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1383: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1366: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1359: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1374: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1394: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1381: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1400: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1404: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1384: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1377: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1395: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1403: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1396: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1397: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1402: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1369: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1401: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1399: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1373: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1407: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1388: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1391: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1393: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1392: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1406: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1398: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1387: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1409/1789 [1:26:45<39:15,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1408: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1410: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1409: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1412/1789 [1:26:45<34:56,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1411: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1412: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1413: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1419/1789 [1:26:48<24:28,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1414: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1417: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1416: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1415: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1418: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1419: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1428/1789 [1:26:48<13:14,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1421: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1420: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1422: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1423: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1424: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1425: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1427: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1428: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1433: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1437/1789 [1:26:49<07:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1426: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1429: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1437: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1434: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1431: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1436: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1430: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1438: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1441: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1441/1789 [1:26:49<05:13,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1435: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1432: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1440: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1443: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1457: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1453: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1445: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1451: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1463/1789 [1:26:49<01:11,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1447: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1439: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1454: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1455: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1444: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1468: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1459: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1466: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1470: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1465: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1469: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1450: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1462: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1464: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1461: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1460: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1448: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1442: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1449: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1471: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1458: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1467: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1446: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1456: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1463: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1452: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1476/1789 [1:30:32<38:52,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1472: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1474: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1473: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1475: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1476: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1477: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1481/1789 [1:30:34<29:16,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1479: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1482: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1480: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1478: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1488/1789 [1:30:35<18:01,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1483: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1481: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1484: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1485: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1486: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1489: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1492/1789 [1:30:35<13:03,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1487: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1491: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1488: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1490: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1496: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1494: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1500/1789 [1:30:35<06:31,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1492: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1501: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1495: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1493: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1499: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1497: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1498: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1509/1789 [1:30:35<03:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1500: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1503: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1502: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1509: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1504: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1505: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1507: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1508: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1514/1789 [1:30:35<02:04,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1510: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1513: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1511: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1526: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1514: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1519: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1506: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1532: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1528: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1521: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1517: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1529: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1512: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1524: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1535/1789 [1:30:36<00:35,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1516: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1530: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1515: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1520: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1523: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1522: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1525: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1535: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1531: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1518: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1533: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1527: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1534: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1540/1789 [1:34:18<38:38,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1536: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1540: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1539: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1537: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1538: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1541: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1542: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1544: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1543: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▋ | 1546/1789 [1:34:21<25:37,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1545: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1549: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1547: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1548: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1554/1789 [1:34:21<14:01,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1552: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1546: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1550: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1553: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1551: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1561: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1565/1789 [1:34:21<05:53,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1554: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1560: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1556: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1557: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1565: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1564: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1555: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1559: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1558: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1562: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1569/1789 [1:34:21<04:23,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1563: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1568: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1566: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1572: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1573: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1569: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1580/1789 [1:34:22<01:54,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1578: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1576: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1583: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1574: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1567: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1571: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1570: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1575: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1580: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1591/1789 [1:34:22<00:53,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1577: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1581: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1587: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1588: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1586: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1584: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1585: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1589: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1597: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1579: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1582: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1596: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1599: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1595: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1592: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1593: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1590: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1598: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1591: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1594: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1605/1789 [1:38:04<24:11,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1602: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1600: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1604: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1603: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1601: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1605: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1609/1789 [1:38:07<18:50,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1606: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1609: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1607: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1611: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1616/1789 [1:38:07<10:45,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1613: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1608: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1610: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1612: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1614: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1615: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1619/1789 [1:38:08<08:15,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1617: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1616: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1618: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1620: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1621: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1619: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1627: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1630: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1626: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1630/1789 [1:38:08<03:19,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1631: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1623: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1632: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1622: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1625: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1634: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1628: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1624: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1629: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1633: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1642/1789 [1:38:08<01:20,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1636: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1638: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1641: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1635: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1642: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1640: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1643: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1637: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1639: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1655/1789 [1:38:08<00:33,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1647: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1648: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1644: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1651: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1656: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1649: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1645: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1662: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1663: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1653: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1659: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1652: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1661/1789 [1:38:08<00:23,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1657: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1646: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1650: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1655: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1660: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1661: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1654: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1658: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1667/1789 [1:41:51<21:49, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1665: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1668: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1664: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1667: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1666: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1671/1789 [1:41:53<15:30,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1669: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1670: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▎| 1674/1789 [1:41:53<11:40,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1671: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1672: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1678: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1677: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1673: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1681/1789 [1:41:54<05:38,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1674: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1675: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1680: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1676: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1679: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1681: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1684/1789 [1:41:54<04:06,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1686: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1692: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1682: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1683: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1690: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1684: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1687: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1685: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1688: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1689: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1700/1789 [1:41:54<01:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1701: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1691: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1693: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1696: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1694: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1704: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1700: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1697: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1695: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1703: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1706: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1707: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1699: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1702: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1712/1789 [1:41:54<00:27,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1698: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1708: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1705: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1710: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1709: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1712: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1718: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1713: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 1722/1789 [1:41:55<00:13,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1711: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1714: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1719: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1716: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1720: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1715: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1717: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1723: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 1726/1789 [1:41:55<00:10,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1722: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1721: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1726: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1724: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1727: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1725: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1731/1789 [1:45:37<12:25, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1729: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1728: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1731: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1732: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1730: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1735/1789 [1:45:39<08:02,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1734: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1733: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1741/1789 [1:45:40<03:55,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1739: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1738: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1737: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1735: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1736: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1740: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1743: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1742: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1748/1789 [1:45:40<01:36,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1745: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1741: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1744: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1746: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1752: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1749: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1755/1789 [1:45:40<00:39,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1750: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1748: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1747: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1753: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1756: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1755: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1751: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1765: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1766: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1754: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1770/1789 [1:45:41<00:06,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1761: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1759: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1767: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1769: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1760: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1762: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1757: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1764: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1758: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1768: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1763: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1770: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1775/1789 [1:45:41<00:03,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1773: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1774: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1771: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1772: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1778: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1775: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|█████████▉| 1784/1789 [1:45:41<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1784: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1776: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1780: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1777: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1782: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1779: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1783: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1788: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1785: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1781: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [1:45:41<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1786: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1787: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 9/1789 [03:46<9:00:05, 18.21s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 6: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 20: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 8: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 0: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 16: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 21: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 13: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 15: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 16/1789 [03:46<4:10:55,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 11: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 12: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 10: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 7: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 4: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 31: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 33: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 21/1789 [03:46<2:42:31,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 29: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 34: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 42: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 9: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 25: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 14: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 49: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 39: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 22: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 2: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 43: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 40: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 59: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 38: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 27: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 46: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 51: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 23: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 50: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 18: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 24: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 3: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 17: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 58: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 63: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 61: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 28: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 35: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 47: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 54: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 30: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 5: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 48: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 53: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 60: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 37: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 62: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 45: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 26: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 44: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 57: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 36: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 32: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 55: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 41: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 52: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 56: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 19: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 68/1789 [07:32<2:18:10,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 67: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 64: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 70: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 69: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 66: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 65: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 74/1789 [07:32<1:49:56,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 68: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 72: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 71: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 73: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▍         | 81/1789 [07:32<1:13:30,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 74: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 77: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 79: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 81: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 82: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 88: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 76: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 96: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 80: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 84: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 78: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 90/1789 [07:33<40:21,  1.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 99: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 111: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 95: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 104: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 90: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 85: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 102: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 92: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 128/1789 [07:33<07:12,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 126: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 118: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 91: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 75: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 116: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 101: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 86: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 109: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 100: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 119: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 125: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 89: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 93: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 83: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 98: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 107: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 110: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 94: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 87: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 122: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 120: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 103: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 121: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 105: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 123: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 124: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 112: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 117: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 115: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 106: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 114: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 108: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 113: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 127: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 97: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 132/1789 [11:18<2:54:41,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 128: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 129: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 131: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 132: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 130: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 133: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 134: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 136: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 135: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 137: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 149/1789 [11:19<1:22:35,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 141: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 140: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 143: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 147: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 145: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 139: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 138: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 148: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 142: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 144: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 152: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▊         | 156/1789 [11:19<1:00:04,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 146: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 150: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 149: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 162: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 163: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 155: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 156: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 157: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 159: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 168/1789 [11:19<33:10,  1.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 160: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 154: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 167: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 151: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 170: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 158: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 169: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 171: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 190: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 175: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|▉         | 174/1789 [11:20<24:15,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 168: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 153: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 161: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 165: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 187: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 186: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 178: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 173: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 174: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 177: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 191: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 172: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 182: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 183: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 179: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 189: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 166: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 164: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 180: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 176: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 184: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 185: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 188: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 181: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 193/1789 [15:04<3:04:45,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 194: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 193: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 192: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 200/1789 [15:05<2:15:23,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 196: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 198: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 195: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 197: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 200: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 199: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█▏        | 204/1789 [15:05<1:48:18,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 201: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 203: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 204: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 207: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 202: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 206: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 212/1789 [15:05<1:04:08,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 208: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 211: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 210: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 209: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 205: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 215: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 216/1789 [15:05<47:50,  1.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 213: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 212: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 214: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 216: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 219: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 217: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 229/1789 [15:06<19:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 222: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 221: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 223: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 218: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 228: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 220: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 227: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 225: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 224: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 229: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 235: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 226: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 241: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 237: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 231: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 230: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 247/1789 [15:06<07:21,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 232: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 247: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 244: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 242: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 251: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 245: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 236: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 253: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 239: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 233: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 238: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 240: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 255/1789 [15:06<05:09,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 250: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 234: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 254: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 243: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 246: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 248: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 252: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 255: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 249: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 257/1789 [18:51<4:52:30, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 256: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 258: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 257: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 260/1789 [18:51<4:00:37,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 261: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 262: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 260: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 259: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 269/1789 [18:51<2:06:12,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 265: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 264: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 270: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 263: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 267: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 272: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 266: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 277/1789 [18:52<1:07:14,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 268: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 269: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 271: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 273: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 276: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 275: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 274: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 281: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 281/1789 [18:52<48:34,  1.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 277: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 278: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 283: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 290/1789 [18:52<23:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 288: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 289: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 279: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 282: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 285: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 280: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 292: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 294: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 286: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 293: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 297: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 287: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 296: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 305/1789 [18:52<08:41,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 284: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 291: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 290: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 300: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 301: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 305: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 298: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 302: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 299: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 295: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 309: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 306: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 304: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 311: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 311/1789 [18:52<06:10,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 303: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 318: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 312: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 308: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 307: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 314: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 313: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 315: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 317: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 319: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 310: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 320/1789 [18:53<03:51,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 316: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 323/1789 [22:37<4:40:18, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 320: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 322: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 321: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 328/1789 [22:38<3:05:01,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 324: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 323: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 325: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 326: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 327: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 329: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▊        | 332/1789 [22:38<2:13:06,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 330: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 333: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 331: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 328: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 332: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 335: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 339/1789 [22:38<1:12:53,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 336: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 338: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 334: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 337: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 339: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 346/1789 [22:38<37:15,  1.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 343: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 340: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 342: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 341: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 344: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 346: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 348: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 350/1789 [22:38<25:40,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 345: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 349: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 347: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 350: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 360: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 354: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 358: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 356: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 352: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 365: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 370/1789 [22:39<06:17,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 351: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 353: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 355: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 359: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 357: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 366: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 362: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 363: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 361: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 368: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 369: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 364: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 373: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 371: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██▏       | 382/1789 [22:39<03:08,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 367: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 381: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 370: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 378: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 372: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 375: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 379: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 377: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 374: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 382: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 376: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 380: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 383: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 386/1789 [26:23<4:56:15, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 384: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 385: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 390/1789 [26:24<3:23:21,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 386: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 390: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 388: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 389: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 394/1789 [26:24<2:20:22,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 387: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 393: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 392: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 391: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 394: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 398/1789 [26:24<1:37:21,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 395: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 396: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 397: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 398: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 406/1789 [26:24<46:17,  2.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 399: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 401: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 400: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 404: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 402: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 405: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 403: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 407: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 413/1789 [26:25<25:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 408: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 406: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 411: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 410: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 412: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 417: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 409: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▎       | 423/1789 [26:25<10:52,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 422: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 413: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 424: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 419: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 421: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 414: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 425: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 415: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 418: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 426: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 416: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 429: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 423: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 439/1789 [26:25<03:55,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 427: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 420: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 433: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 428: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 431: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 436: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 437: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 432: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 435: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 443: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 434: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 430: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 440: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 445/1789 [26:25<02:51,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 439: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 438: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 441: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 446: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 445: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 444: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 442: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 447: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 449/1789 [30:10<4:38:31, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 450: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 448: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 449: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 452/1789 [30:10<3:45:12, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 453: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 454: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 452: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 451: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 457: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 461/1789 [30:10<1:53:43,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 455: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 456: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 460: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 459: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 461: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 458: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 465/1789 [30:11<1:22:43,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 463: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 469: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 468: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 464: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 462: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▋       | 471/1789 [30:11<52:06,  2.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 466: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 465: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 467: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 471: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 473: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 470: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 474: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 479/1789 [30:11<28:17,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 472: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 477: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 475: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 476: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 479: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 482: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 488/1789 [30:11<13:50,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 485: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 478: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 480: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 492: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 483: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 481: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 486: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 494: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 493: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 501/1789 [30:12<05:49,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 484: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 489: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 495: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 491: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 499: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 487: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 496: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 490: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 488: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 503: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 506: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 504: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 500: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 507: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 501: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 508/1789 [30:12<03:52,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 502: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 498: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 497: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 509: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 505: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 508: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 510: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 511: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 515/1789 [33:56<3:43:36, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 512: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 513: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 514: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 519/1789 [33:57<2:42:09,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 517: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 518: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 519: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 515: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 516: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 522: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 526/1789 [33:57<1:29:27,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 520: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 525: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 521: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 523: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 526: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|██▉       | 529/1789 [33:57<1:07:13,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 527: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 524: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 531: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 533: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 539/1789 [33:57<26:37,  1.28s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 529: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 532: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 530: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 537: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 528: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 535: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 536: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 538: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 539: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 534: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 549/1789 [33:58<12:23,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 546: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 544: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 540: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 541: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 545: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 542: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 549: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 543: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 547: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 559: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███▏      | 560/1789 [33:58<05:48,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 548: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 552: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 558: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 560: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 551: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 550: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 567: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 555: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 553: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 554: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 561: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 567/1789 [33:58<03:48,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 562: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 557: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 556: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 565: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 563: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 566: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 569: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 564: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 570: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 571: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 568: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 573/1789 [33:58<02:51,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 575: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 574: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 572: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 573: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 579/1789 [37:43<3:43:08, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 577: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 576: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 578: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 583/1789 [37:43<2:39:24,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 579: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 580: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 581: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 587: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 582: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 583: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 584: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 591/1789 [37:43<1:19:58,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 586: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 589: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 585: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 591: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 590: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 588: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 594/1789 [37:43<1:01:01,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 592: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 594: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 595: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 599: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 593: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 600: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 596: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▎      | 603/1789 [37:44<28:16,  1.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 597: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 598: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 602: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 603: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 601: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 606: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 607: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 608: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 609/1789 [37:44<17:20,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 609: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 605: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 604: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 610: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 611: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 616/1789 [37:44<10:08,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 616: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 613: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 612: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 621: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 625: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 615: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 614: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 618: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 637/1789 [37:44<02:51,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 630: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 622: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 617: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 619: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 629: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 628: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 635: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 627: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 620: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 632: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 634: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 633: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 631: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 623: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 624: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 626: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 638: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 636: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 639: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 637: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 641/1789 [41:29<3:27:00, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 641: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 640: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 643/1789 [41:29<3:02:19,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 642: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 649: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 644: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 643: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 646: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▋      | 651/1789 [41:29<1:39:11,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 647: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 645: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 648: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 651: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 650: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 653: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 654: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 659/1789 [41:30<51:31,  2.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 652: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 656: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 655: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 660: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 658: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 662: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 665/1789 [41:30<32:04,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 657: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 661: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 659: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 664: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 663: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 668: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 665: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 674/1789 [41:30<16:29,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 666: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 670: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 671: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 669: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 667: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 675: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 672: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 678/1789 [41:30<12:13,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 674: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 673: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 676: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 679: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 688/1789 [41:31<05:36,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 686: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 678: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 683: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 677: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 684: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 687: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 685: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 688: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 690: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 700: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 692: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 681: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 682: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 698/1789 [41:31<03:02,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 695: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 680: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 697: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 694: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 689: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 693: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 696: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 699: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 691: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 698: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 704/1789 [41:31<02:22,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 701: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 703: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 702: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 705/1789 [45:15<4:20:07, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 705: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 704: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 707/1789 [45:16<3:40:15, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 706: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 708: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 715/1789 [45:16<1:46:03,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 711: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 707: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 709: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 713: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 710: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 712: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 714: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 715: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 719/1789 [45:16<1:13:54,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 717: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 718: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 716: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 721: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 719: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 720: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 727/1789 [45:16<36:04,  2.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 724: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 722: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 725: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 727: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 723: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 729: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 728: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 735/1789 [45:17<17:46,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 732: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 735: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 726: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 733: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 734: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 731: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 730: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 738: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████▏     | 739/1789 [45:17<12:38,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 737: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 736: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 740: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 748/1789 [45:17<05:50,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 747: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 739: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 746: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 749: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 741: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 745: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 743: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 742: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 753: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 751: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 744: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 750: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 748: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 761/1789 [45:17<02:26,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 752: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 756: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 754: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 757: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 761: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 764: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 758: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 763: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 762: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 759: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 766/1789 [45:17<01:53,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 760: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 755: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 766: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 765: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 767: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 769/1789 [49:02<4:07:21, 14.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 769: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 768: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 771/1789 [49:02<3:28:56, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 770: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 771: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▎     | 779/1789 [49:02<1:40:03,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 778: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 772: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 777: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 775: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 773: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 779: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 774: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 783/1789 [49:02<1:09:32,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 782: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 776: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 781: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 780: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 783: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 789/1789 [49:03<38:54,  2.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 791: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 786: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 785: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 784: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 793: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 790: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 787: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 788: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 789: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 798/1789 [49:03<16:50,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 795: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 798: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 794: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 792: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 799: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 800: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 797: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 805/1789 [49:03<09:08,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 796: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 803: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 801: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 805: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 802: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 808/1789 [49:03<06:54,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 807: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 804: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 813: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 814: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 811: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 808: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 810: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 812: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 809: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 806: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 820/1789 [49:04<02:43,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 815: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 818: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 817: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 819: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 824: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 816: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 823: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 820: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 822: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 821: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▋     | 828/1789 [49:04<01:38,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 827: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 829: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 825: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 828: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 830: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 826: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 831: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 834/1789 [52:48<3:02:47, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 832: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 833: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 838/1789 [52:48<2:09:07,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 835: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 834: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 837: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 841: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 838: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 844/1789 [52:49<1:13:01,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 844: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 839: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 836: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 840: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 845: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 850/1789 [52:49<38:48,  2.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 842: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 843: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 849: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 846: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 847: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 848: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 854/1789 [52:49<25:29,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 855: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 851: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 850: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 853: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 854: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 852: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 860: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 858: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 857: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 866/1789 [52:49<09:14,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 859: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 861: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 856: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 863: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 862: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 866: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 864: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 865: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 874/1789 [52:50<05:11,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 867: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 877: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 869: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 873: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 871: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 872: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 868: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 870: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 874: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 875: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 885/1789 [52:50<02:19,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 882: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 880: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 876: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 878: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 879: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 890: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 881: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 888: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 883: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 886: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 891: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 893: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 895/1789 [52:50<01:19, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 885: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 884: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 887: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 889: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 892: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 895: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 894: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 898/1789 [56:34<3:40:19, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 896: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 897: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 898: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 900: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 902/1789 [56:35<2:23:08,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 899: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 901: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 903: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 904: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 909/1789 [56:35<1:08:20,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 902: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 912: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 905: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 906: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 911: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 907: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 917/1789 [56:35<30:32,  2.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 909: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 908: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 916: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 910: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 913: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 917: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 914: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 920: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 915: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 923/1789 [56:36<18:18,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 925: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 918: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 919: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 924: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 927: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 922: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 923: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 921: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 928/1789 [56:36<12:25,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 926: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 929: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 937/1789 [56:38<07:31,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 933: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 936: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 931: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 940: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 939: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 935: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 938: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 937: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 950/1789 [56:38<03:08,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 959: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 930: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 949: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 945: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 957: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 941: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 946: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 954: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 948: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 932: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 955: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 958: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 944: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 956: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 956/1789 [56:38<02:14,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 934: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 951: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 942: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 950: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 953: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 952: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 928: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 947: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 943: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▎    | 961/1789 [1:00:21<2:45:54, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 960: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 962: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 961: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 964/1789 [1:00:21<2:14:44,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 966: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 963: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 964: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 965: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 968/1789 [1:00:21<1:39:07,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 967: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 969: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 968: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 972: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 979/1789 [1:00:22<42:32,  3.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 971: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 970: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 977: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 974: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 978: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 981: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 973: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 979: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 980: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 975: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 984: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 986: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 989/1789 [1:00:22<21:06,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 976: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 988: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 983: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 987: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 989: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 982: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 992: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 985: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 990: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 993/1789 [1:00:22<15:50,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 991: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 997/1789 [1:00:24<13:18,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 993: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 994: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 997: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 996: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 995: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 998: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1000: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1001/1789 [1:00:24<09:44,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 999: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▋    | 1010/1789 [1:00:25<04:48,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1004: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1003: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1010: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1001: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1006: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1002: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1007: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1005: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1008: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1015: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1013: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1017/1789 [1:00:25<02:58,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1011: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1012: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1016: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1009: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1017: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1020: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1014: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1022: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1019: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1023: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1023/1789 [1:00:25<02:04,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1018: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1021: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1027/1789 [1:04:07<2:40:56, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1025: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1024: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1026: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1028: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1029: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1027: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1031/1789 [1:04:08<1:49:58,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1030: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1033: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1032: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1039/1789 [1:04:08<51:01,  4.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1031: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1041: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1034: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1040: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1035: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1042: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1036: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1045: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1037: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1038: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1039: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▊    | 1050/1789 [1:04:08<21:02,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1043: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1044: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1051: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1046: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1048: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1050: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1047: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1053: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1055: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1049: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1056/1789 [1:04:08<13:36,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1056: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1054: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1052: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1060/1789 [1:04:10<11:38,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1057: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1059: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1058: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1063: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1060: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1062: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1064/1789 [1:04:11<08:42,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1061: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1064: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1069: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 1074/1789 [1:04:11<04:04,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1067: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1065: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1071: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1074: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1068: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1075: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1078: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1066: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1070: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1086/1789 [1:04:11<01:50,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1076: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1072: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1077: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1084: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1073: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1079: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1083: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1085: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1082: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1086: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1081: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1080: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1087: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1089/1789 [1:07:53<2:41:19, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1089: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1088: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1091/1789 [1:07:54<2:17:00, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1090: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1091: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1092: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1093: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████▏   | 1098/1789 [1:07:54<1:12:13,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1094: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1095: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1098: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1097: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1096: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1104: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1108/1789 [1:07:54<30:23,  2.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1100: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1102: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1099: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1101: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1107: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1103: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1105: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1106: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1110: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1111: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1115/1789 [1:07:55<17:45,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1108: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1109: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1117: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1116: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1112: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1119: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1113: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1119/1789 [1:07:55<13:19,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1115: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1114: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1120: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1118: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1123/1789 [1:07:57<11:09,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1121: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1122: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1124: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1123: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1126: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1127/1789 [1:07:57<08:11,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1127: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1125: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1134/1789 [1:07:57<04:38,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1128: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1132: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1129: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1133: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1131: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1130: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1144/1789 [1:07:58<02:03,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1137: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1134: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1135: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1144: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1145: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1138: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1143: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1140: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1142: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1149: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1136: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1139: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1147: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1150/1789 [1:07:58<01:24,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1141: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1150: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1148: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1146: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1151: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1154/1789 [1:11:40<2:25:38, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1153: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1152: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1157/1789 [1:11:40<1:45:33, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1154: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1155: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1156: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1158: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1157: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1166/1789 [1:11:41<41:50,  4.03s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1160: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1162: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1166: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1159: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1163: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1165: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1173: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1174: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1161: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1173/1789 [1:11:41<23:48,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1175: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1167: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1164: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1168: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1171: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1178: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1179: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1169: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1170: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1172: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1183/1789 [1:11:41<11:45,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1180: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1176: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1177: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1184: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1181: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1182: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1183: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▋   | 1187/1789 [1:11:43<09:53,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1185: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1186: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1187: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1190/1789 [1:11:43<07:47,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1191: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1190: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1189: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1188: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1197/1789 [1:11:44<04:17,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1192: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1196: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1194: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1193: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1195: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1203/1789 [1:11:44<02:31,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1203: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1201: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1199: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1197: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1198: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1205: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1202: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1200: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1207: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1206: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1214/1789 [1:11:44<01:04,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1204: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1209: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1208: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1210: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1213: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1211: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1215: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1212: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1214: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1217/1789 [1:15:26<2:41:52, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1216: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1217: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1221/1789 [1:15:27<1:42:31, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1219: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1220: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1218: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1224/1789 [1:15:27<1:11:55,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1221: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1224: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1222: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1225: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1223: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1233/1789 [1:15:27<27:00,  2.92s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1227: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1229: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1228: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1233: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1231: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1226: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1236: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1237: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1230: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1234: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1235: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1242/1789 [1:15:27<12:21,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1240: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1232: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1238: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1245: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1244: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1239: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1241: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1247: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1246/1789 [1:15:27<08:46,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1246: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1242: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1248: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1243: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1250/1789 [1:15:29<07:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1249: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1256/1789 [1:15:30<04:21,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1251: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1253: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1254: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1252: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1250: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1255: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1258/1789 [1:15:30<03:43,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1259: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1258: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1256: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1263: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1257: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1260: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1269/1789 [1:15:30<01:25,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1261: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1265: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1264: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1262: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1267: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1271: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1266: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1268: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1269: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1275: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████▏  | 1279/1789 [1:15:30<00:44, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1273: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1270: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1274: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1278: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1272: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1279: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1276: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1277: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1281/1789 [1:19:12<2:28:26, 17.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1280: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1281: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1283/1789 [1:19:13<2:00:58, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1282: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1284: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1289/1789 [1:19:13<1:01:24,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1283: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1285: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1289: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1288: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1287: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1286: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1296/1789 [1:19:13<27:47,  3.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1290: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1291: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1294: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1299: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1298: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1295: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1308/1789 [1:19:14<09:15,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1293: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1302: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1305: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1300: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1297: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1296: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1292: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1304: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1306: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1301: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1303: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1307: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1312/1789 [1:19:14<06:52,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1311: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1308: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1309: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1310: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1312: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1313: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▎  | 1316/1789 [1:19:16<05:58,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1316: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1315: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1314: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1317: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1322/1789 [1:19:16<03:39,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1318: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1319: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1320: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1322: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1321: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1323: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1329/1789 [1:19:16<02:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1324: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1328: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1327: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1326: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1329: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1337/1789 [1:19:17<01:00,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1325: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1331: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1330: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1332: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1333: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1337: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1335: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1334: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1340: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 1343/1789 [1:19:17<00:41, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1341: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1338: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1336: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1339: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1342: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1343: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 1347/1789 [1:22:59<1:46:54, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1344: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1345: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1346: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 1350/1789 [1:22:59<1:16:10, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1347: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1353: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1349: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1348: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1356/1789 [1:23:00<36:54,  5.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1351: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1352: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1350: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1354: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1357: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 1367/1789 [1:23:00<12:32,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1358: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1355: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1360: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1363: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1356: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1366: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1359: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1361: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1364: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1369: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1368: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1372/1789 [1:23:00<08:26,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1362: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1370: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1372: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1367: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1365: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1373: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1371: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1376/1789 [1:23:00<06:11,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1374: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1375: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1376: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1377: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1379: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1380/1789 [1:23:02<05:18,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1380: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1378: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1381: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1383: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1386/1789 [1:23:03<03:13,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1384: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1382: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1388: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1388/1789 [1:23:03<02:42,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1385: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1392: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1389: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1387: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1386: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1395/1789 [1:23:03<01:23,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1391: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1390: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1393: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1400: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1401: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1397: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▊  | 1405/1789 [1:23:03<00:37, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1394: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1396: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1395: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1404: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1398: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1405: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1399: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1406: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1402: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1403: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1407: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1409/1789 [1:26:45<1:43:06, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1408: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1409: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1410: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1415/1789 [1:26:46<57:51,  9.28s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1411: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1413: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1412: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1414: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1418/1789 [1:26:46<42:11,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1418: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1416: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1415: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1417: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1426/1789 [1:26:46<18:10,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1424: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1419: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1420: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1426: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1428: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1423: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1427: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1431: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1434/1789 [1:26:46<08:32,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1421: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1429: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1425: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1422: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1430: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1434: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1435: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1433: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1438/1789 [1:26:47<05:56,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1432: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1436: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1439: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1437: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1438: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1440: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1442/1789 [1:26:48<04:46,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1441: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1442: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1445/1789 [1:26:49<03:45,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1444: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1445: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1446: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1443: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1447: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1451/1789 [1:26:49<02:12,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1448: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1451: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1449: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████▏ | 1457/1789 [1:26:49<01:12,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1450: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1453: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1452: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1455: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1454: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1456: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1462/1789 [1:26:49<00:45,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1457: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1459: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1458: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1463: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1462: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1465: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1461: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1466: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1468: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1469/1789 [1:26:50<00:24, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1464: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1469: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1460: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1470: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1467: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1471: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1476/1789 [1:30:32<1:05:01, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1472: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1473: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1474: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1475: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1482/1789 [1:30:32<34:57,  6.83s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1477: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1479: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1480: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1478: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1476: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1481: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1485/1789 [1:30:33<25:09,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1486: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1488: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1485: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1482: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1483: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1484: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1491: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1493/1789 [1:30:33<11:07,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1487: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1496: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1497: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1489: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1492: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1494: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1490: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1498: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1495: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1504/1789 [1:30:33<04:17,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1503: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1493: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1502: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1499: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1500: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1501: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1504: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1508/1789 [1:30:35<03:37,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1505: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1506: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1507: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1508: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1511/1789 [1:30:35<02:50,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1510: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1509: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1511: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1514/1789 [1:30:35<02:11,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1512: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1514: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1513: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1520/1789 [1:30:36<01:13,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1519: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1517: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1516: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1518: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1515: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1520: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1526/1789 [1:30:36<00:44,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1522: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1523: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1521: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1526: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1530: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1532: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1524: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1527: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1534: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1529: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1525: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1531: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1528: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1533: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1536/1789 [1:30:36<00:23, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1535: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1537/1789 [1:34:18<1:10:51, 16.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1536: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1538: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1537: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1542/1789 [1:34:18<42:38, 10.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1541: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1539: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1543: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1540: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1548/1789 [1:34:19<20:27,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1545: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1542: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1550: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1546: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1544: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1548: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1547: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1554/1789 [1:34:19<10:08,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1552: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1553: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1549: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1554: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1551: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1561: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1561/1789 [1:34:19<04:38,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1555: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1559: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1562: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1564: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1556: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1560: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1563: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1568/1789 [1:34:19<02:23,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1565: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1566: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1558: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1557: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1567: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1568: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1571/1789 [1:34:21<02:15,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1569: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1570: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1571: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1573: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1574/1789 [1:34:21<01:44,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1572: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1574: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1576/1789 [1:34:22<01:29,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1577: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1575: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1578: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1576: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1583/1789 [1:34:22<00:46,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1580: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1583: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1579: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1581: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1582: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1589/1789 [1:34:22<00:27,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1584: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1587: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1586: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1592: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1585: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1595: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1590: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1595/1789 [1:34:22<00:16, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1593: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1591: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1589: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1598: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1594: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1588: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1597: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1599/1789 [1:34:22<00:14, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1596: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1599: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1605/1789 [1:38:05<40:05, 13.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1602: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1601: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1603: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1600: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1604: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1609/1789 [1:38:05<26:36,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1608: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1605: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1606: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1611: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1610: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1613: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1615/1789 [1:38:05<14:01,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1609: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1607: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1612: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1616: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1618/1789 [1:38:05<09:59,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1614: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1615: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1618: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1621: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1617: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1624: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1619: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1620: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1629/1789 [1:38:06<03:27,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1622: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1627: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1623: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1625: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1626: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1628: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1629: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1630: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1632/1789 [1:38:06<02:38,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1632: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1631: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████▏| 1635/1789 [1:38:07<02:17,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1633: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1634: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1638/1789 [1:38:08<01:43,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1635: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1637: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1636: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1643/1789 [1:38:08<01:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1642: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1638: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1639: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1641: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1640: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1648/1789 [1:38:08<00:33,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1644: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1645: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1648: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1650: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1643: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1651/1789 [1:38:08<00:24,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1646: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1647: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1649: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1652: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1656: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1658/1789 [1:38:09<00:12, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1651: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1655: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1654: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1657: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1661: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1659: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1658: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1653: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1662/1789 [1:38:09<00:09, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1660: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1662: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1663: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1668/1789 [1:41:51<29:15, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1664: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1665: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1666: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1667: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1668: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1671/1789 [1:41:51<20:26, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1673: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1669: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1670: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1672: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1679/1789 [1:41:52<08:04,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1671: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1677: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1676: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1674: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1675: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1679: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1682/1789 [1:41:52<05:50,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1678: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1682: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1685: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1684: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1687: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1680: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1686: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 1694/1789 [1:41:52<01:54,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1683: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1681: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1689: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1688: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1692: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1693: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1690: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1691: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1695: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1694: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1696: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1701/1789 [1:41:54<01:09,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1697: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1700: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1698: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1699: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1701: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1703: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1707/1789 [1:41:54<00:38,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1704: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1705: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1707: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1702: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1710/1789 [1:41:55<00:28,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1706: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1710: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1711: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1708: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1712: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1709: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1714/1789 [1:41:55<00:18,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1713: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1715: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1714: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 1724/1789 [1:41:55<00:07,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1720: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1724: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1721: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1722: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1716: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1717: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1718: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1725: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1723: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1719: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1728/1789 [1:41:55<00:06, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1726: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1727: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1729/1789 [1:45:37<20:04, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1729: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1728: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1733/1789 [1:45:37<11:11, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1730: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1731: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1734: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1732: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1735: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1739/1789 [1:45:38<04:41,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1733: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1736: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1740: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1738: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1739: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1743/1789 [1:45:38<02:31,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1737: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1742: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1741: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1743: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1752/1789 [1:45:38<00:39,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1746: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1749: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1748: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1744: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1747: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1750: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1745: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1757: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1755: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1756/1789 [1:45:38<00:24,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1752: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1751: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1760: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1753: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1759: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1754: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1758: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1756: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▊| 1764/1789 [1:45:40<00:11,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1761: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1762: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1763: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1764: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1768/1789 [1:45:41<00:07,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1765: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1766: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1767: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1770/1789 [1:45:41<00:05,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1769: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1768: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1770: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1773: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1772: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1771: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1778/1789 [1:45:41<00:01,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1778: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1776: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1777: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1774: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|█████████▉| 1784/1789 [1:45:41<00:00, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1775: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1779: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1783: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1780: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1782: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1784: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1787: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1785: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [1:45:42<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1781: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1786: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n",
      "Error processing item 1788: litellm.Timeout: APITimeoutError - Request timed out. \n",
      "error_str: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:   0%|          | 1/1789 [03:38<108:21:45, 218.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   3%|▎         | 60/1789 [03:39<28:00,  1.03it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 92/1789 [03:41<14:44,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 131/1789 [03:41<06:10,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 143/1789 [03:43<05:24,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 152/1789 [03:43<04:30,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 159/1789 [03:43<03:50,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|▉         | 170/1789 [03:44<03:36,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|▉         | 174/1789 [03:44<03:07,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 217/1789 [03:45<01:02, 25.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 223/1789 [03:46<01:13, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 232/1789 [03:46<01:10, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 247/1789 [03:46<00:49, 31.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 260/1789 [03:47<00:53, 28.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 288/1789 [03:48<00:37, 40.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 298: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 297/1789 [03:48<00:57, 26.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 304/1789 [03:48<00:55, 26.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 316/1789 [03:49<00:48, 30.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 321/1789 [03:49<00:51, 28.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 344: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 325/1789 [03:49<01:04, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 332: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 346/1789 [03:50<01:10, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 329: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 368/1789 [03:51<00:39, 36.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 377: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 379/1789 [03:51<00:41, 34.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 372: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██▏       | 384/1789 [03:51<00:44, 31.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 391: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 390/1789 [03:52<01:09, 20.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 398: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 409/1789 [03:53<00:44, 30.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 414: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▎       | 422/1789 [03:53<00:34, 39.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 419: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 428/1789 [03:53<00:36, 37.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 434: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 440/1789 [03:53<00:35, 38.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 444: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 445/1789 [03:53<00:40, 33.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 446: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 452/1789 [03:54<00:48, 27.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 453: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 456/1789 [03:54<01:17, 17.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 469: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 459/1789 [03:55<01:32, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 479: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 464/1789 [04:01<09:17,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 470: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 519/1789 [04:02<00:50, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 532: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|██▉       | 534/1789 [04:03<00:56, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 546/1789 [04:03<00:54, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 567/1789 [04:05<01:02, 19.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 565: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 598/1789 [04:05<00:28, 42.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 609/1789 [04:06<00:52, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 617/1789 [04:16<05:33,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 628/1789 [04:17<04:05,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 640/1789 [04:17<02:29,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 646/1789 [04:17<01:58,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▋      | 652/1789 [04:18<01:46, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 657/1789 [04:18<01:27, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 665/1789 [04:19<01:34, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 701/1789 [04:20<00:34, 31.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 710/1789 [04:20<00:34, 31.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 718/1789 [04:20<00:41, 25.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 724/1789 [04:21<00:45, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 729/1789 [04:27<04:47,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 735/1789 [04:27<03:40,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 744/1789 [04:28<02:58,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 753/1789 [04:28<01:47,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 764/1789 [04:29<01:04, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 775/1789 [04:29<00:43, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 785/1789 [04:29<00:33, 30.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 790/1789 [04:29<00:35, 28.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 794/1789 [04:30<00:43, 22.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 803/1789 [04:30<00:34, 28.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 812/1789 [04:30<00:32, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 823/1789 [04:30<00:25, 37.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 833/1789 [04:31<00:23, 40.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 844/1789 [04:31<00:27, 34.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 852/1789 [04:31<00:30, 31.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 856/1789 [04:31<00:29, 31.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 870: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 864/1789 [04:32<00:38, 24.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 878/1789 [04:32<00:23, 39.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 890/1789 [04:32<00:19, 45.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 901/1789 [04:33<00:19, 46.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 912/1789 [04:33<00:24, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 922/1789 [04:33<00:26, 32.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 918: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 930/1789 [04:34<00:27, 30.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 939/1789 [04:34<00:28, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 943/1789 [04:34<00:27, 30.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 972/1789 [04:35<00:15, 53.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 968: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 981/1789 [04:35<00:24, 32.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 993/1789 [04:36<00:27, 29.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1003: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1002: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1001: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1000: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 998/1789 [04:36<00:30, 26.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1004: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1017: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1011: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1009: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1005: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1002/1789 [04:36<00:28, 27.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1012: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1015: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1040: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1038: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1006/1789 [04:41<04:04,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1007: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1016: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1008: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1006: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1015/1789 [04:42<02:22,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1037: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1060: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1063: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 972: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1039: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1062: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1061: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1018/1789 [04:42<02:24,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1051: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1054: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1055: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1052: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1053: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1030/1789 [04:43<01:09, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1059: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1056: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1066: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1067: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 991: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1058: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1057: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1037/1789 [04:43<00:55, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1069: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1070: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1068: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1064: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1065: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1071: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▊    | 1047/1789 [04:43<00:34, 21.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1021: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1020: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1072: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1019: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1077: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1073: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1028: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1014: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1022: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1018: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1024: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1010: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1026: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1076: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1064/1789 [04:43<00:18, 39.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1031: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1025: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1075: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1074: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1078: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1013: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1079: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1023: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1027: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1029: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1030: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1034: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1035: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1032: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 1070/1789 [04:44<00:18, 39.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1033: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1036: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1045: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1042: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 1076/1789 [04:44<00:20, 34.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1043: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1047: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1041: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1083: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1049: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1085: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1044: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1080: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1086: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1090/1789 [04:44<00:23, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1082: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1087: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1048: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1084: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1050: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1046: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1081: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1088: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1089: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1095: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1094: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1090: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1097: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1093: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████▏   | 1099/1789 [04:44<00:17, 39.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1091: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1098: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1096: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1092: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1104: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1112/1789 [04:45<00:18, 37.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1099: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1110: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1123/1789 [04:45<00:17, 37.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1131: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▎   | 1138/1789 [04:45<00:13, 48.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1141: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1144/1789 [04:46<00:17, 36.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1145: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1149/1789 [04:46<00:19, 33.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1149: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1157/1789 [04:46<00:19, 32.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1155: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1166/1789 [04:46<00:20, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1168: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1170/1789 [04:47<00:21, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1175: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1181/1789 [04:47<00:18, 32.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1190: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1190/1789 [04:48<00:32, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1202: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1212/1789 [04:48<00:14, 40.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1222: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1219/1789 [04:54<02:14,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1243: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1230/1789 [04:55<01:39,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1227: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1234/1789 [04:55<01:25,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1237: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1237/1789 [04:55<01:14,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1284: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1251/1789 [04:56<00:39, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1251: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1261/1789 [04:56<00:26, 19.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1254: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1274/1789 [04:56<00:17, 29.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1286: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████▏  | 1279/1789 [04:57<00:19, 25.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1298: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1300/1789 [04:57<00:12, 40.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1300: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1312/1789 [04:57<00:12, 37.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1318: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▎  | 1317/1789 [04:58<00:15, 30.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1329: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1340/1789 [04:58<00:09, 45.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1334: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 1346/1789 [04:58<00:11, 36.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1355: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1359/1789 [04:59<00:13, 31.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1358: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1375/1789 [04:59<00:09, 43.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1377: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1381/1789 [04:59<00:09, 44.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1386: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1392/1789 [05:07<01:51,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1404: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1403/1789 [05:07<01:01,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1409: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1411/1789 [05:08<00:46,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1439: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1414/1789 [05:08<00:47,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1458: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1424/1789 [05:09<00:26, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1452: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1435/1789 [05:09<00:17, 19.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1468: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1439/1789 [05:09<00:20, 16.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1471: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1443/1789 [05:09<00:19, 17.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1475: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1451/1789 [05:10<00:20, 16.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1489: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████▏ | 1457/1789 [05:10<00:18, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1494: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1470/1789 [05:11<00:10, 30.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1500: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1479/1789 [05:11<00:08, 35.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1503: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1483/1789 [05:11<00:09, 32.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1505: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1487/1789 [05:11<00:14, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1510: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▎ | 1494/1789 [05:12<00:12, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1430: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1506/1789 [05:12<00:07, 36.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1518: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1515/1789 [05:12<00:10, 26.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1529: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▋ | 1544/1789 [05:13<00:04, 56.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1563: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1551/1789 [05:20<01:01,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1545: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1556/1789 [05:20<00:53,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1554: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1565/1789 [05:20<00:33,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1559: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1570/1789 [05:21<00:26,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1564: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1580/1789 [05:21<00:17, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1589: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1591/1789 [05:22<00:11, 16.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1588: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1616/1789 [05:22<00:03, 48.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1617: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1625/1789 [05:22<00:03, 50.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1628: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████▏| 1633/1789 [05:22<00:03, 43.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1639: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1649/1789 [05:23<00:04, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1652: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1663/1789 [05:23<00:03, 35.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1670: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1672/1789 [05:24<00:04, 27.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1693: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▎| 1676/1789 [05:24<00:04, 24.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1692: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1702/1789 [05:25<00:02, 38.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1701: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1710/1789 [05:25<00:02, 34.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1715: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1717/1789 [05:25<00:01, 40.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1711: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 1723/1789 [05:25<00:01, 38.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1723: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1727/1789 [05:25<00:02, 28.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1729: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1744/1789 [05:26<00:01, 36.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1751: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1762/1789 [05:26<00:00, 55.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1763: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1769/1789 [05:26<00:00, 35.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1771: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1774/1789 [05:32<00:03,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1787: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|█████████▉| 1782/1789 [05:34<00:01,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1783: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [05:34<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1779: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 2/1789 [00:01<15:01,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 6/1789 [00:05<25:30,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 14/1789 [00:05<09:19,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|▏         | 25/1789 [00:05<03:40,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▎         | 65/1789 [00:11<03:49,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▎         | 67/1789 [00:11<03:56,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 74/1789 [00:12<03:19,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▍         | 86/1789 [00:12<01:58, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 93/1789 [00:12<01:28, 19.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 129/1789 [00:13<00:35, 46.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 140/1789 [00:14<01:01, 26.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▊         | 156/1789 [00:14<00:49, 32.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 163/1789 [00:14<00:46, 34.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|▉         | 177/1789 [00:14<00:37, 43.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 190/1789 [00:15<00:42, 37.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 198/1789 [00:15<00:36, 43.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█▏        | 204/1789 [00:15<01:01, 25.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 209/1789 [00:15<00:54, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 218/1789 [00:16<00:55, 28.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 241/1789 [00:16<00:30, 50.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 256/1789 [00:16<00:28, 53.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 262/1789 [00:17<00:31, 49.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 268/1789 [00:17<01:01, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 273/1789 [00:24<09:27,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 280/1789 [00:24<06:08,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▋        | 291/1789 [00:25<03:04,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 288: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 302/1789 [00:25<01:46, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 311: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 324/1789 [00:25<00:49, 29.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 325: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▊        | 332/1789 [00:26<00:55, 26.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 333: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 339/1789 [00:26<00:48, 30.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 336: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 345/1789 [00:26<00:59, 24.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 352: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 359/1789 [00:27<00:44, 32.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 355: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 370/1789 [00:27<00:39, 36.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 372: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 375/1789 [00:27<00:40, 35.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 386: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 394/1789 [00:27<00:32, 42.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 393: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 404/1789 [00:28<00:34, 40.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 406: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 415/1789 [00:28<00:48, 28.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 416: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 430/1789 [00:28<00:31, 43.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 432: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 436/1789 [00:29<00:32, 41.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 437: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 453/1789 [00:29<00:36, 36.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 462: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 468/1789 [00:29<00:28, 45.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 501: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▋       | 474/1789 [00:31<02:16,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 500: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 478/1789 [00:35<06:27,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 504: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 486/1789 [00:36<04:02,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 509: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 495/1789 [00:37<03:09,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 479: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 502/1789 [00:37<02:04, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 478: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 516/1789 [00:37<01:07, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 548: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|██▉       | 530/1789 [00:38<00:45, 27.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 515: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 540/1789 [00:38<00:38, 32.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 520: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 545/1789 [00:38<00:35, 35.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 528: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 550/1789 [00:38<00:39, 31.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 535: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 554/1789 [00:38<00:51, 24.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 556: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███▏      | 561/1789 [00:39<00:42, 28.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 568/1789 [00:39<00:42, 28.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 572/1789 [00:39<00:55, 22.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 578/1789 [00:39<00:49, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 584/1789 [00:40<01:31, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▍      | 623/1789 [00:41<00:28, 40.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 639/1789 [00:41<00:33, 34.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 648/1789 [00:43<01:07, 16.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▋      | 651/1789 [00:43<01:36, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 695/1789 [00:48<01:57,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 705/1789 [00:49<01:32, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 719/1789 [00:50<01:13, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 723/1789 [00:50<01:07, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 743/1789 [00:50<00:34, 30.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 748/1789 [00:50<00:36, 28.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 755/1789 [00:51<00:42, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 759/1789 [00:51<00:52, 19.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 763/1789 [00:51<00:56, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 774/1789 [00:52<00:53, 18.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▎     | 779/1789 [00:52<01:09, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 819/1789 [00:52<00:12, 76.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▋     | 831/1789 [00:53<00:28, 34.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 840/1789 [00:54<00:25, 36.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 855/1789 [00:54<00:28, 32.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 886/1789 [00:55<00:17, 50.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 870: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 896/1789 [00:55<00:29, 30.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 904/1789 [01:01<02:46,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 915/1789 [01:02<02:13,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 919/1789 [01:03<02:01,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 931/1789 [01:03<01:11, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 942/1789 [01:03<00:46, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 951/1789 [01:03<00:40, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 968: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 972: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 918: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 967/1789 [01:04<00:23, 34.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 972/1789 [01:04<00:24, 33.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 977/1789 [01:04<00:25, 31.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 985/1789 [01:05<00:35, 22.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1002/1789 [01:05<00:18, 41.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 991: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1000: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1001: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1004: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1002: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1008: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1013/1789 [01:05<00:18, 41.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1006: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1003: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1005: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1013: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1011: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1007: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1019: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1021: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1009: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1016: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1022: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1024: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1018/1789 [01:05<00:18, 42.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1010: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1012: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1014: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1018: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1020: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1023/1789 [01:05<00:23, 33.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1015: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1023: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1027: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1029: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1031: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1038: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1042/1789 [01:06<00:16, 44.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1037: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1034: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1035: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1026: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1033: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1040: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1028: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1030: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1032: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1025: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1017: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1039: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1036: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1042: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1041: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1043: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1044: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1045: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▊    | 1048/1789 [01:06<00:21, 34.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1046: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1047: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1048: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1053/1789 [01:06<00:26, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1052: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1053: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1050: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1049: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1054: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1064: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1063: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 1076/1789 [01:07<00:14, 48.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1071: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1060: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1059: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1058: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1062: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1057: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1055: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1065: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1067: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1066: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1061: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1056: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1069: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1068: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1051: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1075: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1070: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1074: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1072: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1076: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1083/1789 [01:07<00:14, 49.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1081: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1080: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1084: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1078: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1073: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1077: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1082: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1089: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1079: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1085: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1089/1789 [01:07<00:18, 37.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1083: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1086: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1088: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1087: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1090: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1096: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████▏   | 1098/1789 [01:08<00:26, 26.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1091: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1098: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1092: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1093: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1095: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1094: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1097: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1099: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1109: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1117/1789 [01:08<00:24, 27.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1124: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1121/1789 [01:09<00:23, 28.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1135: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1133/1789 [01:15<02:45,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1113: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1136/1789 [01:15<02:20,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1115: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1142/1789 [01:16<01:44,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1147: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1151/1789 [01:16<01:00, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1152: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1157/1789 [01:16<00:50, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1159: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1171/1789 [01:16<00:24, 24.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1174: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1184/1789 [01:17<00:18, 31.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1197: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▋   | 1189/1789 [01:17<00:22, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1190: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1193/1789 [01:17<00:27, 21.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1206: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1199/1789 [01:18<00:24, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1211: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1221/1789 [01:18<00:12, 44.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1223: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1234/1789 [01:18<00:10, 51.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1242: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1240/1789 [01:18<00:14, 39.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1241: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1250/1789 [01:19<00:17, 30.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1251: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1258/1789 [01:19<00:18, 29.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1261: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1267/1789 [01:22<01:14,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1259: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1307/1789 [01:26<00:59,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1301: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1309/1789 [01:27<01:01,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1309: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▎  | 1318/1789 [01:27<00:44, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1308: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1326/1789 [01:28<00:42, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1370: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1338/1789 [01:28<00:24, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1341: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 1349/1789 [01:28<00:16, 26.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1373: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1354/1789 [01:28<00:15, 28.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1378: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1359/1789 [01:29<00:15, 26.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1379: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 1368/1789 [01:29<00:17, 24.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1319: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1380/1789 [01:29<00:11, 35.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1386: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1391/1789 [01:30<00:09, 42.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1390: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1403/1789 [01:30<00:08, 43.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1412: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1409/1789 [01:30<00:08, 42.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1402: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1423/1789 [01:30<00:09, 36.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1424: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1428/1789 [01:31<00:10, 33.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1431: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1433/1789 [01:31<00:10, 33.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1442: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1442/1789 [01:31<00:13, 26.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1439: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1466/1789 [01:32<00:06, 52.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1465: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1478/1789 [01:32<00:06, 48.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1477: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1484/1789 [01:32<00:07, 41.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1485: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1489/1789 [01:33<00:12, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1494: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1501/1789 [01:33<00:13, 21.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1490: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1507/1789 [01:34<00:13, 21.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1500: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1512/1789 [01:35<00:38,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1530: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1553/1789 [01:39<00:26,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1562: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1557/1789 [01:40<00:23,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1567: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1559/1789 [01:40<00:23,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1555: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1565/1789 [01:40<00:22, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1586: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1567/1789 [01:41<00:24,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1563: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1574/1789 [01:41<00:16, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1566: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1581/1789 [01:41<00:12, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1582: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1589/1789 [01:42<00:09, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1624: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1595/1789 [01:42<00:10, 18.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1550: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1599/1789 [01:42<00:08, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1619: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1605/1789 [01:43<00:10, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1635: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1613/1789 [01:43<00:06, 26.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1639: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1620/1789 [01:43<00:06, 26.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1583: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1645/1789 [01:44<00:03, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1609: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1664/1789 [01:44<00:02, 49.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1676: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1670/1789 [01:45<00:04, 28.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1666: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▎| 1675/1789 [01:45<00:05, 20.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1705: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 1693/1789 [01:46<00:03, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1691: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 1723/1789 [01:46<00:01, 45.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1716: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1729/1789 [01:47<00:01, 36.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1742: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1740/1789 [01:47<00:01, 34.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1740: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1753/1789 [01:53<00:07,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1759: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1760/1789 [01:53<00:04,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1772: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1767/1789 [01:53<00:02,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1774: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1773/1789 [01:53<00:01, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1786: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1778/1789 [01:54<00:01,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1737: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|█████████▉| 1782/1789 [01:54<00:00,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1755: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [01:55<00:00, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1787: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:   0%|          | 2/1789 [00:01<13:40,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 4/1789 [00:01<07:22,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 9/1789 [00:02<05:17,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   3%|▎         | 62/1789 [00:02<00:18, 94.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 78/1789 [00:03<00:59, 28.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 90/1789 [00:10<04:32,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 98/1789 [00:10<03:49,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 118/1789 [00:11<02:18, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 125/1789 [00:11<02:01, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 131/1789 [00:11<01:58, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 142/1789 [00:12<01:48, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 146/1789 [00:12<01:49, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 193/1789 [00:13<00:28, 55.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 207/1789 [00:14<00:47, 33.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 217/1789 [00:14<00:49, 31.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 231/1789 [00:15<01:02, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 236/1789 [00:15<00:58, 26.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 267/1789 [00:15<00:31, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 274/1789 [00:16<00:43, 34.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 279/1789 [00:21<04:35,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 283/1789 [00:22<04:06,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 286/1789 [00:23<04:49,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▋        | 294/1789 [00:23<03:23,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 305/1789 [00:24<02:26, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 337/1789 [00:24<00:39, 36.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 346: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 343/1789 [00:24<00:37, 39.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 353: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 356/1789 [00:25<00:37, 38.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 359: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 365/1789 [00:26<00:57, 24.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 363: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 370/1789 [00:26<00:53, 26.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 371: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██▏       | 381/1789 [00:26<00:41, 34.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 384: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 389/1789 [00:26<00:37, 37.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 403: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 414/1789 [00:26<00:27, 50.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 415: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 420/1789 [00:27<00:28, 47.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 421: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 426/1789 [00:27<00:43, 31.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 425: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 431/1789 [00:27<00:58, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 428: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 438/1789 [00:28<00:46, 29.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 432: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 447/1789 [00:28<01:07, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 459: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 469/1789 [00:28<00:33, 39.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 480: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 483/1789 [00:29<00:26, 48.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 486: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 490/1789 [00:34<05:22,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 533: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 506/1789 [00:35<02:43,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 509: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 516/1789 [00:35<02:08,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 527: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 523/1789 [00:36<01:57, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|██▉       | 536/1789 [00:36<01:03, 19.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 563: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 542/1789 [00:36<00:51, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 551/1789 [00:37<01:00, 20.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 556/1789 [00:37<00:51, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 517: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███▏      | 563/1789 [00:38<01:08, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 590/1789 [00:38<00:27, 43.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 607/1789 [00:38<00:20, 57.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 614/1789 [00:39<00:36, 32.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▍      | 620/1789 [00:39<00:41, 28.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 633/1789 [00:39<00:38, 30.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▋      | 650/1789 [00:40<00:25, 45.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 674/1789 [00:40<00:21, 52.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 680/1789 [00:40<00:32, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 685/1789 [00:41<00:36, 29.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▊      | 689/1789 [00:41<00:41, 26.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 696/1789 [00:41<00:51, 21.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 699/1789 [00:42<01:03, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 722/1789 [00:43<01:11, 14.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 724/1789 [00:44<01:49,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 727/1789 [00:48<04:14,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 735/1789 [00:49<03:02,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 749/1789 [00:49<01:24, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 755/1789 [00:49<01:06, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 762/1789 [00:50<01:17, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 768/1789 [00:50<01:04, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 774/1789 [00:51<01:05, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 809/1789 [00:51<00:19, 49.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 822/1789 [00:51<00:17, 54.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▋     | 830/1789 [00:52<00:31, 30.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 842/1789 [00:52<00:30, 31.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 853/1789 [00:53<00:26, 35.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 887/1789 [00:53<00:17, 51.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 870: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 897/1789 [00:54<00:34, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 904/1789 [00:54<00:31, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 916/1789 [01:00<02:35,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 930/1789 [01:02<01:45,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 935/1789 [01:02<01:31,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 918: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 943/1789 [01:02<01:05, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 972: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 957/1789 [01:06<02:08,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 990/1789 [01:07<00:50, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 991: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 968: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1005: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1000: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1001: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1006: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1003/1789 [01:08<00:42, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1009: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1002: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1004: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1007: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1003: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1013/1789 [01:08<00:43, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1020: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1012: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1016: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1010: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1017/1789 [01:10<01:50,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1034: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1014: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1011: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1046: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1013: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1017: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1008: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1019: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1018: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1053: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1024/1789 [01:11<01:48,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1052: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1061: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1047: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1027/1789 [01:13<02:27,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1022: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1029/1789 [01:14<02:54,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1054: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1067: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1036/1789 [01:14<01:46,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1056: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1050: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1029: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1051: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1031: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1035: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1058: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1057: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1030: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1062: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1049: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▊    | 1050/1789 [01:14<00:47, 15.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1044: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1055: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1040: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1038: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1045: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1037: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1028: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1027: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1032: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1039: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1026: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1066: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1024: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1015: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1025: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1033: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1043: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 1065/1789 [01:14<00:25, 28.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1021: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1048: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1059: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1041: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1023: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1060: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1042: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1036: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1068: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1069: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1065: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1090: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1071: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1063: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1070: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 1073/1789 [01:15<00:28, 25.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1072: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1084: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 1082/1789 [01:15<00:28, 24.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1075: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1077: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1086: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1082: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1087: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1078: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1089: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1079: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1080: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1076: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1088: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1073: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1085: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1081: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1083: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1074: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1092/1789 [01:15<00:20, 34.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1092: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1064: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1093: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1095: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1091: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1099: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1104/1789 [01:16<00:18, 36.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1096: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1097: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1094: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1098: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1109: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1117/1789 [01:16<00:17, 38.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1119: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1127/1789 [01:16<00:20, 31.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1129: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▎   | 1139/1789 [01:17<00:16, 38.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1139: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1149/1789 [01:17<00:16, 38.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1146: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1155/1789 [01:17<00:15, 42.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1153: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1160/1789 [01:17<00:19, 32.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1164: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1172/1789 [01:18<00:21, 28.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1174: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1179/1789 [01:18<00:17, 35.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1177: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1184/1789 [01:18<00:22, 27.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1191: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1194/1789 [01:19<00:26, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1193: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1205/1789 [01:19<00:18, 31.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1214: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1212/1789 [01:19<00:24, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1215: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▊   | 1226/1789 [01:20<00:16, 34.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1225: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1230/1789 [01:20<00:16, 34.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1234: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1238/1789 [01:20<00:20, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1239: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1242/1789 [01:20<00:19, 28.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1242: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1245/1789 [01:20<00:28, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1249: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1248/1789 [01:21<00:30, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1247: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1253/1789 [01:21<00:43, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1286: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1264/1789 [01:26<01:53,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1298: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1272/1789 [01:26<01:06,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1253: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1283/1789 [01:26<00:36, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1263: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1294/1789 [01:27<00:36, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1305: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1305/1789 [01:27<00:23, 20.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1333: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1310/1789 [01:27<00:19, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1340: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▎  | 1318/1789 [01:28<00:19, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1341: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1335/1789 [01:28<00:18, 24.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1327: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▌  | 1343/1789 [01:29<00:13, 33.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1363: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 1368/1789 [01:29<00:07, 53.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1371: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1375/1789 [01:29<00:08, 51.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1374: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1381/1789 [01:29<00:09, 42.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1379: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1386/1789 [01:30<00:15, 25.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1387: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1403/1789 [01:30<00:10, 37.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1397: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1409/1789 [01:30<00:09, 39.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1414: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1419/1789 [01:31<00:11, 31.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1422: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1428/1789 [01:31<00:14, 25.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1438: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1447/1789 [01:31<00:07, 43.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1444: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1453/1789 [01:32<00:14, 23.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1458: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████▏ | 1458/1789 [01:32<00:14, 22.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1456: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1467/1789 [01:33<00:12, 24.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1466: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1479/1789 [01:33<00:10, 28.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1489: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1486/1789 [01:34<00:24, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1503: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1509/1789 [01:35<00:18, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1516: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1516/1789 [01:39<00:42,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1514: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1519/1789 [01:39<00:37,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1515: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1522/1789 [01:39<00:36,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1545: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1524/1789 [01:40<00:39,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1540: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1540/1789 [01:40<00:15, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1534: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1549/1789 [01:40<00:09, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1572: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1553/1789 [01:40<00:10, 22.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1559: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1557/1789 [01:41<00:14, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1584: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▊ | 1586/1789 [01:41<00:04, 42.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1585: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1592/1789 [01:42<00:07, 25.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1600: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1602/1789 [01:42<00:06, 27.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1592: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1621/1789 [01:42<00:04, 41.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1630: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1632/1789 [01:43<00:04, 35.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1625: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1642/1789 [01:43<00:05, 27.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1648: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1656/1789 [01:44<00:04, 29.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1652: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1660/1789 [01:44<00:04, 28.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1663: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1670/1789 [01:44<00:03, 33.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1677: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1682/1789 [01:44<00:02, 39.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1681: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 1692/1789 [01:44<00:01, 52.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1688: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 1698/1789 [01:45<00:02, 44.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1708: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1718/1789 [01:46<00:02, 31.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1719: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 1723/1789 [01:47<00:07,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1753: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1727/1789 [01:51<00:19,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1757: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1735/1789 [01:53<00:12,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1730: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1744/1789 [01:53<00:06,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1736: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1754/1789 [01:53<00:02, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1755: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1759/1789 [01:53<00:01, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1756: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1767/1789 [01:54<00:01, 20.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1761: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1775/1789 [01:54<00:00, 20.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1766: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [01:54<00:00, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1773: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:   0%|          | 8/1789 [00:01<03:11,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 16/1789 [00:01<01:37, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▎         | 64/1789 [00:02<00:26, 64.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▍         | 89/1789 [00:08<03:11,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   6%|▌         | 99/1789 [00:10<03:11,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 122/1789 [00:10<01:50, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 143/1789 [00:10<01:02, 26.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 150/1789 [00:11<00:54, 30.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 157/1789 [00:11<01:00, 26.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 163/1789 [00:11<01:07, 23.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▉         | 168/1789 [00:12<01:16, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|▉         | 172/1789 [00:12<01:16, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|█         | 183/1789 [00:12<01:05, 24.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 189/1789 [00:12<01:12, 22.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 224/1789 [00:13<00:25, 62.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 232/1789 [00:13<00:47, 32.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 238/1789 [00:14<00:51, 30.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▎        | 243/1789 [00:14<00:47, 32.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 248/1789 [00:14<00:54, 28.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 257/1789 [00:14<00:56, 27.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 269/1789 [00:15<00:42, 35.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 287/1789 [00:15<00:28, 51.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▋        | 293/1789 [00:15<00:27, 53.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 299/1789 [00:16<01:05, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 309: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 308/1789 [00:21<05:58,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 316/1789 [00:21<03:44,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 334: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 323/1789 [00:22<02:41,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 359: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 353/1789 [00:23<01:17, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 369: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 359/1789 [00:23<01:06, 21.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 371: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 373/1789 [00:23<00:48, 29.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 379: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██▏       | 383/1789 [00:23<00:42, 32.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 409: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 393/1789 [00:24<00:46, 29.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 394: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 407/1789 [00:24<00:38, 35.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 365: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 417/1789 [00:24<00:34, 39.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 422: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 428/1789 [00:25<00:33, 40.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 429: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 437/1789 [00:25<00:42, 32.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 436: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 449/1789 [00:25<00:32, 40.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 444: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 458/1789 [00:26<00:37, 35.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 464: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 464/1789 [00:26<00:35, 37.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 455: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▋       | 473/1789 [00:26<00:44, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 477: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 486/1789 [00:26<00:32, 39.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 485: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 495/1789 [00:27<00:47, 27.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 497: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 501/1789 [00:27<00:40, 31.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 500: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▊       | 513/1789 [00:28<01:04, 19.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 521: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|██▉       | 533/1789 [00:28<00:33, 38.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 538/1789 [00:28<00:33, 37.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 537: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 543/1789 [00:28<00:40, 30.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 542: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 550/1789 [00:29<01:03, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 553: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███▏      | 561/1789 [00:34<05:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 569/1789 [00:34<02:54,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 580/1789 [00:38<05:32,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 617/1789 [00:39<01:07, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▍      | 622/1789 [00:39<01:04, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 630/1789 [00:40<00:58, 19.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 634/1789 [00:40<01:01, 18.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 641/1789 [00:40<00:57, 19.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 644/1789 [00:40<01:00, 18.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 656/1789 [00:41<00:58, 19.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 662/1789 [00:42<01:08, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 676/1789 [00:47<04:50,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 697/1789 [00:47<01:54,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 707/1789 [00:49<01:57,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 716/1789 [00:49<01:18, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 729/1789 [00:49<00:45, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 735/1789 [00:50<00:59, 17.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 744/1789 [00:50<00:45, 23.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 748/1789 [00:50<00:43, 23.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 756/1789 [00:51<00:52, 19.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 787/1789 [00:51<00:16, 59.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 796/1789 [00:51<00:17, 56.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 804/1789 [00:52<00:24, 39.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 815/1789 [00:52<00:32, 29.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 820/1789 [00:52<00:33, 29.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 827/1789 [00:53<01:08, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 865/1789 [00:54<00:16, 56.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 870: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 876/1789 [00:59<02:14,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 890/1789 [01:00<01:48,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 896/1789 [01:00<01:28, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 907/1789 [01:01<01:04, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 918: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 918/1789 [01:01<00:41, 21.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 929/1789 [01:02<00:52, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 954/1789 [01:02<00:26, 31.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 968/1789 [01:03<00:22, 36.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 968: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 980/1789 [01:03<00:21, 37.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 972: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 987/1789 [01:03<00:19, 40.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 993/1789 [01:04<00:49, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1000: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1012/1789 [01:05<00:25, 30.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1017: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1013: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1020: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1009: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1005: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1008: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1001: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1004: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1015: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1010: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1016: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 991: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1006: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1042/1789 [01:05<00:15, 46.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1003: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1012: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1007: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1021: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1002: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1019: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1014: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1025: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1032: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1024: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1034: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1028: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1018: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1029: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1037: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1026: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1011: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1022: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1041: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1027: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1036: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1023: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1033: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1047: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1042: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1030: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1049: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1043: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1039: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1040: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1044: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1031: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1048: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▊    | 1049/1789 [01:06<00:21, 34.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1046: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1035: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1045: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1038: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1051: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1050: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1052: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1055/1789 [01:06<00:29, 25.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1055: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1054: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1053: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1060/1789 [01:07<00:40, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1060: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1057: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1069: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1059: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 1067/1789 [01:07<00:41, 17.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1061: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1064: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1076: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1077: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1065: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1056: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1070: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1068: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1062: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1074: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1066: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1058: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1071: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1067: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1063: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1075: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1098: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1072: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1073: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1085/1789 [01:08<00:34, 20.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1078: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1088: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1095: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1086: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1092: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1081: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1085: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1087: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1082: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1097: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1080: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1090: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1084: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1093: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1094: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1079: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1099: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████▏   | 1100/1789 [01:08<00:23, 29.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1120: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1105/1789 [01:13<02:13,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1083: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1114: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1115/1789 [01:13<01:24,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1091: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1089: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1096: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1101: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1121/1789 [01:13<01:11,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1136: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1125/1789 [01:14<01:14,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1138: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1132/1789 [01:14<00:53, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1165: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1135/1789 [01:14<00:48, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1169: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1144/1789 [01:15<00:36, 17.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1151: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1151/1789 [01:15<00:28, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1117: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1154/1789 [01:15<00:33, 19.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1185: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1166/1789 [01:16<00:29, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1195: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1175/1789 [01:16<00:23, 26.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1142: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1179/1789 [01:16<00:22, 27.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1130: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1195/1789 [01:16<00:18, 32.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1203: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1206/1789 [01:17<00:18, 31.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1217: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1214/1789 [01:17<00:18, 30.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1147: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1218/1789 [01:17<00:23, 24.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1148: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1221/1789 [01:18<00:30, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1232: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1230/1789 [01:18<00:23, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1234: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1239/1789 [01:18<00:15, 34.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1247: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1248/1789 [01:18<00:17, 31.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1256: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1253/1789 [01:19<00:16, 32.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1250: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1261/1789 [01:19<00:20, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1265: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1267/1789 [01:19<00:20, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1264: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1273/1789 [01:20<00:42, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1281: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1294/1789 [01:25<01:33,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1309: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1297/1789 [01:25<01:22,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1314: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1300/1789 [01:26<01:12,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1319: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1302/1789 [01:26<01:09,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1317: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1306/1789 [01:26<00:58,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1324: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1311/1789 [01:27<00:51,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1344: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1328/1789 [01:27<00:15, 28.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1332: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1333/1789 [01:27<00:17, 26.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1302: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1357/1789 [01:28<00:09, 43.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1370: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1363/1789 [01:28<00:12, 34.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1320: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 1368/1789 [01:28<00:16, 25.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1375: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1381/1789 [01:29<00:12, 32.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1394: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1395/1789 [01:29<00:09, 43.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1398: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1401/1789 [01:29<00:11, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1408: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1414/1789 [01:29<00:10, 36.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1411: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1421/1789 [01:30<00:09, 36.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1420: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1426/1789 [01:30<00:10, 34.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1428: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1430/1789 [01:30<00:12, 28.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1433: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1437/1789 [01:30<00:15, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1437: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1450/1789 [01:31<00:15, 22.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1457: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1465/1789 [01:32<00:13, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1464: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1471/1789 [01:32<00:11, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1475: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1478/1789 [01:32<00:14, 21.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1470: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1481/1789 [01:33<00:21, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1496: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1502/1789 [01:39<00:54,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1515: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1510/1789 [01:39<00:37,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1514: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1521/1789 [01:40<00:29,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1559: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1525/1789 [01:40<00:24, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1560: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1535/1789 [01:41<00:16, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1522: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1543/1789 [01:41<00:10, 22.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1530: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1553/1789 [01:41<00:09, 24.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1537: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1571/1789 [01:42<00:06, 31.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1578: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▊ | 1586/1789 [01:42<00:04, 41.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1579: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1591/1789 [01:42<00:05, 36.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1589: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1596/1789 [01:42<00:06, 31.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1606: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1614/1789 [01:43<00:05, 33.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1614: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1622/1789 [01:44<00:11, 14.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1646: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1646/1789 [01:44<00:05, 24.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1642: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1657/1789 [01:45<00:04, 31.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1666: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1669/1789 [01:45<00:05, 20.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1678: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1683/1789 [01:47<00:09, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1694: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 1693/1789 [01:50<00:15,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1703: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1703/1789 [01:51<00:08, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1716: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1707/1789 [01:51<00:06, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1690: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1711/1789 [01:52<00:09,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1720: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1714/1789 [01:52<00:07,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1723: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1717/1789 [01:52<00:08,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1765: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1719/1789 [01:53<00:09,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1753: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 1723/1789 [01:53<00:07,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1693: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1755/1789 [01:53<00:00, 38.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1714: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1770/1789 [01:54<00:00, 31.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1741: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1776/1789 [01:54<00:00, 35.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1735: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|█████████▉| 1787/1789 [01:55<00:00, 30.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1787: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [01:55<00:00, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1788: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Items:   0%|          | 1/1789 [00:01<32:38,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 3/1789 [00:01<18:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 4/1789 [00:03<23:39,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 5/1789 [00:03<17:21,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▎         | 65/1789 [00:08<02:58,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 68/1789 [00:09<03:06,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 76/1789 [00:09<02:26, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▍         | 89/1789 [00:09<01:27, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 96/1789 [00:09<01:09, 24.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   6%|▋         | 112/1789 [00:10<00:50, 32.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 125/1789 [00:10<00:41, 40.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 135/1789 [00:13<03:33,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 141/1789 [00:14<03:19,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▊         | 156/1789 [00:14<01:57, 13.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 201/1789 [00:16<00:38, 41.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 212/1789 [00:22<03:56,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 220/1789 [00:22<03:15,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 227/1789 [00:22<02:46,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 240/1789 [00:22<01:55, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 252/1789 [00:23<01:21, 18.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 265/1789 [00:23<00:54, 28.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 271/1789 [00:23<00:59, 25.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 276/1789 [00:23<01:12, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 280/1789 [00:24<01:14, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 283/1789 [00:24<01:22, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 288: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 286/1789 [00:24<01:37, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▋        | 292/1789 [00:25<01:59, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▋        | 294/1789 [00:25<02:28, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 307: litellm.APIError: APIError: OpenAIException - Connection error."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 297/1789 [00:26<04:07,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error processing item 298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 347/1789 [00:27<00:36, 39.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 348: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 356/1789 [00:27<00:41, 34.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 362: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 360/1789 [00:27<00:43, 32.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 383: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 364/1789 [00:28<00:50, 28.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 358: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 371/1789 [00:28<01:18, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 366: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██▏       | 383/1789 [00:29<00:56, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 380: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 387/1789 [00:34<07:09,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 396: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 393/1789 [00:34<04:58,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 410: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 408/1789 [00:34<02:06, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 423: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 418/1789 [00:35<01:47, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 426: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▎       | 422/1789 [00:35<01:36, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 428: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 425/1789 [00:35<01:28, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 439: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 428/1789 [00:35<01:32, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 448: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 431/1789 [00:36<01:37, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 446: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 433/1789 [00:36<02:12, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 471: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▋       | 472/1789 [00:36<00:31, 42.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 481: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 480/1789 [00:37<00:32, 40.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 486: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 487/1789 [00:37<00:42, 30.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 432: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 492/1789 [00:37<00:49, 26.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 490: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 499/1789 [00:38<01:07, 18.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 508: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 505/1789 [00:39<01:37, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 501: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 550/1789 [00:40<00:28, 42.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 556: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 557/1789 [00:40<00:37, 32.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 567/1789 [00:41<00:54, 22.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 571/1789 [00:41<00:55, 22.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 584/1789 [00:46<03:25,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 590/1789 [00:46<02:52,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 583: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 594/1789 [00:46<02:20,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▎      | 603/1789 [00:47<01:59,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 606/1789 [00:47<02:26,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 613/1789 [00:48<01:45, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 616/1789 [00:48<01:57,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 639/1789 [00:49<00:39, 29.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 645/1789 [00:49<00:38, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▋      | 650/1789 [00:49<00:37, 30.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 677: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 659/1789 [00:50<00:53, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 665/1789 [00:50<00:44, 25.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 682/1789 [00:50<00:35, 30.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▊      | 690/1789 [00:51<00:40, 27.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▊      | 693/1789 [00:51<00:50, 21.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 705/1789 [00:51<00:43, 25.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 713/1789 [00:52<00:36, 29.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|████      | 722/1789 [00:52<00:33, 32.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 726/1789 [00:52<00:56, 18.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 734/1789 [00:53<00:45, 23.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████▏     | 738/1789 [00:53<00:47, 22.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 745/1789 [00:53<00:37, 27.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 749/1789 [00:53<00:41, 25.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 758/1789 [00:54<01:00, 17.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 760/1789 [00:54<01:16, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 787/1789 [00:59<02:24,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 794/1789 [00:59<01:48,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 797/1789 [00:59<01:34, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 804/1789 [00:59<01:13, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 810/1789 [01:00<00:53, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 816/1789 [01:00<01:11, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 821/1789 [01:00<00:53, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 827/1789 [01:01<01:12, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▋     | 831/1789 [01:02<01:38,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 870: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 875/1789 [01:02<00:13, 65.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 889/1789 [01:03<00:26, 33.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 919/1789 [01:05<00:42, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 918: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 950/1789 [01:05<00:20, 40.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 957/1789 [01:06<00:36, 22.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 962/1789 [01:12<02:38,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 972: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 967/1789 [01:12<02:15,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1008: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 981/1789 [01:12<01:20, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1007: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 991: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1001: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1004: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1003: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1002: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1009: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1011: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1010: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1005: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 993/1789 [01:13<00:52, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1018: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1015: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1016: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1001/1789 [01:13<00:57, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1022: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1026: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1023: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1025: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1018/1789 [01:14<00:28, 26.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1029: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 968: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1024: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1031: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1035: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1027: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1030: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1028: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1033: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1037: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1034: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1032: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1039: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1038: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1039/1789 [01:14<00:23, 32.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1045: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1049: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1044: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1041: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1036: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1051: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1043: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1055: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1047: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1046: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1042: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1048: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1050: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1055/1789 [01:15<00:17, 42.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1040: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1056: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1054: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1012: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1053: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1052: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1014: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1013: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1058: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1000: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1006: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1057: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1021: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1060: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1019: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1065: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 1069/1789 [01:16<00:33, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1059: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1064: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1067: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1061: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1066: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1078: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1017: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1070: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1074: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1063: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 1073/1789 [01:16<00:37, 19.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1072: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1069: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1076: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1081: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1020: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1084: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1077: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1071: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1062: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1068: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1079: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1075: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1073: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1089: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1080: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1087: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1086: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1082: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1092: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1083: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1085: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1088: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1091: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1098: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1094: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████▏   | 1099/1789 [01:16<00:22, 30.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1097: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1090: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1096: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1093: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1099: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1107/1789 [01:17<00:25, 26.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1095: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1122: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1122/1789 [01:17<00:16, 41.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1121: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1131/1789 [01:18<00:22, 29.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1134: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▎   | 1138/1789 [01:18<00:32, 19.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1154: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1152/1789 [01:19<00:29, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1135: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1172/1789 [01:19<00:15, 40.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1164: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1178/1789 [01:23<02:08,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1191: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▋   | 1188/1789 [01:24<01:22,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1193: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1196/1789 [01:25<01:16,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1198: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1202/1789 [01:25<00:59,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1214: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1208/1789 [01:26<00:42, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1249: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1211/1789 [01:26<00:59,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1253: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1221/1789 [01:27<00:34, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1255: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▊   | 1229/1789 [01:27<00:26, 21.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1262: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1234/1789 [01:27<00:21, 25.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1197: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1242/1789 [01:27<00:22, 23.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1270: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1253/1789 [01:28<00:18, 28.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1231: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|███████   | 1261/1789 [01:28<00:19, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1222: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████▏  | 1278/1789 [01:29<00:17, 29.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1279: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1284/1789 [01:29<00:15, 32.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1280: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1293/1789 [01:29<00:18, 26.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1300: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1301/1789 [01:29<00:17, 27.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1302: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1307/1789 [01:30<00:16, 29.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1303: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1314/1789 [01:30<00:18, 26.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1316: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▎  | 1319/1789 [01:31<00:28, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1315: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1329/1789 [01:31<00:24, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1324: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1334/1789 [01:32<00:49,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1356: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1361/1789 [01:37<01:04,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1366: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 1367/1789 [01:37<00:54,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1368: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1378/1789 [01:37<00:33, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1369: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1383/1789 [01:38<00:42,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1392: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1387/1789 [01:41<01:36,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1393: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1390/1789 [01:42<01:37,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1390: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1392/1789 [01:43<01:42,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1447: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1448/1789 [01:43<00:14, 23.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1454: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████▏ | 1455/1789 [01:44<00:19, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1451: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1462/1789 [01:44<00:18, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1505: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1467/1789 [01:47<00:34,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1508: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1471/1789 [01:50<01:01,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1511: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1474/1789 [01:51<01:08,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1512: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1480/1789 [01:51<00:52,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1525: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1489/1789 [01:52<00:36,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1509: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1525/1789 [01:52<00:07, 37.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1542: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1558/1789 [01:54<00:08, 26.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1573: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1566/1789 [01:54<00:07, 28.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1581: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1580/1789 [01:54<00:05, 35.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1583: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▊ | 1586/1789 [01:55<00:08, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1571: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1591/1789 [01:55<00:08, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1579: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1595/1789 [01:56<00:14, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1597: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1604/1789 [01:56<00:09, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1628: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1611/1789 [01:57<00:13, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1608: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1614/1789 [01:57<00:12, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1644: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1643/1789 [02:03<00:23,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1659: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1645/1789 [02:03<00:24,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1674: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1651/1789 [02:04<00:20,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1647: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1663/1789 [02:04<00:10, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1706: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1671/1789 [02:05<00:09, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1669: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▎| 1677/1789 [02:05<00:07, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1676: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1689/1789 [02:06<00:04, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1710: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1700/1789 [02:06<00:04, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1686: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1706/1789 [02:06<00:04, 19.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1728: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1734/1789 [02:07<00:01, 34.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1738: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1744/1789 [02:07<00:01, 32.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1744: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1753/1789 [02:08<00:00, 38.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1754: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1757/1789 [02:08<00:00, 33.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1759: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1761/1789 [02:08<00:01, 25.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1760: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1779/1789 [02:09<00:00, 33.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1788: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [02:09<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1774: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 1/1789 [00:03<1:38:02,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 8/1789 [00:05<12:56,  2.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 11/1789 [00:05<08:58,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 21/1789 [00:06<04:12,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|▏         | 23/1789 [00:06<03:42,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   3%|▎         | 48/1789 [00:07<01:13, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   3%|▎         | 58/1789 [00:07<01:05, 26.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 72/1789 [00:07<00:46, 36.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 77/1789 [00:07<01:02, 27.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▍         | 81/1789 [00:08<01:03, 26.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▍         | 88/1789 [00:08<01:43, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 121/1789 [00:09<00:33, 50.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 137/1789 [00:09<00:30, 53.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 144/1789 [00:10<01:20, 20.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▊         | 153/1789 [00:11<01:44, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 207/1789 [00:12<00:35, 44.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 220/1789 [00:18<03:22,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 230/1789 [00:19<02:54,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 238/1789 [00:19<02:30, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▍        | 266/1789 [00:19<01:21, 18.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 285/1789 [00:21<01:28, 16.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  17%|█▋        | 296/1789 [00:21<01:28, 16.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▊        | 333/1789 [00:22<00:27, 53.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 334: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 340/1789 [00:22<00:48, 29.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 348: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 351/1789 [00:23<00:44, 32.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 376: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 356/1789 [00:23<00:56, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 365: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 365/1789 [00:23<00:53, 26.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 384: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 376/1789 [00:24<01:07, 20.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 396: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 402/1789 [00:24<00:25, 54.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 403: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 409/1789 [00:24<00:35, 38.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 405: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 418/1789 [00:25<00:57, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 427: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 425/1789 [00:26<01:14, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 446: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▍       | 447/1789 [00:28<01:51, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 456: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 449/1789 [00:31<04:22,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 465: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  25%|██▌       | 456/1789 [00:31<03:19,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 475: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▌       | 465/1789 [00:31<02:27,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 474: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▋       | 470/1789 [00:32<02:19,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 479: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  26%|██▋       | 473/1789 [00:32<02:06, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 485: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 481/1789 [00:32<01:25, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 499: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 495/1789 [00:33<00:45, 28.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 441: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▊       | 511/1789 [00:33<00:27, 45.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 528: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 518/1789 [00:34<00:56, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 532: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 527/1789 [00:34<00:51, 24.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 544: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 537/1789 [00:34<00:39, 31.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 545: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  30%|███       | 542/1789 [00:34<00:47, 26.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 563: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 579/1789 [00:35<00:19, 61.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 587/1789 [00:36<00:33, 35.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 599/1789 [00:36<00:33, 35.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 604/1789 [00:36<00:39, 29.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 608/1789 [00:36<00:43, 27.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 646/1789 [00:38<00:30, 36.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 656/1789 [00:38<00:28, 39.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 671/1789 [00:45<03:26,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 682/1789 [00:46<02:27,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 687/1789 [00:46<02:14,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 736/1789 [00:47<00:32, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 750/1789 [00:48<00:42, 24.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 760/1789 [00:49<00:38, 26.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 801/1789 [00:50<00:22, 44.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 811/1789 [00:50<00:22, 42.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 819/1789 [00:56<03:09,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 825/1789 [00:56<02:44,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 837/1789 [00:57<01:43,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 843/1789 [00:58<01:57,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 866/1789 [00:58<00:48, 19.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 880/1789 [01:00<01:14, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 885/1789 [01:00<01:14, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 870: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 917/1789 [01:01<00:45, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 931/1789 [01:02<00:36, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 918: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 939/1789 [01:02<00:34, 24.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 944/1789 [01:02<00:30, 27.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 956/1789 [01:04<00:53, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 968: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 964/1789 [01:04<00:49, 16.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 970/1789 [01:04<00:36, 22.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 972: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 977/1789 [01:05<01:24,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1006: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1005: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1000/1789 [01:09<01:51,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 991: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1011: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1021: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1005/1789 [01:09<01:40,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1002: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1007: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1001: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1000: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1017: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1008: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1016/1789 [01:10<01:00, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1003: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1010: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1009: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1014: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1004: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1022: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1012: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1020/1789 [01:10<01:15, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1020: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1024: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1016: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1033: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1023: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1026: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1024/1789 [01:10<01:03, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1013: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1031: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1029: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1015: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1019: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1018: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1028: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1031/1789 [01:11<00:56, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1025: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1038/1789 [01:13<01:47,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1038: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1046: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1032: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1027: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1030: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1042: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1043: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1076: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1061: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1063: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1045: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1072: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1050: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1041: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1034: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1056: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1067: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1059: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1055: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1047: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1040: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1079: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1074: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1052: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1065: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1064: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1058: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1071: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1044: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1060: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1035: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1066: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1039: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1049: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1036: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1075: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1080: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1068: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1073: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1077: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 1074/1789 [01:13<00:20, 35.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1048: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1062: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1051: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1070: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1069: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1037: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1053: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1078: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1089: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1054: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1081: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1084/1789 [01:14<00:28, 24.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1091: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1088: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1085: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1057: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1082: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1083: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1087: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1092/1789 [01:14<00:29, 23.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1093: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1084: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1090: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1086: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1092: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1097: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1111/1789 [01:22<02:06,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1096: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1095: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1111: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1133/1789 [01:23<01:03, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1099: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1147: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1142/1789 [01:23<00:50, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1094: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1098: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1143: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1149/1789 [01:24<00:53, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1151: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1161/1789 [01:25<01:05,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1185: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1202/1789 [01:25<00:16, 35.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1207: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1212/1789 [01:26<00:23, 25.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1216: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1220/1789 [01:27<00:23, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1224: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▊   | 1226/1789 [01:27<00:22, 24.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1245: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1232/1789 [01:28<00:33, 16.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1232: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1288/1789 [01:30<00:12, 39.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1313: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1301/1789 [01:31<00:18, 26.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1320: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1311/1789 [01:34<00:51,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1340: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1324/1789 [01:35<00:41, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1344: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1329/1789 [01:35<00:35, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1310: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1351/1789 [01:35<00:18, 23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1368: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1362/1789 [01:36<00:19, 22.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1370: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1371/1789 [01:37<00:26, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1363: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1420/1789 [01:38<00:07, 49.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1427: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|███████▉  | 1430/1789 [01:39<00:12, 29.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1429: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1437/1789 [01:39<00:12, 27.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1455: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1447/1789 [01:41<00:30, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1475: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▎ | 1498/1789 [01:42<00:06, 46.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1520: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1510/1789 [01:43<00:08, 33.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1528: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1519/1789 [01:47<00:33,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1521: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1528/1789 [01:47<00:25, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1549: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1541/1789 [01:48<00:18, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1558: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▋ | 1547/1789 [01:48<00:16, 14.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1562: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1558/1789 [01:48<00:12, 18.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1568: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1562/1789 [01:49<00:15, 15.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1580: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1569/1789 [01:49<00:11, 19.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1593: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1581/1789 [01:49<00:07, 27.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1596: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▊ | 1586/1789 [01:49<00:06, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1573: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1593/1789 [01:50<00:10, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1571: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████ | 1627/1789 [01:51<00:03, 44.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1626: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  91%|█████████▏| 1633/1789 [01:51<00:03, 39.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1633: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1638/1789 [01:51<00:05, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1645: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1653/1789 [01:52<00:04, 29.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1653: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1657/1789 [01:52<00:04, 28.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1678: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1665/1789 [01:53<00:06, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1667: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▎| 1674/1789 [01:53<00:04, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1680: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1687/1789 [01:53<00:03, 29.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1692: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 1696/1789 [01:54<00:03, 30.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1701: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1700/1789 [01:54<00:03, 28.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1702: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1705/1789 [01:54<00:03, 26.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1706: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1708/1789 [01:54<00:03, 21.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1710: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1714/1789 [01:55<00:04, 17.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1708: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1727/1789 [01:55<00:01, 35.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1748: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1741/1789 [02:00<00:08,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1770: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1762/1789 [02:01<00:02, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1736: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1768/1789 [02:01<00:01, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1745: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1778/1789 [02:02<00:00, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1775: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [02:02<00:00, 14.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1781: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 1/1789 [00:01<34:08,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 5/1789 [00:01<06:44,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   1%|          | 9/1789 [00:02<06:41,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   3%|▎         | 58/1789 [00:02<00:31, 54.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   4%|▍         | 72/1789 [00:04<01:09, 24.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 122/1789 [00:05<00:40, 40.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 133/1789 [00:10<03:38,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 141/1789 [00:12<03:42,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 147/1789 [00:12<03:13,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▊         | 154/1789 [00:12<02:34, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|▉         | 172/1789 [00:12<01:28, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  10%|█         | 186/1789 [00:13<00:57, 27.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 192/1789 [00:13<01:37, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 197/1789 [00:14<01:30, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 201/1789 [00:14<01:25, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 213/1789 [00:14<00:59, 26.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 223/1789 [00:15<01:19, 19.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 255/1789 [00:15<00:25, 60.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 273/1789 [00:16<00:55, 27.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 280/1789 [00:16<00:48, 30.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 286/1789 [00:17<00:51, 29.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▋        | 291/1789 [00:18<01:48, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 321/1789 [00:19<01:27, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  18%|█▊        | 325/1789 [00:22<03:18,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 329: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 345/1789 [00:23<01:48, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 321: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 351/1789 [00:23<01:52, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 352: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 356/1789 [00:24<02:01, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 387: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|██        | 364/1789 [00:24<01:39, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 357: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 372/1789 [00:25<01:20, 17.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 390: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 390/1789 [00:25<00:48, 28.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 374: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 404/1789 [00:25<00:31, 44.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 338: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 411/1789 [00:25<00:33, 41.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 419: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 417/1789 [00:26<01:10, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 423: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 426/1789 [00:27<01:23, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 354: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 429/1789 [00:27<01:47, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 435: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 434/1789 [00:28<02:04, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 477: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 479/1789 [00:28<00:22, 57.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 492: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 492/1789 [00:29<00:35, 36.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 496: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 502/1789 [00:29<00:36, 35.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 494: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▊       | 510/1789 [00:29<00:41, 30.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 523: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▉       | 521/1789 [00:30<01:06, 19.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 552/1789 [00:31<00:34, 35.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 561: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███▏      | 562/1789 [00:32<00:45, 26.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 570/1789 [00:36<02:43,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 579/1789 [00:36<02:16,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 577: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 586/1789 [00:36<01:43, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 591/1789 [00:37<01:36, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  33%|███▎      | 598/1789 [00:37<01:25, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  34%|███▍      | 613/1789 [00:37<00:44, 26.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 628/1789 [00:38<00:49, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 635/1789 [00:38<00:59, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 656/1789 [00:39<00:27, 40.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 663/1789 [00:39<00:32, 34.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  37%|███▋      | 669/1789 [00:39<00:44, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  38%|███▊      | 678/1789 [00:40<00:48, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 696/1789 [00:40<00:32, 33.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 705/1789 [00:42<01:29, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 710/1789 [00:42<01:40, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 746/1789 [00:46<01:53,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 751/1789 [00:47<01:56,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 754/1789 [00:49<02:35,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 760/1789 [00:49<02:14,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 766/1789 [00:49<01:48,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 786/1789 [00:50<00:47, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 790/1789 [00:50<00:52, 18.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▌     | 807/1789 [00:51<00:35, 28.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  46%|████▌     | 816/1789 [00:52<00:58, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 848/1789 [00:52<00:21, 43.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 859/1789 [00:53<00:33, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▉     | 873/1789 [00:54<00:39, 22.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 870: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|████▉     | 890/1789 [00:54<00:34, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  50%|█████     | 895/1789 [00:54<00:35, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 911/1789 [00:55<00:28, 30.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 916/1789 [00:55<00:29, 29.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 918: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 920/1789 [00:55<00:30, 28.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 924/1789 [00:56<00:49, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 927/1789 [00:56<00:49, 17.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 936/1789 [00:57<00:47, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 939/1789 [00:57<00:51, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 941/1789 [01:01<06:22,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 952/1789 [01:02<02:40,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▎    | 960/1789 [01:02<01:35,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 972: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  54%|█████▍    | 974/1789 [01:02<00:48, 16.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 985/1789 [01:03<00:37, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 968: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 993/1789 [01:03<00:44, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 991: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1006: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1003: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1001: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1002/1789 [01:04<00:39, 19.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1004: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1009: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1007: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1010: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1005: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1016: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1011/1789 [01:04<00:45, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1013: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1008: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1021: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1017: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1020: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1023: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▊    | 1049/1789 [01:05<00:11, 66.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1019: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1011: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1014: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1022: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1027: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1018: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1012: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1015: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1028: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1024: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1025: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1031: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1030: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1002: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1036: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1026: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1000: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1029: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1035: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1039: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1040: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1041: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1032: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1034: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1046: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1043: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1033: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1042: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1045: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1047: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1038: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1037: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1044: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1050: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1049: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1048: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1053: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1051: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1052: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  59%|█████▉    | 1060/1789 [01:05<00:18, 39.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1057: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1061: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1059: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1058: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1056: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1055: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1062: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1060: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1064: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1054: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1065: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1063: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|█████▉    | 1069/1789 [01:06<00:29, 24.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1074: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1075: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1076: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1068: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1079: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1067: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1072: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1090: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1077: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1069: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  60%|██████    | 1082/1789 [01:07<00:28, 24.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1099: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1083: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1073: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1080: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1095: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1093: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1091/1789 [01:07<00:36, 19.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1092: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1071: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1070: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1085: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1084: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1091: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1082: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1089: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1087: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1098: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1066: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1094: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1078: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1088: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1081: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1086: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1096: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1097: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1106: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1116/1789 [01:07<00:17, 39.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1124: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1130/1789 [01:08<00:20, 31.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1136: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1135/1789 [01:09<00:30, 21.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1135: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1133: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▎   | 1139/1789 [01:13<02:38,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1183: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  64%|██████▍   | 1153/1789 [01:14<01:20,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1138: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1157/1789 [01:15<01:30,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1193: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1160/1789 [01:15<01:25,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1194: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1163/1789 [01:15<01:25,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1200: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1166/1789 [01:16<01:27,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1148: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1212/1789 [01:17<00:17, 33.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1212: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1220/1789 [01:17<00:15, 37.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1195: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▊   | 1228/1789 [01:17<00:17, 32.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1231: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1234/1789 [01:18<00:29, 18.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1240: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1242/1789 [01:18<00:24, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1252: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1247/1789 [01:19<00:26, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1235: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1291/1789 [01:20<00:12, 39.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1308: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1304/1789 [01:21<00:17, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1306: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1313/1789 [01:21<00:18, 25.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1315: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1320/1789 [01:22<00:20, 23.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1348: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1335/1789 [01:23<00:23, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1351: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▌  | 1362/1789 [01:27<00:44,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1362: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 1366/1789 [01:27<00:39, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1364: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1369/1789 [01:27<00:38, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1366: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1372/1789 [01:27<00:40, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1376: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1376/1789 [01:28<00:36, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1380: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1382/1789 [01:28<00:33, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1387: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1384/1789 [01:29<00:49,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1423: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1387/1789 [01:30<01:39,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1384: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1404: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1435: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  80%|████████  | 1440/1789 [01:30<00:07, 44.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1446: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1453/1789 [01:31<00:13, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1449: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1463/1789 [01:32<00:14, 22.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1486: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▎ | 1494/1789 [01:33<00:09, 29.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1483: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1501: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1503/1789 [01:33<00:09, 30.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1507: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1510/1789 [01:34<00:10, 26.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1511: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▍ | 1516/1789 [01:34<00:13, 19.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1524: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1525/1789 [01:35<00:12, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1513: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  85%|████████▌ | 1529/1789 [01:40<01:14,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1558: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  86%|████████▌ | 1537/1789 [01:41<00:56,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1571: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1577/1789 [01:41<00:09, 21.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1584: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1583/1789 [01:41<00:10, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1590: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1592/1789 [01:42<00:09, 21.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1597: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1603/1789 [01:42<00:07, 26.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1611: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1610/1789 [01:43<00:14, 12.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1612: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1644/1789 [01:43<00:03, 42.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1639: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1620: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1652/1789 [01:44<00:04, 32.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1651: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1658/1789 [01:44<00:04, 31.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1665: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1663/1789 [01:44<00:03, 33.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1671: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1668/1789 [01:45<00:04, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1672: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▎| 1675/1789 [01:45<00:05, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1673: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1682/1789 [01:46<00:06, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1679: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 1691/1789 [01:46<00:04, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1683: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▍| 1694/1789 [01:46<00:04, 20.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1690: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1702/1789 [01:47<00:06, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1717: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1719/1789 [01:47<00:02, 31.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1716: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1729/1789 [01:48<00:01, 34.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1732: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1734/1789 [01:48<00:01, 30.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1733: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1738/1789 [01:53<00:15,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1743: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1744/1789 [01:53<00:09,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1744: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1748/1789 [01:53<00:06,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1758: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1751/1789 [01:54<00:06,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1781: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1772/1789 [01:54<00:01, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1753: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  99%|█████████▉| 1778/1789 [01:54<00:00, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1751: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [01:55<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1772: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 1/1789 [00:00<25:17,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 14: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 3/1789 [00:01<10:14,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 4: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 5/1789 [00:01<08:45,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 9: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 12: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   0%|          | 6/1789 [00:02<13:38,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 11: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 20: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   3%|▎         | 62/1789 [00:03<00:30, 55.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 23: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 24: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 19: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 2: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 31: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 28: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 38: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 44: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 5: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 13: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 43: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 33: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 45: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 35: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 51: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 42: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 27: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 3: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 36: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 54: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 37: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 0: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 25: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 34: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 49: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 10: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 47: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 22: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 29: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 17: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 61: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 32: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 7: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 40: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 15: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 62: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 8: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 52: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 50: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 6: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 16: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 55: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 53: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 26: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 57: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 21: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 56: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 46: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 39: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 18: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 58: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 59: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 48: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 63: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 30: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 60: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 41: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 64: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 66: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 67: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 65: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 91: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 70: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 68: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 76: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 72: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 79: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 75: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 91/1789 [00:05<01:25, 19.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 74: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 98: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 82: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 69: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 96: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 71: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 89: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 81: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 94: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 97: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 77: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   5%|▌         | 97/1789 [00:05<01:18, 21.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 92: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 78: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 88: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 83: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 73: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 95: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 119: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 85: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 87: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 126: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 90: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 125: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 122/1789 [00:10<03:00,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 86: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 99: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 106: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 126/1789 [00:10<02:45, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 84: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 93: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 80: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   7%|▋         | 129/1789 [00:11<03:08,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 145: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 136/1789 [00:11<02:32, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 135: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 139/1789 [00:11<02:15, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 177: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 143/1789 [00:11<02:14, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 184: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   8%|▊         | 152/1789 [00:12<02:05, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 181: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 143: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:   9%|▊         | 154/1789 [00:13<03:03,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 190: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  11%|█         | 196/1789 [00:13<00:32, 48.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 155: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 163: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 162: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 195: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 207: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 202: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  12%|█▏        | 208/1789 [00:14<00:51, 30.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 209: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 210: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  13%|█▎        | 224/1789 [00:15<00:52, 29.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 228: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 244: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 212: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▎        | 245/1789 [00:15<00:40, 37.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 248: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 240: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 252: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 242: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  14%|█▍        | 257/1789 [00:16<00:58, 26.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 257: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 253: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 272/1789 [00:16<00:46, 32.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 272: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  15%|█▌        | 277/1789 [00:17<01:20, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 276: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 281/1789 [00:22<07:50,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 309: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 312: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▌        | 287/1789 [00:22<05:25,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 288: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 295: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  16%|█▋        | 294/1789 [00:28<13:42,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 279: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  19%|█▉        | 345/1789 [00:28<01:35, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 304: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 278: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 285: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 321: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 298: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 335: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 340: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 345: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 350: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  20%|█▉        | 357/1789 [00:30<02:08, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 386: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 366: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  21%|██        | 373/1789 [00:31<01:54, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 389: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 383: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 362: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 404: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  22%|██▏       | 396/1789 [00:35<02:49,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 384: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 407/1789 [00:35<01:59, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 405: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 408: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 415/1789 [00:36<02:05, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 415: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  23%|██▎       | 418/1789 [00:36<02:04, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 421: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 423: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 426/1789 [00:37<01:35, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 420: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  24%|██▍       | 434/1789 [00:38<02:16,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 449: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 428: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 475: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 478: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  27%|██▋       | 480/1789 [00:38<00:26, 48.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 484: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 483: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 493/1789 [00:39<00:36, 35.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 493: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 495: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 499/1789 [00:39<00:33, 38.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 491: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 499: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  28%|██▊       | 508/1789 [00:40<01:04, 19.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 519: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  29%|██▊       | 514/1789 [00:40<01:28, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 511: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 546: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 554/1789 [00:41<00:29, 41.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 552: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  31%|███       | 559/1789 [00:41<00:33, 36.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 550: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 569/1789 [00:42<00:50, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 567: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 564: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 575/1789 [00:43<01:42, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 570: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  32%|███▏      | 579/1789 [00:43<01:39, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 576: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 593: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 595: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 581: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▍      | 618/1789 [00:48<02:10,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 611: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 622: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 628/1789 [00:48<01:35, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 626: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 624: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  35%|███▌      | 635/1789 [00:49<01:34, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 634: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 638/1789 [00:49<01:26, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 639: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 645/1789 [00:49<01:16, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 644: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  36%|███▌      | 648/1789 [00:49<01:10, 16.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 678: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 656: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 677: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 658: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▊      | 692/1789 [00:50<00:23, 47.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 681: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 659: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 665: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 700: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 661: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 702: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  39%|███▉      | 703/1789 [00:51<00:25, 42.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 705: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  40%|███▉      | 712/1789 [00:51<00:35, 30.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 709: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  41%|████      | 728/1789 [00:53<01:05, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 735: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 713: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  42%|████▏     | 750/1789 [00:53<00:30, 33.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 724: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 727: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 749: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 758: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 766/1789 [00:54<00:32, 31.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 722: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 743: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 769: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 772/1789 [00:54<00:34, 29.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 776: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  43%|████▎     | 777/1789 [00:55<00:59, 17.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 775: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▎     | 781/1789 [00:55<01:07, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 792: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 778: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 806: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 799: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 812: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 805: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 780: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 787/1789 [00:55<00:55, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 790: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 809: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 801: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 810: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 817: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 793/1789 [00:57<01:31, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 795: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 813: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  44%|████▍     | 796/1789 [01:00<04:07,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 789: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 796: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 800/1789 [01:01<04:05,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 819: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 794: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 803: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  45%|████▍     | 804/1789 [01:01<03:29,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 822: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 811: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 815: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 808: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 828: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 797: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 827: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 821: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 802: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 814: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 791: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 820: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 836: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 824: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 838: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 823: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 830: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 793: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 832: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 785: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 804: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 816: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 798: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 826: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 831: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 829: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 800: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 837: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 833: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 807: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 818: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 835: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 839: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 825: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 834: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 841/1789 [01:02<00:36, 25.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 840: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 841: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  47%|████▋     | 846/1789 [01:02<00:42, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 843: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 842: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 844: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 845: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 850: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 848: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 847: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 850/1789 [01:02<00:39, 23.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 861: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 849: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 860: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 853: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 846: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 860/1789 [01:03<00:46, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 852: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 854: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 857: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 858: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 855: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 863: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  48%|████▊     | 865/1789 [01:03<00:38, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 882: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 856: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 865: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 851: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 859: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  49%|████▊     | 869/1789 [01:04<01:04, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 864: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 872: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 870: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 879: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 874: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 873: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 895: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████     | 911/1789 [01:04<00:15, 56.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 888: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 878: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 891: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 868: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 862: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 885: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 881: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 866: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 869: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 871: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 880: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 889: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 884: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 875: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 900: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 886: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 903: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 876: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 892: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 902: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 890: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 893: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 898: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 877: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 904: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 899: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 883: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 897: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 901: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 894: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 896: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 887: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 867: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 906: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 907: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 908: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 912: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 913: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 905: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 910: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 911: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 914: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 917: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 918: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 909: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 915: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  51%|█████▏    | 921/1789 [01:05<00:29, 29.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 920: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 916: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 919: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 921: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 933: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  52%|█████▏    | 929/1789 [01:05<00:31, 27.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 940: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 924: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 929: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 927: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 928: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 931: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 926: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 922: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 942/1789 [01:06<00:29, 29.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 934: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 925: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 932: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 970: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 937: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 963: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 964: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 935: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 948: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 951: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 938: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 923: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  53%|█████▎    | 951/1789 [01:07<00:46, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 960: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 957: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 962: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 969: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 971: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 930: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 968: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 945: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 944: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 946: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 954: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 955: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▍    | 979/1789 [01:07<00:18, 43.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 959: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 943: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 965: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 950: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 936: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 952: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 972: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 967: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 973: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 949: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 961: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 958: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 974: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 941: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 975: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 966: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 939: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 947: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 953: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 956: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 976: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 942: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 978: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 980: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 982: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 977: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 979: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 983: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 981: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 985: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 984: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  55%|█████▌    | 988/1789 [01:13<02:28,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 988: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 992: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1005: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 987: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 989: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 986: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 990: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 991: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▌    | 1000/1789 [01:13<01:39,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 996: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 999: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 997: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 995: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1002: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1003: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 998: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 993: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1001: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1007: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  56%|█████▋    | 1010/1789 [01:13<01:08, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 994: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1021: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1037: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1012: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1035: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1004: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1015: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1017: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1014: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1006: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1016: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1016/1789 [01:14<01:06, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1049: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1048: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  57%|█████▋    | 1023/1789 [01:15<01:10, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1059: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1057: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1046: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1060: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1064: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1061: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1029/1789 [01:15<00:53, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1058: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1062: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1065: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1066: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1067: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1063: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1025: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1022: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1013: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  58%|█████▊    | 1036/1789 [01:16<01:30,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1009: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1030: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1038: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1040: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1019: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1031: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  61%|██████    | 1093/1789 [01:17<00:09, 72.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1043: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1023: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1041: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1050: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1044: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1008: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1026: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1024: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1032: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1020: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1053: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1033: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1069: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1055: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1080: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1010: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1056: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1028: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1029: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1045: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1042: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1018: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1074: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1079: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1052: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1039: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1000: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1070: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1071: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1036: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1034: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1076: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1078: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1085: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1073: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1051: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1077: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1027: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1054: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1081: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1047: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1083: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1082: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1072: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1086: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1091: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1068: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1088: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1011: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1084: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1090: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1075: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1087: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1089: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1092: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1094: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1093: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1098: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1102: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1123: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1110: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1100: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1095: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1099: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1103: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1120: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1122: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1126: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  62%|██████▏   | 1109/1789 [01:19<00:24, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1117: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1105: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1124: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1109: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1107: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1106: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1119: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1120/1789 [01:19<00:23, 28.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1127: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1111: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1129: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1114: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1115: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1108: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1128: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1138: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1097: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1112: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1121: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1104: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1118: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1101: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1156: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1135: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  63%|██████▎   | 1129/1789 [01:19<00:22, 29.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1149: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1116: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1131: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1150: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1151: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1113: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1096: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1136: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1132: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1147: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1130: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1134: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1153: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1142: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1152: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1145: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1125: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1137: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1139: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1154: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1141: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1146: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1144: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1133: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1143: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1148: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1140: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1155: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▍   | 1158/1789 [01:20<00:15, 39.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1157: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1158: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1160: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1162: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  65%|██████▌   | 1171/1789 [01:21<00:23, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1166: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1165: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1159: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1168: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1172: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1173: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1169: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1174: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1170: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1161: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1167: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1171: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1164: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1163: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1176/1789 [01:26<01:50,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1177: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1175: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1181: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  66%|██████▌   | 1184/1789 [01:26<01:22,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1182: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1180: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1183: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1178: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1220: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1189: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1184: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1195: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1191/1789 [01:26<01:02,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1214: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1198: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1179: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1219: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1186: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1190: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1193: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1209: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  67%|██████▋   | 1194/1789 [01:27<01:01,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1187: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1212: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1217: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1204: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1185: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1210: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1206: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1213: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1211: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1196: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1201: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1192: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1205: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1194: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1191: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1176: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1218: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1188: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1203: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1202: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1199: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1197: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1216: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1215: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1200: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1208: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1207: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  68%|██████▊   | 1222/1789 [01:27<00:20, 27.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1221: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1222: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1227: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1229: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1228: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1231/1789 [01:27<00:21, 26.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1226: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1225: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1223: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1232: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1239: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1240: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  69%|██████▉   | 1240/1789 [01:28<00:18, 30.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1231: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1237: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1241: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1230: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1242: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1235: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1247: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1244: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1247/1789 [01:28<00:15, 34.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1234: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1224: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1233: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1238: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1236: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1246: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1245: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1243: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1248: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  70%|██████▉   | 1252/1789 [01:28<00:15, 34.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1249: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1253: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1255: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1262: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1250: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1265: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1257: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1264/1789 [01:29<00:39, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1251: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1260: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1263: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1254: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1256: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1276: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1259: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1252: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  71%|███████   | 1270/1789 [01:29<00:31, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1268: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1261: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1272: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1271: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1279: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1278: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1281/1789 [01:30<00:27, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1282: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1269: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1267: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1264: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1266: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1281: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1283: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1301: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1273: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1284: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1288: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  72%|███████▏  | 1291/1789 [01:30<00:19, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1258: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1270: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1286: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1280: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1275: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1274: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1277: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1290: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1289: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1287: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1297: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1285: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1299/1789 [01:31<00:21, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1294: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1296: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1291: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1293: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1299: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1298: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1302/1789 [01:31<00:30, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1295: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1300: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1304: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  73%|███████▎  | 1305/1789 [01:31<00:33, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1292: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1306: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1303: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1307: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1312: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1309: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1324/1789 [01:32<00:18, 25.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1317: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1314: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1320: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1316: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1311: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1308: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1326: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1324: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1305: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1315: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1319: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1310: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1329: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1318: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1313: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1302: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1325: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1327: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1321: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  74%|███████▍  | 1329/1789 [01:32<00:18, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1322: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1328: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1334: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1323: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1335: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1333/1789 [01:33<00:20, 21.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1330: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1333: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1341: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1332: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1345: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  75%|███████▍  | 1340/1789 [01:33<00:29, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1337: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1344: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1340: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  76%|███████▋  | 1368/1789 [01:34<00:12, 33.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1336: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1351: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1368: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1347: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1348: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1353: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1358: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1361: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1360: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1370: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1346: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1338: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1349: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1365: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1367: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1350: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1369: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1354: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1366: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1375: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1357: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1363: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1343: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1331: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1339: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1371: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1342: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1362: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1375/1789 [01:34<00:11, 35.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1352: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1355: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1359: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1356: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1364: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1379: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1382: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1380: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1373: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1383: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1381/1789 [01:39<01:21,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1397: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1398: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1399: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1372: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1384: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  77%|███████▋  | 1386/1789 [01:39<01:08,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1376: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1381: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1378: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1386: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  78%|███████▊  | 1390/1789 [01:40<00:59,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1392: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1388: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1387: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1393: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1385: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1389: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▊  | 1407/1789 [01:40<00:23, 15.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1409: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1391: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1396: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1395: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1394: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1415: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1390: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1374: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1377: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1408: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1426: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1419: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1410: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1421: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1412/1789 [01:40<00:22, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1401: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1400: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1441: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1402: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1404: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1416/1789 [01:41<00:27, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1443: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1442: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1446: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1428: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  79%|███████▉  | 1419/1789 [01:41<00:31, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1403: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1429: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1405: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  81%|████████  | 1445/1789 [01:42<00:11, 29.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1444: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1416: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1438: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1450: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1413: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1422: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1432: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1417: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1447: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1434: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1412: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1425: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1433: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1431: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1440: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1437: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1445: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1414: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1439: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1435: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1424: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1406: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1452: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1448: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1430: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1449: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  82%|████████▏ | 1469/1789 [01:43<00:09, 33.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1458: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1469: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1418: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1436: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1453: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1461: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1427: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1466: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1420: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1423: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1407: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1462: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1411: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1460: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1465: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1457: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1463: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1470: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1454: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1468: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1455: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1451: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1467: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1474: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1472: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1459: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1456: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1471: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1475: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1477/1789 [01:43<00:12, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1464: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1480: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1473: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1479: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1476: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1478: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1485: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1484: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1483/1789 [01:43<00:12, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1477: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1488: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1490: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1481: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1497: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1482: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1483: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  83%|████████▎ | 1493/1789 [01:44<00:14, 20.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1492: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1495: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1498: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1502: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1494: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1493: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▎ | 1497/1789 [01:44<00:17, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1513: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1496: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1515: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1489: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1491: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  84%|████████▍ | 1504/1789 [01:46<00:28,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1486: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1504: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1531: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1511: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  87%|████████▋ | 1554/1789 [01:47<00:05, 39.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1518: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1519: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1500: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1501: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1503: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1499: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1530: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1487: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1517: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1512: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1525: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1528: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1510: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1527: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1522: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1516: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1505: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1532: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1521: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1508: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1507: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1542: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1533: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1535: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1534: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1506: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1538: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1550: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1520: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1524: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1544: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1526: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1539: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1549: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1543: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1555: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1547: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1529: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1546: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1554: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1552: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1540: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1509: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1537: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1553: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1551: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1541: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1536: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1523: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1514: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1545: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1556: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1557: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1548: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1563: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1589: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1575: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1574: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1585: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1581: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1571: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1584: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1590: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1576: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1569/1789 [01:52<00:25,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1586: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1580: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1593: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  88%|████████▊ | 1580/1789 [01:53<00:21,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1562: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1564: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1558: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1566: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1560: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1559: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1583: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1570: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1568: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1573: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1561: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1572: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1588: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1569: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1582: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1565: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1587: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1567: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  89%|████████▉ | 1590/1789 [01:53<00:16, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1578: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1579: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1606: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1621: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1591: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1604: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1607: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1595: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|████████▉ | 1605/1789 [02:00<00:38,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1609: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1597: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1628: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1599: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1608: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1600: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1605: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1639: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  90%|█████████ | 1614/1789 [02:01<00:30,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1637: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1614: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1602: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1646: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1594: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1643: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1603: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1616: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1618: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1652: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1615: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1601: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1624: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1642: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1619: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1622: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1636: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1634: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1644: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1650: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1627: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1617: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1640: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1625: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1635: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1623: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1633: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1596: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1629: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1641: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1638: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1632: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1654: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1653: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1645: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1651: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1648: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1598: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1630: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1631: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1647: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1649: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1626: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1649/1789 [02:04<00:14,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1657: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1620: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1611: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  92%|█████████▏| 1654/1789 [02:04<00:14,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1577: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1655: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1656: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1656/1789 [02:05<00:16,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1662: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1660: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1613: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1661: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1658/1789 [02:05<00:14,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1612: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1610: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1592: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1658: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1665: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1669/1789 [02:06<00:09, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1671: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1663: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1713: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1712: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1670: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1659: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  93%|█████████▎| 1672/1789 [02:06<00:08, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1664: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1667: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1666: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1669: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1672: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1674: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1693: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1714: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1668: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1676: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1698: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1679: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1681: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  94%|█████████▍| 1689/1789 [02:06<00:05, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1703: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1709: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1685: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1692: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1682: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1694: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1678: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1702/1789 [02:07<00:03, 24.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1683: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1684: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1708: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1696: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1715: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1690: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1680: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1691: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1695: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1706: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1701: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1717: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1700: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  95%|█████████▌| 1707/1789 [02:07<00:03, 26.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1688: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1699: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1707: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1716: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1718: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1677: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1712/1789 [02:07<00:02, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1702: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1710: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1705: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1711: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1697: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1704: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1673: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1722: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▌| 1720/1789 [02:08<00:03, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1687: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1719: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1689: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1686: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1720: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1724: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  96%|█████████▋| 1726/1789 [02:08<00:03, 17.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1725: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1675: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1721: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1726: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1723: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1729: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1727: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1736/1789 [02:09<00:02, 21.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1732: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1734: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1731: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1728: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1730: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1742: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1737: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1736: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1735: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  97%|█████████▋| 1744/1789 [02:09<00:02, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1739: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1744: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1745: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1738: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1754: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1752: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1740: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1733: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1748: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1743: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1753/1789 [02:09<00:01, 25.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1755: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1747: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1741: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1757: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1749: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items:  98%|█████████▊| 1761/1789 [02:10<00:01, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1750: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1768: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1753: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1765: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1770: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1761: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1764: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1751: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1785: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 1789/1789 [02:10<00:00, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing item 1767: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1784: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1760: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1774: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1771: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1772: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1758: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1763: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1766: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1759: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1780: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1779: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1777: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1775: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1782: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1781: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1762: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1776: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1787: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1746: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1756: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1788: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1773: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1783: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1769: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1786: litellm.APIError: APIError: OpenAIException - Connection error.\n",
      "Error processing item 1778: litellm.APIError: APIError: OpenAIException - Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train.add_metrics(new_metrics_final)\n",
    "dev.add_metrics(new_metrics_final)\n",
    "test.add_metrics(new_metrics_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelryan/Documents/School/Stanford/Research/autometrics/autometrics/evaluate/correlation.py:65: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_correlations_all[target_column][metric_column] = correlation(df[target_column], df[metric_column])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top 1 Metric &amp; Value</th>\n",
       "      <th>Top 2 Metric &amp; Value</th>\n",
       "      <th>Top 3 Metric &amp; Value</th>\n",
       "      <th>Top 4 Metric &amp; Value</th>\n",
       "      <th>Top 5 Metric &amp; Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>helpfulness</th>\n",
       "      <td>Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness</th>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complexity</th>\n",
       "      <td>Engagement_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbosity</th>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Engagement_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Top 1 Metric & Value  \\\n",
       "helpfulness     Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "correctness  Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "coherence       Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "complexity     Engagement_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "verbosity    Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "\n",
       "                                                          Top 2 Metric & Value  \\\n",
       "helpfulness              Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "correctness  Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "coherence                Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "complexity                       Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "verbosity                  Engagement_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "\n",
       "                                                          Top 3 Metric & Value  \\\n",
       "helpfulness  Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "correctness                 Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "coherence    Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "complexity               Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "verbosity                        Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "\n",
       "                                                          Top 4 Metric & Value  \\\n",
       "helpfulness                 Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "correctness                 Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "coherence                   Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "complexity   Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "verbosity    Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "\n",
       "                                           Top 5 Metric & Value  \n",
       "helpfulness       Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)  \n",
       "correctness       Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)  \n",
       "coherence         Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)  \n",
       "complexity   Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)  \n",
       "verbosity    Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_top_5_metrics_by_validation(dev, test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for target in tqdm(dataset.get_target_columns()):\n",
    "    aggregator = Ridge(dataset=train, name=f'Ridge_{target}_llm')\n",
    "    aggregator.ensure_dependencies(train)\n",
    "    aggregator.ensure_dependencies(dev)\n",
    "    aggregator.ensure_dependencies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Completeness_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Coherence_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Relevance_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Tone_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Engagement_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Accuracy_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Informative value_Meta-Llama-3.1-70b-Instruct_rubric',\n",
       " 'Conciseness_Meta-Llama-3.1-70b-Instruct_rubric']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.get_metric_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "for target in tqdm(dataset.get_target_columns()):\n",
    "    aggregator = Ridge(dataset=train, name=f'Ridge_{target}_llm')\n",
    "    aggregator.learn(train, target)\n",
    "    aggregator.predict(train)\n",
    "    aggregator.predict(dev)\n",
    "    aggregator.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelryan/Documents/School/Stanford/Research/autometrics/autometrics/evaluate/correlation.py:65: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_correlations_all[target_column][metric_column] = correlation(df[target_column], df[metric_column])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top 1 Metric &amp; Value</th>\n",
       "      <th>Top 2 Metric &amp; Value</th>\n",
       "      <th>Top 3 Metric &amp; Value</th>\n",
       "      <th>Top 4 Metric &amp; Value</th>\n",
       "      <th>Top 5 Metric &amp; Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>helpfulness</th>\n",
       "      <td>Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Informative value_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Conciseness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness</th>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Informative value_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Conciseness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Rg_helpfulness_llm (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coherence</th>\n",
       "      <td>Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complexity</th>\n",
       "      <td>Engagement_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Informative value_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Conciseness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Rg_verbosity_llm (nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbosity</th>\n",
       "      <td>Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Engagement_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Informative value_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "      <td>Conciseness_Meta-Llama-3.1-70b-Instruct_rubric (nan)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Top 1 Metric & Value  \\\n",
       "helpfulness     Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "correctness  Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "coherence       Coherence_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "complexity     Engagement_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "verbosity    Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "\n",
       "                                                    Top 2 Metric & Value  \\\n",
       "helpfulness        Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "correctness  Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "coherence          Completeness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "complexity   Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "verbosity            Engagement_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "\n",
       "                                                          Top 3 Metric & Value  \\\n",
       "helpfulness        Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "correctness         Informative value_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "coherence    Contextual understanding_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "complexity          Informative value_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "verbosity          Grammar and syntax_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "\n",
       "                                                   Top 4 Metric & Value  \\\n",
       "helpfulness  Informative value_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "correctness        Conciseness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "coherence            Relevance_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "complexity         Conciseness_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "verbosity    Informative value_Meta-Llama-3.1-70b-Instruct_rubric (nan)   \n",
       "\n",
       "                                             Top 5 Metric & Value  \n",
       "helpfulness  Conciseness_Meta-Llama-3.1-70b-Instruct_rubric (nan)  \n",
       "correctness                              Rg_helpfulness_llm (nan)  \n",
       "coherence           Tone_Meta-Llama-3.1-70b-Instruct_rubric (nan)  \n",
       "complexity                                 Rg_verbosity_llm (nan)  \n",
       "verbosity    Conciseness_Meta-Llama-3.1-70b-Instruct_rubric (nan)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_top_5_metrics_by_validation(dev, test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelryan/Documents/School/Stanford/Research/autometrics/autometrics/evaluate/correlation.py:65: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_correlations_all[target_column][metric_column] = correlation(df[target_column], df[metric_column])[0]\n",
      "/Users/michaelryan/Documents/School/Stanford/Research/autometrics/autometrics/evaluate/correlation.py:65: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_correlations_all[target_column][metric_column] = correlation(df[target_column], df[metric_column])[0]\n",
      "/Users/michaelryan/Documents/School/Stanford/Research/autometrics/autometrics/evaluate/correlation.py:65: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_correlations_all[target_column][metric_column] = correlation(df[target_column], df[metric_column])[0]\n",
      "/Users/michaelryan/Documents/School/Stanford/Research/autometrics/autometrics/evaluate/correlation.py:65: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_correlations_all[target_column][metric_column] = correlation(df[target_column], df[metric_column])[0]\n",
      "/Users/michaelryan/Documents/School/Stanford/Research/autometrics/autometrics/evaluate/correlation.py:65: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_correlations_all[target_column][metric_column] = correlation(df[target_column], df[metric_column])[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for target_column in dataset.target_columns:\n",
    "    metric = get_top_metric_by_validation(dev, target_column, True)\n",
    "    plot_metric_target_scatterplot(test, metric, target_column)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
