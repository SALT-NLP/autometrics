{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/auto_eval/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Is the model proficient in applying empathy and emotional intelligence to its responses when the user conveys emotions or faces challenging circumstances?]\n",
      "Score 1: The model neglects to identify or react to the emotional tone of user inputs, giving responses that are unfitting or emotionally insensitive.\n",
      "Score 2: The model intermittently acknowledges emotional context but often responds without sufficient empathy or emotional understanding.\n",
      "Score 3: The model typically identifies emotional context and attempts to answer with empathy, yet the responses might sometimes miss the point or lack emotional profundity.\n",
      "Score 4: The model consistently identifies and reacts suitably to emotional context, providing empathetic responses. Nonetheless, there may still be sporadic oversights or deficiencies in emotional depth.\n",
      "Score 5: The model excels in identifying emotional context and persistently offers empathetic, emotionally aware responses that demonstrate a profound comprehension of the user's emotions or situation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m score_rubric \u001b[38;5;241m=\u001b[39m SCORE_RUBRIC_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrubric_data)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(score_rubric)\n\u001b[0;32m---> 28\u001b[0m feedback, score \u001b[38;5;241m=\u001b[39m judge\u001b[38;5;241m.\u001b[39msingle_absolute_grade(\n\u001b[1;32m     29\u001b[0m     instruction\u001b[38;5;241m=\u001b[39minstruction,\n\u001b[1;32m     30\u001b[0m     response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m     31\u001b[0m     rubric\u001b[38;5;241m=\u001b[39mscore_rubric,\n\u001b[1;32m     32\u001b[0m     reference_answer\u001b[38;5;241m=\u001b[39mreference_answer\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedback:\u001b[39m\u001b[38;5;124m\"\u001b[39m, feedback)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore:\u001b[39m\u001b[38;5;124m\"\u001b[39m, score)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/auto_eval/lib/python3.12/site-packages/prometheus_eval/judge.py:81\u001b[0m, in \u001b[0;36mPrometheusEval.single_absolute_grade\u001b[0;34m(self, instruction, response, rubric, reference_answer, params)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_absolute_grade\u001b[39m(\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     65\u001b[0m     instruction: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m     70\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    Grades a single response absolutely based on the provided instruction and response.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    :return: A tuple containing the feedback and score.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     feedbacks, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabsolute_grade(\n\u001b[1;32m     82\u001b[0m         instructions\u001b[38;5;241m=\u001b[39m[instruction],\n\u001b[1;32m     83\u001b[0m         responses\u001b[38;5;241m=\u001b[39m[response],\n\u001b[1;32m     84\u001b[0m         rubric\u001b[38;5;241m=\u001b[39m[rubric],\n\u001b[1;32m     85\u001b[0m         reference_answers\u001b[38;5;241m=\u001b[39m[reference_answer] \u001b[38;5;28;01mif\u001b[39;00m reference_answer \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[1;32m     86\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feedbacks[\u001b[38;5;241m0\u001b[39m], scores[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/auto_eval/lib/python3.12/site-packages/prometheus_eval/judge.py:200\u001b[0m, in \u001b[0;36mPrometheusEval.absolute_grade\u001b[0;34m(self, instructions, responses, rubric, reference_answers, params)\u001b[0m\n\u001b[1;32m    197\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mappend(input_)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_async:\n\u001b[0;32m--> 200\u001b[0m     feedbacks, scores \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    201\u001b[0m         async_batch_completions_with_retries(\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    203\u001b[0m             inputs,\n\u001b[1;32m    204\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    205\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    206\u001b[0m         )\n\u001b[1;32m    207\u001b[0m     )\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     feedbacks, scores \u001b[38;5;241m=\u001b[39m batch_completions_with_retries(\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    211\u001b[0m         inputs,\n\u001b[1;32m    212\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    213\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    214\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/auto_eval/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# Absolute Grading: Outputs score of 1 to 5\n",
    "\n",
    "from prometheus_eval.litellm import LiteLLM\n",
    "from prometheus_eval import PrometheusEval\n",
    "from prometheus_eval.prompts import ABSOLUTE_PROMPT, SCORE_RUBRIC_TEMPLATE\n",
    "\n",
    "# model = VLLM(model=\"prometheus-eval/prometheus-7b-v2.0\")\n",
    "model = LiteLLM('openai/prometheus-eval/prometheus-7b-v2.0', api_base=\"http://jagupard37:8000/v1\", api_key='None') # VLLM endpoint\n",
    "judge = PrometheusEval(model=model, absolute_grade_template=ABSOLUTE_PROMPT)\n",
    "\n",
    "instruction = \"Struggling with a recent break-up, a person opens up about the intense feelings of loneliness and sadness. They ask for advice on how to cope with the heartbreak and move forward in life.\",\n",
    "response = \"I'm genuinely sorry to hear about your break-up. This can be an immensely challenging time filled with intense emotions of loneliness and sorrow. It's important to remember that it's normal to experience these feelings; they are a testament to the deep connection you once had. Firstly, don't hesitate to embrace your emotions, let them flow freely. Ignoring them often complicates the healing process. It's natural to be upset, to shed tears, or to feel angry. This is all part of the journey towards healing. Self-care can be a healing balm in these tough times. This could mean indulging in your favourite book, journaling your thoughts, or even just a quiet cup of tea. Small acts of kindness to oneself can significantly improve your emotional well-being. Also, don't isolate yourself. Surround yourself with supportive individuals who can offer comfort and understanding. This might include friends, family, or even a mental health professional. They can provide much-needed emotional support and strategies to help you cope. Lastly, remember there's no set timeline for healing. It's different for everyone and it's okay to take as long as you need. Keep your focus on the future and the potential it holds. Though it may not seem possible now, you will emerge stronger from this experience. It's okay to ask for help, it's okay to grieve, and it's okay to take it one day at a time. You're not alone in this journey, and there are people ready and willing to help. It's okay to heal at your own pace.\",\n",
    "reference_answer = \"I can only imagine how difficult this time must be for you. Heartbreak can feel like an overwhelming wave that washes over you, making you feel lost and alone. It's important to remember that it's okay to feel this way; your feelings are valid and it's natural to grieve the loss of a relationship. Firstly, it's crucial to allow yourself to feel the emotions fully. Suppressing or denying them often only prolongs the healing process. It's okay to cry, to feel sad, or to be angry. These are all part of the healing journey. Engaging in self-care activities can also provide a much-needed boost. This could be anything from taking a warm bath, writing in a journal, or simply drinking a cup of your favorite tea. Small acts of self-love can make a big difference in how you feel. Next, try to surround yourself with supportive people who understand your situation and provide comfort. Friends and family can be a great source of strength in times of heartbreak. If you feel comfortable, you might want to consider seeking professional help. Therapists and counselors are trained to provide assistance and tools to navigate through difficult times like these. Lastly, it's important to remember that it's okay to take your time to heal. Everyone has their own pace and there's no rush. Try to focus on the future and the possibilities it holds. While it may not seem like it now, you will come out stronger and more resilient from this experience. Remember, it's okay to ask for help and it's okay to feel the way you feel. You are not alone in this journey and there are people who care about you and want to help. It's okay to take one day at a time. Healing is a process, and it's okay to move through it at your own pace.\",\n",
    "\n",
    "rubric_data = {\n",
    "  \"criteria\":\"Is the model proficient in applying empathy and emotional intelligence to its responses when the user conveys emotions or faces challenging circumstances?\",\n",
    "  \"score1_description\":\"The model neglects to identify or react to the emotional tone of user inputs, giving responses that are unfitting or emotionally insensitive.\",\n",
    "  \"score2_description\":\"The model intermittently acknowledges emotional context but often responds without sufficient empathy or emotional understanding.\",\n",
    "  \"score3_description\":\"The model typically identifies emotional context and attempts to answer with empathy, yet the responses might sometimes miss the point or lack emotional profundity.\",\n",
    "  \"score4_description\":\"The model consistently identifies and reacts suitably to emotional context, providing empathetic responses. Nonetheless, there may still be sporadic oversights or deficiencies in emotional depth.\",\n",
    "  \"score5_description\":\"The model excels in identifying emotional context and persistently offers empathetic, emotionally aware responses that demonstrate a profound comprehension of the user's emotions or situation.\"\n",
    "}\n",
    "\n",
    "score_rubric = SCORE_RUBRIC_TEMPLATE.format(**rubric_data)\n",
    "\n",
    "print(score_rubric)\n",
    "\n",
    "feedback, score = judge.single_absolute_grade(\n",
    "    instruction=instruction,\n",
    "    response=response,\n",
    "    rubric=score_rubric,\n",
    "    reference_answer=reference_answer\n",
    ")\n",
    "\n",
    "print(\"Feedback:\", feedback)\n",
    "print(\"Score:\", score)\n",
    "\n",
    "# Output\n",
    "# Feedback: The response provided shows a high level of empathy and emotional intelligence. It effectively addresses the emotional distress expressed by the user. It acknowledges the user's pain and validates their feelings of loneliness and sadness, which is a crucial aspect of providing empathetic advice. The response also suggests practical steps for coping, such as embracing emotions, practicing self-care, and seeking support from friends, family, or professionals. Furthermore, the response reassures the user that healing is a personal process with no fixed timeline, offering comfort and understanding. It emphasizes the user's worth and potential to overcome the situation, which demonstrates a profound comprehension of the user's emotions and situation. By comparing the score rubric with the provided response, it is clear that the model exhibits an excellent ability to apply empathy and emotional intelligence. The response does not have any deficiencies in emotional depth and successfully meets the criteria for a score of 5.\n",
    "# Score: 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
