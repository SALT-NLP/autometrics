{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec208fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/mryan0/.conda/envs/autometrics/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autometrics.dataset.datasets import RealHumanEval\n",
    "from autometrics.util.analysis import display_top_5_metrics_by_validation, get_top_metric_by_validation, plot_metric_target_scatterplot\n",
    "from autometrics.aggregator.regression import Ridge\n",
    "from autometrics.generator.LLMJudgeProposer import LLMJudgeProposer\n",
    "import dspy\n",
    "import litellm\n",
    "from tqdm import tqdm\n",
    "\n",
    "litellm.suppress_debug_info = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a00ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "humaneval_prompt = \"\"\"You are an expert Python programmer, be helpful to the user and return code only in Python.\"\"\"\n",
    "\n",
    "task_prompt = humaneval_prompt\n",
    "\n",
    "# %%\n",
    "dataset = RealHumanEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b976b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1000 Validation size: 1000 Test size: 1000\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "train, dev, test = dataset.get_splits(train_ratio=0.2, val_ratio=0.2, seed=42, max_size=1000)\n",
    "\n",
    "print(\"Train size:\", len(train.dataframe), \"Validation size:\", len(dev.dataframe), \"Test size:\", len(test.dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0df27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def count_nums(arr):\\n    total = 0\\n    total_greater_than_0 = 0\\n    for number in arr:\\n        string = str(number)\\n        print(string)\\n        if string[0] == \"-\":\\n            number = -number\\n            total += -int(string[1])\\n            rest = str(number)[1:]\\n            # print(f\"the rest: {rest}\")\\n        else:\\n            # print(int(string[0]))\\n\\n            total = total + int(string[0])\\n            # print(f\"total: {total}\")\\n\\n            rest = str(number)[1:]\\n        print(rest)\\n        for dig in rest:\\n            total += int(dig)\\n            # print(f\"dig {total}\")\\n        if total > 0:\\n            total_greater_than_0 +=1\\n    return total_greater_than_0\\n    \\n# print(count_nums([1,1,2]))\\nprint(count_nums([1,1,2,-2,3,4,[CODE GOES HERE]2]))\\n        \\n            \\n                \\n            \\n\\n            ',\n",
       " 'def count_nums(arr):\\n    count = 0\\n    for num in arr:\\n        num_str = str(num)\\n        running_sum = 0[CODE GOES HERE]\\n            \\n        for char in num_str:\\n            if neg == False:\\n            running_sum+=int(char)\\n                \\n        \\n        if runnging_sum > 0:\\n            count += 1\\n    return count\\n            ',\n",
       " '\\nclass LoginAuthenticator:\\n    def __init__(self):\\n        # DO NOT CHANGE\\n        self.user_credentials = {}  # dictionary for username: hashed_password\\n\\n    def _hash_password(self, password):\\n        # WRITE CODE HERE\\n        hashPass = password + \"ishashed\"\\n        return return hashPass\\n\\n    def add_user(self, username, password):\\n        # WRITE CODE HERE\\n        if username in self.user_credentials:\\n            [CODE GOES HERE]\\n        return\\n\\n    def authenticate_user(self, username, password):\\n        # DO NOT CHANGE\\n        #Checks if the given username and password are valid\\n        if username not in self.user_credentials:\\n            return False\\n        return self.user_credentials[username] == self._hash_password(password)\\n\\n    def remove_user(self, username):\\n        # WRITE CODE HERE\\n        return\\n\\n    def change_password(self, username, old_password, new_password):\\n        # WRITE CODE HERE\\n        return\\n',\n",
       " 'def sum_product(numbers):\\n    s =0\\n    p = 1\\n    for num in numbers:\\n        s+=num\\n        p*=num\\n    return s,p[CODE GOES HERE]None',\n",
       " '\\nclass LoginAuthenticator:\\n    def __init__(self):\\n        # DO NOT CHANGE\\n        self.user_credentials = {}  # dictionary for username: hashed_password\\n\\n    def _hash_password(self, password):\\n        # WRITE CODE HERE\\n        return[CODE GOES HERE]\\n\\n    def add_user(self, username, password):\\n        # WRITE CODE HERE\\n        return\\n\\n    def authenticate_user(self, username, password):\\n        # DO NOT CHANGE\\n        #Checks if the given username and password are valid\\n        if username not in self.user_credentials:\\n            return False\\n        return self.user_credentials[username] == self._hash_password(password)\\n\\n    def remove_user(self, username):\\n        # WRITE CODE HERE\\n        return\\n\\n    def change_password(self, username, old_password, new_password):\\n        # WRITE CODE HERE\\n        return\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dataframe['input'].to_list()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71b6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "llama33_70b = dspy.LM(\"litellm_proxy/meta-llama/Meta-Llama-3.3-70b-Instruct\", api_base=\"http://future-hgx-1.stanford.edu:7410/v1\", api_key=\"None\")\n",
    "\n",
    "dspy.settings.configure(lm=llama33_70b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0419c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/m000076/mryan0/autometrics/autometrics/metrics/reference_based/MOVERScore.py:25: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"\"\"---\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautometrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMetricBank\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m reference_free_metrics\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m      4\u001b[0m generator \u001b[38;5;241m=\u001b[39m LLMJudgeProposer(train_dataset\u001b[38;5;241m=\u001b[39mtrain, task_description\u001b[38;5;241m=\u001b[39mtask_prompt, proposer_model\u001b[38;5;241m=\u001b[39mllama33_70b, judge_model\u001b[38;5;241m=\u001b[39mllama33_70b)\n",
      "File \u001b[0;32m/projects/m000076/mryan0/autometrics/autometrics/metrics/MetricBank.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautometrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreference_free\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mUniEvalFact\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UniEvalFact\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautometrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreference_free\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPerplexity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Perplexity\n\u001b[0;32m---> 26\u001b[0m reference_based_metrics \u001b[38;5;241m=\u001b[39m [BLEU(), CHRF(), TER(), GLEU(), SARI(), BERTScore(), ROUGE(), \u001b[43mMOVERScore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, BARTScore(), UniEvalDialogue(), UniEvalSum(), CIDEr(), LevenshteinDistance(), LevenshteinRatio(), HammingDistance(), JaroSimilarity(), JaroWinklerSimilarity()]\n\u001b[1;32m     27\u001b[0m reference_free_metrics \u001b[38;5;241m=\u001b[39m [FKGL(), UniEvalFact(), Perplexity(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)]\n\u001b[1;32m     29\u001b[0m all_metrics \u001b[38;5;241m=\u001b[39m reference_based_metrics \u001b[38;5;241m+\u001b[39m reference_free_metrics\n",
      "File \u001b[0;32m/projects/m000076/mryan0/autometrics/autometrics/metrics/reference_based/MOVERScore.py:146\u001b[0m, in \u001b[0;36mMOVERScore.__init__\u001b[0;34m(self, model_name, device)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name\n",
      "File \u001b[0;32m~/.conda/envs/autometrics/lib/python3.12/site-packages/transformers/modeling_utils.py:3162\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3160\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3161\u001b[0m         )\n\u001b[0;32m-> 3162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/autometrics/lib/python3.12/site-packages/torch/nn/modules/module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/autometrics/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/autometrics/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/autometrics/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/autometrics/lib/python3.12/site-packages/torch/nn/modules/module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1324\u001b[0m             device,\n\u001b[1;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1326\u001b[0m             non_blocking,\n\u001b[1;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1328\u001b[0m         )\n\u001b[0;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/autometrics/lib/python3.12/site-packages/torch/cuda/__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "from autometrics.metrics.MetricBank import reference_free_metrics\n",
    "\n",
    "# %%\n",
    "generator = LLMJudgeProposer(train_dataset=train, task_description=task_prompt, proposer_model=llama33_70b, judge_model=llama33_70b)\n",
    "\n",
    "# %%\n",
    "print(llama33_70b.model)\n",
    "\n",
    "for target_column in dataset.target_columns:\n",
    "    train.add_metrics(reference_free_metrics)\n",
    "    dev.add_metrics(reference_free_metrics)\n",
    "    test.add_metrics(reference_free_metrics)\n",
    "\n",
    "df = display_top_5_metrics_by_validation(dev, test, True)\n",
    "print(df)\n",
    "df.to_csv(\"outputs/\" + dataset.name + \"_top_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "new_metrics = reference_free_metrics\n",
    "\n",
    "for target_column in dataset.target_columns:\n",
    "    new_metrics.extend(generator.generate(train, target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c940de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Condense the metrics that have duplicate names\n",
    "new_metrics_names = set()\n",
    "new_metrics_final = []\n",
    "for metric in new_metrics:\n",
    "    if metric.name not in new_metrics_names:\n",
    "        new_metrics_names.add(metric.name)\n",
    "        new_metrics_final.append(metric)\n",
    "\n",
    "# %%\n",
    "train.add_metrics(new_metrics_final)\n",
    "dev.add_metrics(new_metrics_final)\n",
    "test.add_metrics(new_metrics_final)\n",
    "\n",
    "# %%\n",
    "df = display_top_5_metrics_by_validation(dev, test, True)\n",
    "print(df)\n",
    "df.to_csv(\"outputs/\" + dataset.name + \"_top_metrics_dspy.csv\")\n",
    "\n",
    "# %%\n",
    "for target in tqdm(dataset.get_target_columns()):\n",
    "    aggregator = Ridge(dataset=train, name=f'Ridge_{target}_llm')\n",
    "    aggregator.ensure_dependencies(train)\n",
    "    aggregator.ensure_dependencies(dev)\n",
    "    aggregator.ensure_dependencies(test)\n",
    "\n",
    "# %%\n",
    "train.get_metric_columns()\n",
    "\n",
    "# %%\n",
    "for target in tqdm(dataset.get_target_columns()):\n",
    "    aggregator = Ridge(dataset=train, name=f'Ridge_{target}_llm')\n",
    "    aggregator.learn(train, target)\n",
    "    aggregator.predict(train)\n",
    "    aggregator.predict(dev)\n",
    "    aggregator.predict(test)\n",
    "\n",
    "# %%\n",
    "df = display_top_5_metrics_by_validation(dev, test, True)\n",
    "print(df)\n",
    "df.to_csv(\"outputs/\" + dataset.name + \"_top_metrics_dspy_regression.csv\")\n",
    "\n",
    "# all computed values\n",
    "dataset.get_dataframe().to_csv(\"outputs/\" + dataset.name + \"_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
